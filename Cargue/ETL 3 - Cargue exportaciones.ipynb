{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL:  Exportaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generales\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Funciones Snowflake\n",
    "import funciones as snow_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aumentar número de columnas que se pueden ver\n",
    "pd.options.display.max_columns = None\n",
    "# En los dataframes, mostrar los float con dos decimales\n",
    "pd.options.display.float_format = '{:,.10f}'.format\n",
    "# Cada columna será tan grande como sea necesario para mostrar todo su contenido\n",
    "pd.set_option('display.max_colwidth', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias necesarias para subir a Snowflake\n",
    "import os\n",
    "import json\n",
    "import snowflake.connector # [pip install snowflake-connector-python]\n",
    "from snowflake.connector.pandas_tools import write_pandas # [pip install \"snowflake-connector-python[pandas]\"]\n",
    "from snowflake.snowpark import Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sesión actual: {<snowflake.snowpark.session.Session object at 0x0000027FA6C9C190>}\n"
     ]
    }
   ],
   "source": [
    "# Paso 1: Definir la ruta al archivo JSON en el escritorio\n",
    "desktop_path = os.path.join(os.path.expanduser(\"~\"), \"Desktop\\Conn\")\n",
    "json_file_path = os.path.join(desktop_path, \"snowflake_credentials.json\")\n",
    "\n",
    "# Paso 2: Leer las credenciales desde el archivo JSON\n",
    "with open(json_file_path, 'r') as file:\n",
    "    credentials = json.load(file)\n",
    "\n",
    "# Paso 3: Definir los parámetros de conexión usando las credenciales\n",
    "connection_parameters = {\n",
    "        \"account\": credentials[\"ACCOUNT_SNOWFLAKE\"],\n",
    "        \"user\": credentials[\"USER_SNOWFLAKE\"],\n",
    "        \"password\": credentials[\"PASSWORD_SNOWFLAKE\"],\n",
    "        \"role\": credentials[\"ROLE_SNOWFLAKE\"],\n",
    "        \"warehouse\": credentials[\"WAREHOUSE\"]\n",
    "    }\n",
    "\n",
    "# Paso 5: Crear un objeto de conexión utilizando snowflake.connector\n",
    "session = Session.builder.configs(connection_parameters).create()\n",
    "print(\"Sesión actual:\", {session})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear objeto de conexión\n",
    "conn = session.connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Base de exportaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solo se debe cambiar la ubicación del archivo\n",
    "path_exportaciones = \"C:/Users/nrivera/OneDrive - PROCOLOMBIA/Documentos/017B-Documentos-Colombia/Cargue/Insumos/EXPORTACIONES/\"\n",
    "exportaciones_file = 'Base_Exportaciones_Colombianas.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se descargó el Excel, se eliminaron las demás pestañas y solo se dejó la base de datos y exportó a CSV\n",
    "# Se eligen los tipos de columna ya conocidos\n",
    "df_exportaciones = pd.read_csv(path_exportaciones + exportaciones_file, sep=\";\", decimal=\",\",\n",
    "                                dtype= {\n",
    "                                    'Tipo' : str,\n",
    "                                    'Cadena' : str,\n",
    "                                    'Sector' : str,\n",
    "                                    'Subsector' : str,\n",
    "                                    'Posicion' : str,\n",
    "                                    'Descripcion Posicion' : str,\n",
    "                                    'Nit Exportador' : str,\n",
    "                                    'Razon Social' : str,\n",
    "                                    'Registrada NEO' : str,\n",
    "                                    'Pais Destino' : str,\n",
    "                                    'HUB' : str,\n",
    "                                    'Continente' : str,\n",
    "                                    'Zona Geografica' : str,\n",
    "                                    'Tipo Acuerdo' : str,\n",
    "                                    'Departamento Origen' : str,\n",
    "                                    'Medio Transporte' : str,\n",
    "                                    'Cadena Frío' : str,\n",
    "                                    'Economia Naranja' : str,\n",
    "                                    'TIPO*' : str,\n",
    "                                    'CADENA*' : str,\n",
    "                                    'SECTOR*' : str,\n",
    "                                    'SUBSECTOR*' : str,\n",
    "                                    '*DPTO MAS EXPORTA' : str,\n",
    "                                    '2018 USD' : float,\n",
    "                                    '2018 KG Neto' : float,\n",
    "                                    '2019 USD' : float,\n",
    "                                    '2019 KG Neto' : float,\n",
    "                                    '2020 USD' : float,\n",
    "                                    '2020 KG Neto' : float,\n",
    "                                    '2021 USD' : float,\n",
    "                                    '2021 KG Neto' : float,\n",
    "                                    '2022 USD' : float,\n",
    "                                    '2022 KG Neto' : float,\n",
    "                                    '2023 USD' : float,\n",
    "                                    '2023 KG Neto' : float,\n",
    "                                    '2023 USD (Ene-Oct)' : float,\n",
    "                                    '2023 KG Neto (Ene-Oct)' : float,\n",
    "                                    '2024 USD (Ene-Oct)' : float,\n",
    "                                    '2024 KG Neto (Ene-Oct)' : float\n",
    "                                })\n",
    "df_exportaciones.shape\n",
    "\n",
    "# Crear insumo para validación en el paso # 8\n",
    "df_insumo_validacion = df_exportaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tipo',\n",
       " 'Cadena',\n",
       " 'Sector',\n",
       " 'Subsector',\n",
       " 'Posicion',\n",
       " 'Descripcion Posicion',\n",
       " 'Nit Exportador',\n",
       " 'Razon Social',\n",
       " 'Registrada NEO',\n",
       " 'Pais Destino',\n",
       " 'HUB',\n",
       " 'Continente',\n",
       " 'Zona Geografica',\n",
       " \"TLC'S\",\n",
       " 'Tipo Acuerdo',\n",
       " 'Departamento Origen',\n",
       " 'Medio Transporte',\n",
       " 'Cadena Frío',\n",
       " 'Economia Naranja',\n",
       " 'TIPO*',\n",
       " 'CADENA*',\n",
       " 'SECTOR*',\n",
       " 'SUBSECTOR*',\n",
       " '*DPTO MAS EXPORTA']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identificar las columnas que no son de años\n",
    "id_vars = [col for col in df_exportaciones.columns if not any(keyword in col for keyword in ['USD', 'KG Neto'])]\n",
    "id_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear listas con las columnas que contienen valores (USD y KG Neto)\n",
    "value_vars_usd = [col for col in df_exportaciones.columns if 'USD' in col]\n",
    "value_vars_kg = [col for col in df_exportaciones.columns if 'KG Neto' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2018 USD',\n",
       " '2019 USD',\n",
       " '2020 USD',\n",
       " '2021 USD',\n",
       " '2022 USD',\n",
       " '2023 USD',\n",
       " '2023 USD (Ene-Oct)',\n",
       " '2024 USD (Ene-Oct)']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_vars_usd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2018 KG Neto',\n",
       " '2019 KG Neto',\n",
       " '2020 KG Neto',\n",
       " '2021 KG Neto',\n",
       " '2022 KG Neto',\n",
       " '2023 KG Neto',\n",
       " '2023 KG Neto (Ene-Oct)',\n",
       " '2024 KG Neto (Ene-Oct)']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_vars_kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tipo</th>\n",
       "      <th>Cadena</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Subsector</th>\n",
       "      <th>Posicion</th>\n",
       "      <th>Descripcion Posicion</th>\n",
       "      <th>Nit Exportador</th>\n",
       "      <th>Razon Social</th>\n",
       "      <th>Registrada NEO</th>\n",
       "      <th>Pais Destino</th>\n",
       "      <th>HUB</th>\n",
       "      <th>Continente</th>\n",
       "      <th>Zona Geografica</th>\n",
       "      <th>TLC'S</th>\n",
       "      <th>Tipo Acuerdo</th>\n",
       "      <th>Departamento Origen</th>\n",
       "      <th>Medio Transporte</th>\n",
       "      <th>Cadena Frío</th>\n",
       "      <th>Economia Naranja</th>\n",
       "      <th>TIPO*</th>\n",
       "      <th>CADENA*</th>\n",
       "      <th>SECTOR*</th>\n",
       "      <th>SUBSECTOR*</th>\n",
       "      <th>*DPTO MAS EXPORTA</th>\n",
       "      <th>Año</th>\n",
       "      <th>Valor USD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No Mineras</td>\n",
       "      <td>Metalmecánica y Otras Industrias</td>\n",
       "      <td>Artesanías</td>\n",
       "      <td>Cerámica</td>\n",
       "      <td>6914900000</td>\n",
       "      <td>Las demás manufacturas de cerámica.</td>\n",
       "      <td>9001271404</td>\n",
       "      <td>C.I.A   MIGUEL CABALLERO SAS</td>\n",
       "      <td>Si</td>\n",
       "      <td>Afganistán</td>\n",
       "      <td>Norteamérica</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Asia del Sur</td>\n",
       "      <td>Resto de países</td>\n",
       "      <td>Sin Acuerdo</td>\n",
       "      <td>Cundinamarca</td>\n",
       "      <td>Aéreo</td>\n",
       "      <td>No</td>\n",
       "      <td>No aplica</td>\n",
       "      <td>No Mineras</td>\n",
       "      <td>Sistema Moda</td>\n",
       "      <td>Textiles y confecciones</td>\n",
       "      <td>Otras confecciones</td>\n",
       "      <td>Bogotá</td>\n",
       "      <td>2018</td>\n",
       "      <td>278.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>No Mineras</td>\n",
       "      <td>Sistema Moda</td>\n",
       "      <td>Textiles y confecciones</td>\n",
       "      <td>Otras confecciones</td>\n",
       "      <td>6307909000</td>\n",
       "      <td>Los demás artículos confeccionados</td>\n",
       "      <td>9001271404</td>\n",
       "      <td>C.I.A   MIGUEL CABALLERO SAS</td>\n",
       "      <td>Si</td>\n",
       "      <td>Afganistán</td>\n",
       "      <td>Norteamérica</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Asia del Sur</td>\n",
       "      <td>Resto de países</td>\n",
       "      <td>Sin Acuerdo</td>\n",
       "      <td>Cundinamarca</td>\n",
       "      <td>Aéreo</td>\n",
       "      <td>No</td>\n",
       "      <td>No aplica</td>\n",
       "      <td>No Mineras</td>\n",
       "      <td>Sistema Moda</td>\n",
       "      <td>Textiles y confecciones</td>\n",
       "      <td>Otras confecciones</td>\n",
       "      <td>Bogotá</td>\n",
       "      <td>2018</td>\n",
       "      <td>1,903.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>No Mineras</td>\n",
       "      <td>Agroalimentos</td>\n",
       "      <td>Banano</td>\n",
       "      <td>Banano</td>\n",
       "      <td>0803901100</td>\n",
       "      <td>Bananas o plátanos frescos del tipo \"cavendish valery\"</td>\n",
       "      <td>9008378146</td>\n",
       "      <td>C.I. NOVA FOODS EXPORT S.A.S.</td>\n",
       "      <td>Si</td>\n",
       "      <td>Albania</td>\n",
       "      <td>Europa</td>\n",
       "      <td>Europa</td>\n",
       "      <td>Europa del Sur</td>\n",
       "      <td>Resto de países</td>\n",
       "      <td>Sin Acuerdo</td>\n",
       "      <td>Magdalena</td>\n",
       "      <td>Marítimo</td>\n",
       "      <td>Si</td>\n",
       "      <td>No aplica</td>\n",
       "      <td>No Mineras</td>\n",
       "      <td>Agroalimentos</td>\n",
       "      <td>Banano</td>\n",
       "      <td>Banano</td>\n",
       "      <td>Magdalena</td>\n",
       "      <td>2018</td>\n",
       "      <td>16,200.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>No Mineras</td>\n",
       "      <td>Agroalimentos</td>\n",
       "      <td>Banano</td>\n",
       "      <td>Banano</td>\n",
       "      <td>0803901100</td>\n",
       "      <td>Bananas o plátanos frescos del tipo \"cavendish valery\"</td>\n",
       "      <td>9009348972</td>\n",
       "      <td>C.I BACCOTA S.A.S</td>\n",
       "      <td>Si</td>\n",
       "      <td>Albania</td>\n",
       "      <td>Europa</td>\n",
       "      <td>Europa</td>\n",
       "      <td>Europa del Sur</td>\n",
       "      <td>Resto de países</td>\n",
       "      <td>Sin Acuerdo</td>\n",
       "      <td>Antioquia</td>\n",
       "      <td>Marítimo</td>\n",
       "      <td>Si</td>\n",
       "      <td>No aplica</td>\n",
       "      <td>No Mineras</td>\n",
       "      <td>Agroalimentos</td>\n",
       "      <td>Banano</td>\n",
       "      <td>Banano</td>\n",
       "      <td>Antioquia</td>\n",
       "      <td>2018</td>\n",
       "      <td>639,203.4000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>No Mineras</td>\n",
       "      <td>Agroalimentos</td>\n",
       "      <td>Café</td>\n",
       "      <td>Café verde</td>\n",
       "      <td>0901119000</td>\n",
       "      <td>Los demás cafés sin tostar, sin descafeinar.</td>\n",
       "      <td>9001105941</td>\n",
       "      <td>OLAM AGRO COLOMBIA S.A.S</td>\n",
       "      <td>Si</td>\n",
       "      <td>Albania</td>\n",
       "      <td>Europa</td>\n",
       "      <td>Europa</td>\n",
       "      <td>Europa del Sur</td>\n",
       "      <td>Resto de países</td>\n",
       "      <td>Sin Acuerdo</td>\n",
       "      <td>Huila</td>\n",
       "      <td>Marítimo</td>\n",
       "      <td>No</td>\n",
       "      <td>No aplica</td>\n",
       "      <td>No Mineras</td>\n",
       "      <td>Agroalimentos</td>\n",
       "      <td>Café</td>\n",
       "      <td>Café verde</td>\n",
       "      <td>Huila</td>\n",
       "      <td>2018</td>\n",
       "      <td>62,336.3000000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Tipo                            Cadena                   Sector  \\\n",
       "2   No Mineras  Metalmecánica y Otras Industrias  Artesanías                \n",
       "6   No Mineras  Sistema Moda                      Textiles y confecciones   \n",
       "20  No Mineras  Agroalimentos                     Banano                    \n",
       "22  No Mineras  Agroalimentos                     Banano                    \n",
       "25  No Mineras  Agroalimentos                     Café                      \n",
       "\n",
       "             Subsector    Posicion  \\\n",
       "2   Cerámica            6914900000   \n",
       "6   Otras confecciones  6307909000   \n",
       "20  Banano              0803901100   \n",
       "22  Banano              0803901100   \n",
       "25  Café verde          0901119000   \n",
       "\n",
       "                                       Descripcion Posicion Nit Exportador  \\\n",
       "2   Las demás manufacturas de cerámica.                      9001271404      \n",
       "6   Los demás artículos confeccionados                       9001271404      \n",
       "20  Bananas o plátanos frescos del tipo \"cavendish valery\"   9008378146      \n",
       "22  Bananas o plátanos frescos del tipo \"cavendish valery\"   9009348972      \n",
       "25  Los demás cafés sin tostar, sin descafeinar.             9001105941      \n",
       "\n",
       "                     Razon Social Registrada NEO Pais Destino           HUB  \\\n",
       "2   C.I.A   MIGUEL CABALLERO SAS   Si             Afganistán   Norteamérica   \n",
       "6   C.I.A   MIGUEL CABALLERO SAS   Si             Afganistán   Norteamérica   \n",
       "20  C.I. NOVA FOODS EXPORT S.A.S.  Si             Albania      Europa         \n",
       "22  C.I BACCOTA S.A.S              Si             Albania      Europa         \n",
       "25  OLAM AGRO COLOMBIA S.A.S       Si             Albania      Europa         \n",
       "\n",
       "   Continente Zona Geografica            TLC'S Tipo Acuerdo  \\\n",
       "2   Asia       Asia del Sur    Resto de países  Sin Acuerdo   \n",
       "6   Asia       Asia del Sur    Resto de países  Sin Acuerdo   \n",
       "20  Europa     Europa del Sur  Resto de países  Sin Acuerdo   \n",
       "22  Europa     Europa del Sur  Resto de países  Sin Acuerdo   \n",
       "25  Europa     Europa del Sur  Resto de países  Sin Acuerdo   \n",
       "\n",
       "   Departamento Origen Medio Transporte Cadena Frío Economia Naranja  \\\n",
       "2   Cundinamarca        Aéreo            No          No aplica         \n",
       "6   Cundinamarca        Aéreo            No          No aplica         \n",
       "20  Magdalena           Marítimo         Si          No aplica         \n",
       "22  Antioquia           Marítimo         Si          No aplica         \n",
       "25  Huila               Marítimo         No          No aplica         \n",
       "\n",
       "         TIPO*        CADENA*                  SECTOR*          SUBSECTOR*  \\\n",
       "2   No Mineras  Sistema Moda   Textiles y confecciones  Otras confecciones   \n",
       "6   No Mineras  Sistema Moda   Textiles y confecciones  Otras confecciones   \n",
       "20  No Mineras  Agroalimentos  Banano                   Banano               \n",
       "22  No Mineras  Agroalimentos  Banano                   Banano               \n",
       "25  No Mineras  Agroalimentos  Café                     Café verde           \n",
       "\n",
       "   *DPTO MAS EXPORTA   Año          Valor USD  \n",
       "2   Bogotá            2018 278.0000000000      \n",
       "6   Bogotá            2018 1,903.0000000000    \n",
       "20  Magdalena         2018 16,200.0000000000   \n",
       "22  Antioquia         2018 639,203.4000000000  \n",
       "25  Huila             2018 62,336.3000000000   "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convertir a formato long para USD\n",
    "df_usd_long = df_exportaciones.melt(id_vars=id_vars, value_vars=value_vars_usd, var_name='Año', value_name='Valor USD')\n",
    "df_usd_long['Año'] = df_usd_long['Año'].str.replace(\"USD\", \"\")\n",
    "df_usd_long['Año'] = df_usd_long['Año'].str.replace(\" \", \"\")\n",
    "df_usd_long = df_usd_long[df_usd_long['Valor USD'] > 0]\n",
    "df_usd_long.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tipo</th>\n",
       "      <th>Cadena</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Subsector</th>\n",
       "      <th>Posicion</th>\n",
       "      <th>Descripcion Posicion</th>\n",
       "      <th>Nit Exportador</th>\n",
       "      <th>Razon Social</th>\n",
       "      <th>Registrada NEO</th>\n",
       "      <th>Pais Destino</th>\n",
       "      <th>HUB</th>\n",
       "      <th>Continente</th>\n",
       "      <th>Zona Geografica</th>\n",
       "      <th>TLC'S</th>\n",
       "      <th>Tipo Acuerdo</th>\n",
       "      <th>Departamento Origen</th>\n",
       "      <th>Medio Transporte</th>\n",
       "      <th>Cadena Frío</th>\n",
       "      <th>Economia Naranja</th>\n",
       "      <th>TIPO*</th>\n",
       "      <th>CADENA*</th>\n",
       "      <th>SECTOR*</th>\n",
       "      <th>SUBSECTOR*</th>\n",
       "      <th>*DPTO MAS EXPORTA</th>\n",
       "      <th>Año</th>\n",
       "      <th>Peso KG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No Mineras</td>\n",
       "      <td>Metalmecánica y Otras Industrias</td>\n",
       "      <td>Artesanías</td>\n",
       "      <td>Cerámica</td>\n",
       "      <td>6914900000</td>\n",
       "      <td>Las demás manufacturas de cerámica.</td>\n",
       "      <td>9001271404</td>\n",
       "      <td>C.I.A   MIGUEL CABALLERO SAS</td>\n",
       "      <td>Si</td>\n",
       "      <td>Afganistán</td>\n",
       "      <td>Norteamérica</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Asia del Sur</td>\n",
       "      <td>Resto de países</td>\n",
       "      <td>Sin Acuerdo</td>\n",
       "      <td>Cundinamarca</td>\n",
       "      <td>Aéreo</td>\n",
       "      <td>No</td>\n",
       "      <td>No aplica</td>\n",
       "      <td>No Mineras</td>\n",
       "      <td>Sistema Moda</td>\n",
       "      <td>Textiles y confecciones</td>\n",
       "      <td>Otras confecciones</td>\n",
       "      <td>Bogotá</td>\n",
       "      <td>2018</td>\n",
       "      <td>6.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>No Mineras</td>\n",
       "      <td>Sistema Moda</td>\n",
       "      <td>Textiles y confecciones</td>\n",
       "      <td>Otras confecciones</td>\n",
       "      <td>6307909000</td>\n",
       "      <td>Los demás artículos confeccionados</td>\n",
       "      <td>9001271404</td>\n",
       "      <td>C.I.A   MIGUEL CABALLERO SAS</td>\n",
       "      <td>Si</td>\n",
       "      <td>Afganistán</td>\n",
       "      <td>Norteamérica</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Asia del Sur</td>\n",
       "      <td>Resto de países</td>\n",
       "      <td>Sin Acuerdo</td>\n",
       "      <td>Cundinamarca</td>\n",
       "      <td>Aéreo</td>\n",
       "      <td>No</td>\n",
       "      <td>No aplica</td>\n",
       "      <td>No Mineras</td>\n",
       "      <td>Sistema Moda</td>\n",
       "      <td>Textiles y confecciones</td>\n",
       "      <td>Otras confecciones</td>\n",
       "      <td>Bogotá</td>\n",
       "      <td>2018</td>\n",
       "      <td>12.5000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>No Mineras</td>\n",
       "      <td>Agroalimentos</td>\n",
       "      <td>Banano</td>\n",
       "      <td>Banano</td>\n",
       "      <td>0803901100</td>\n",
       "      <td>Bananas o plátanos frescos del tipo \"cavendish valery\"</td>\n",
       "      <td>9008378146</td>\n",
       "      <td>C.I. NOVA FOODS EXPORT S.A.S.</td>\n",
       "      <td>Si</td>\n",
       "      <td>Albania</td>\n",
       "      <td>Europa</td>\n",
       "      <td>Europa</td>\n",
       "      <td>Europa del Sur</td>\n",
       "      <td>Resto de países</td>\n",
       "      <td>Sin Acuerdo</td>\n",
       "      <td>Magdalena</td>\n",
       "      <td>Marítimo</td>\n",
       "      <td>Si</td>\n",
       "      <td>No aplica</td>\n",
       "      <td>No Mineras</td>\n",
       "      <td>Agroalimentos</td>\n",
       "      <td>Banano</td>\n",
       "      <td>Banano</td>\n",
       "      <td>Magdalena</td>\n",
       "      <td>2018</td>\n",
       "      <td>39,182.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>No Mineras</td>\n",
       "      <td>Agroalimentos</td>\n",
       "      <td>Banano</td>\n",
       "      <td>Banano</td>\n",
       "      <td>0803901100</td>\n",
       "      <td>Bananas o plátanos frescos del tipo \"cavendish valery\"</td>\n",
       "      <td>9009348972</td>\n",
       "      <td>C.I BACCOTA S.A.S</td>\n",
       "      <td>Si</td>\n",
       "      <td>Albania</td>\n",
       "      <td>Europa</td>\n",
       "      <td>Europa</td>\n",
       "      <td>Europa del Sur</td>\n",
       "      <td>Resto de países</td>\n",
       "      <td>Sin Acuerdo</td>\n",
       "      <td>Antioquia</td>\n",
       "      <td>Marítimo</td>\n",
       "      <td>Si</td>\n",
       "      <td>No aplica</td>\n",
       "      <td>No Mineras</td>\n",
       "      <td>Agroalimentos</td>\n",
       "      <td>Banano</td>\n",
       "      <td>Banano</td>\n",
       "      <td>Antioquia</td>\n",
       "      <td>2018</td>\n",
       "      <td>1,407,807.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>No Mineras</td>\n",
       "      <td>Agroalimentos</td>\n",
       "      <td>Café</td>\n",
       "      <td>Café verde</td>\n",
       "      <td>0901119000</td>\n",
       "      <td>Los demás cafés sin tostar, sin descafeinar.</td>\n",
       "      <td>9001105941</td>\n",
       "      <td>OLAM AGRO COLOMBIA S.A.S</td>\n",
       "      <td>Si</td>\n",
       "      <td>Albania</td>\n",
       "      <td>Europa</td>\n",
       "      <td>Europa</td>\n",
       "      <td>Europa del Sur</td>\n",
       "      <td>Resto de países</td>\n",
       "      <td>Sin Acuerdo</td>\n",
       "      <td>Huila</td>\n",
       "      <td>Marítimo</td>\n",
       "      <td>No</td>\n",
       "      <td>No aplica</td>\n",
       "      <td>No Mineras</td>\n",
       "      <td>Agroalimentos</td>\n",
       "      <td>Café</td>\n",
       "      <td>Café verde</td>\n",
       "      <td>Huila</td>\n",
       "      <td>2018</td>\n",
       "      <td>19,954.0000000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Tipo                            Cadena                   Sector  \\\n",
       "2   No Mineras  Metalmecánica y Otras Industrias  Artesanías                \n",
       "6   No Mineras  Sistema Moda                      Textiles y confecciones   \n",
       "20  No Mineras  Agroalimentos                     Banano                    \n",
       "22  No Mineras  Agroalimentos                     Banano                    \n",
       "25  No Mineras  Agroalimentos                     Café                      \n",
       "\n",
       "             Subsector    Posicion  \\\n",
       "2   Cerámica            6914900000   \n",
       "6   Otras confecciones  6307909000   \n",
       "20  Banano              0803901100   \n",
       "22  Banano              0803901100   \n",
       "25  Café verde          0901119000   \n",
       "\n",
       "                                       Descripcion Posicion Nit Exportador  \\\n",
       "2   Las demás manufacturas de cerámica.                      9001271404      \n",
       "6   Los demás artículos confeccionados                       9001271404      \n",
       "20  Bananas o plátanos frescos del tipo \"cavendish valery\"   9008378146      \n",
       "22  Bananas o plátanos frescos del tipo \"cavendish valery\"   9009348972      \n",
       "25  Los demás cafés sin tostar, sin descafeinar.             9001105941      \n",
       "\n",
       "                     Razon Social Registrada NEO Pais Destino           HUB  \\\n",
       "2   C.I.A   MIGUEL CABALLERO SAS   Si             Afganistán   Norteamérica   \n",
       "6   C.I.A   MIGUEL CABALLERO SAS   Si             Afganistán   Norteamérica   \n",
       "20  C.I. NOVA FOODS EXPORT S.A.S.  Si             Albania      Europa         \n",
       "22  C.I BACCOTA S.A.S              Si             Albania      Europa         \n",
       "25  OLAM AGRO COLOMBIA S.A.S       Si             Albania      Europa         \n",
       "\n",
       "   Continente Zona Geografica            TLC'S Tipo Acuerdo  \\\n",
       "2   Asia       Asia del Sur    Resto de países  Sin Acuerdo   \n",
       "6   Asia       Asia del Sur    Resto de países  Sin Acuerdo   \n",
       "20  Europa     Europa del Sur  Resto de países  Sin Acuerdo   \n",
       "22  Europa     Europa del Sur  Resto de países  Sin Acuerdo   \n",
       "25  Europa     Europa del Sur  Resto de países  Sin Acuerdo   \n",
       "\n",
       "   Departamento Origen Medio Transporte Cadena Frío Economia Naranja  \\\n",
       "2   Cundinamarca        Aéreo            No          No aplica         \n",
       "6   Cundinamarca        Aéreo            No          No aplica         \n",
       "20  Magdalena           Marítimo         Si          No aplica         \n",
       "22  Antioquia           Marítimo         Si          No aplica         \n",
       "25  Huila               Marítimo         No          No aplica         \n",
       "\n",
       "         TIPO*        CADENA*                  SECTOR*          SUBSECTOR*  \\\n",
       "2   No Mineras  Sistema Moda   Textiles y confecciones  Otras confecciones   \n",
       "6   No Mineras  Sistema Moda   Textiles y confecciones  Otras confecciones   \n",
       "20  No Mineras  Agroalimentos  Banano                   Banano               \n",
       "22  No Mineras  Agroalimentos  Banano                   Banano               \n",
       "25  No Mineras  Agroalimentos  Café                     Café verde           \n",
       "\n",
       "   *DPTO MAS EXPORTA   Año              Peso KG  \n",
       "2   Bogotá            2018 6.0000000000          \n",
       "6   Bogotá            2018 12.5000000000         \n",
       "20  Magdalena         2018 39,182.0000000000     \n",
       "22  Antioquia         2018 1,407,807.0000000000  \n",
       "25  Huila             2018 19,954.0000000000     "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convertir a formato long para KG Neto\n",
    "df_kg_long = df_exportaciones.melt(id_vars=id_vars, value_vars=value_vars_kg, var_name='Año', value_name='Peso KG')\n",
    "df_kg_long['Año'] = df_kg_long['Año'].str.replace(\"KG Neto\", \"\")\n",
    "df_kg_long['Año'] = df_kg_long['Año'].str.replace(\" \", \"\")\n",
    "df_kg_long = df_kg_long[df_kg_long['Peso KG'] > 0]\n",
    "df_kg_long.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para subir a Snowflake los nombres de las columnas no deben tener espacios, carácteres especiales, tildes o empezados por números\n",
    "# Limpiar espacios y carácteres especiales\n",
    "\n",
    "# USD\n",
    "df_usd_long.columns = df_usd_long.columns.str.replace(' ', '_') \n",
    "df_usd_long.columns = df_usd_long.columns.str.replace('(', '') \n",
    "df_usd_long.columns = df_usd_long.columns.str.replace(')', '')\n",
    "df_usd_long.columns = df_usd_long.columns.str.replace('-', '_')\n",
    "df_usd_long.columns = df_usd_long.columns.str.replace(\"TLC'S\", 'TLCS')\n",
    "\n",
    "# KG\n",
    "df_kg_long.columns = df_kg_long.columns.str.replace(' ', '_') \n",
    "df_kg_long.columns = df_kg_long.columns.str.replace('(', '') \n",
    "df_kg_long.columns = df_kg_long.columns.str.replace(')', '')\n",
    "df_kg_long.columns = df_kg_long.columns.str.replace('-', '_')\n",
    "df_kg_long.columns = df_kg_long.columns.str.replace(\"TLC'S\", 'TLCS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nuevos nombres de columnas (No pueden empezar con números ni tener * o tildes)\n",
    "\n",
    "# USD\n",
    "df_usd_long = df_usd_long.rename(columns={\n",
    "    'TIPO*' : 'TIPO_ESTRELLA', \n",
    "    'CADENA*' : 'CADENA_ESTRELLA', \n",
    "    'SECTOR*' : 'SECTOR_ESTRELLA',\n",
    "    'SUBSECTOR*' : 'SUBSECTOR_ESTRELLA', \n",
    "    '*DPTO_MAS_EXPORTA': 'DPTO_MAS_EXPORTA_ESTRELLA',\n",
    "    'Cadena_Frío' : 'Cadena_Frio',\n",
    "    'Año' : 'Year'\n",
    "})\n",
    "\n",
    "# KG\n",
    "df_kg_long = df_kg_long.rename(columns={\n",
    "    'TIPO*' : 'TIPO_ESTRELLA', \n",
    "    'CADENA*' : 'CADENA_ESTRELLA', \n",
    "    'SECTOR*' : 'SECTOR_ESTRELLA',\n",
    "    'SUBSECTOR*' : 'SUBSECTOR_ESTRELLA', \n",
    "    '*DPTO_MAS_EXPORTA': 'DPTO_MAS_EXPORTA_ESTRELLA',\n",
    "    'Cadena_Frío' : 'Cadena_Frio',\n",
    "    'Año' : 'Year'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiar a mayúsculas\n",
    "# USD\n",
    "df_usd_long.columns = map(str.upper, df_usd_long.columns)\n",
    "# KG\n",
    "df_kg_long.columns = map(str.upper, df_kg_long.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Parámetros (cambiar el mes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_1_YEAR</th>\n",
       "      <th>T_YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  T_1_YEAR T_YEAR\n",
       "0  2022     2023 "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear un DataFrame que represente TEMP_PARAMETROS_CERRADO\n",
    "TEMP_PARAMETROS_CERRADO = pd.DataFrame({\n",
    "    'T_1_YEAR': ['2022'],\n",
    "    'T_YEAR': ['2023']\n",
    "})\n",
    "\n",
    "# Mostrar el DataFrame resultante\n",
    "TEMP_PARAMETROS_CERRADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_1_YEAR</th>\n",
       "      <th>T_YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023(Ene-Oct)</td>\n",
       "      <td>2024(Ene-Oct)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        T_1_YEAR         T_YEAR\n",
       "0  2023(Ene-Oct)  2024(Ene-Oct)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear un DataFrame que represente TEMP_PARAMETROS_CORRIDO\n",
    "TEMP_PARAMETROS_CORRIDO = pd.DataFrame({\n",
    "    'T_1_YEAR': ['2023(Ene-Oct)'],\n",
    "    'T_YEAR': ['2024(Ene-Oct)']\n",
    "})\n",
    "\n",
    "# Mostrar el DataFrame resultante\n",
    "TEMP_PARAMETROS_CORRIDO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Correlativa de Geografía"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlativa con la definición de Continentes\n",
    "query_continentes = \"\"\"\n",
    "SELECT DISTINCT A.PAIS_LLAVE_EXPORTACIONES,\n",
    "    B.REGION_NAME\n",
    "FROM DOCUMENTOS_COLOMBIA.GEOGRAFIA.ST_PAISES AS A\n",
    "LEFT JOIN DOCUMENTOS_COLOMBIA.GEOGRAFIA.CONTINENTES AS B ON A.REGION_NAME_EXPORTACIONES = B.REGION_NAME_EXPORTACIONES\n",
    "WHERE A.PAIS_LLAVE_EXPORTACIONES IS NOT NULL\n",
    "ORDER BY 1 ASC;\n",
    "\"\"\"\n",
    "# Ejecutar\n",
    "df_continentes = snow_func.snowflake_sql(conn, query_continentes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlativa con la definición de HUBS\n",
    "query_hubs = \"\"\"\n",
    "\tSELECT DISTINCT A.PAIS_LLAVE_EXPORTACIONES,\n",
    "\t\tB.NOMBRE_HUB\n",
    "\tFROM DOCUMENTOS_COLOMBIA.GEOGRAFIA.ST_PAISES AS A\n",
    "\tLEFT JOIN DOCUMENTOS_COLOMBIA.GEOGRAFIA.HUBS AS B ON A.HUB_NAME_EXPORTACIONES = B.HUB_NAME_EXPORTACIONES\n",
    "\tWHERE A.PAIS_LLAVE_EXPORTACIONES IS NOT NULL\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "\tSELECT A.PAIS_LLAVE_EXPORTACIONES,\n",
    "\t\tC.NOMBRE_HUB\n",
    "\tFROM DOCUMENTOS_COLOMBIA.GEOGRAFIA.ST_PAISES AS A\n",
    "\tLEFT JOIN DOCUMENTOS_COLOMBIA.GEOGRAFIA.CARIBE_PAISES AS B ON A.M49_CODE = B.M49_CODE\n",
    "\tLEFT JOIN DOCUMENTOS_COLOMBIA.GEOGRAFIA.HUBS AS C ON B.ID_HUB = C.ID_HUB\n",
    "\tWHERE C.NOMBRE_HUB = 'Caribe';\n",
    "\"\"\"\n",
    "# Ejecutar\n",
    "df_hubs = snow_func.snowflake_sql(conn, query_hubs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlativa con la definición de TLCs\n",
    "query_tlcs = \"\"\"\n",
    "SELECT DISTINCT A.PAIS_LLAVE_EXPORTACIONES,\n",
    "\tA.NOMBRE_TLC\n",
    "FROM DOCUMENTOS_COLOMBIA.GEOGRAFIA.ST_PAISES AS A\n",
    "WHERE A.PAIS_LLAVE_EXPORTACIONES IS NOT NULL\n",
    "ORDER BY 1 ASC;\n",
    "\"\"\"\n",
    "# Ejecutar\n",
    "df_tlcs = snow_func.snowflake_sql(conn, query_tlcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se trae la tabla completa de geografía para la verificación de países\n",
    "query_geografia = \"\"\"\n",
    "SELECT *\n",
    "FROM DOCUMENTOS_COLOMBIA.GEOGRAFIA.ST_PAISES AS A\n",
    "WHERE A.PAIS_LLAVE_EXPORTACIONES IS NOT NULL;\n",
    "\"\"\"\n",
    "# Ejecutar\n",
    "df_verif = snow_func.snowflake_sql(conn, query_geografia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista con los dfs de geografía relevantes para el conteo de empresas\n",
    "df_geo_list = {'CONTINENTES' : df_continentes, \n",
    "               'HUBS' : df_hubs, \n",
    "               'TLCS': df_tlcs}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Verificar completitud de países"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elegir columnas de interés\n",
    "\n",
    "# Correlativa\n",
    "df_geo_paises_expo = df_verif[['PAIS_LLAVE_EXPORTACIONES', 'COUNTRY_OR_AREA']].drop_duplicates()\n",
    "\n",
    "# Exportaciones USD\n",
    "df_usd_long_paises_expo = df_usd_long[['PAIS_DESTINO']].drop_duplicates()\n",
    "\n",
    "# Exportaciones KG\n",
    "df_kg_long_paises_expo = df_kg_long[['PAIS_DESTINO']].drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar unión\n",
    "\n",
    "# USD\n",
    "df_usd_long_paises_expo = df_usd_long_paises_expo.merge(df_geo_paises_expo, how='left', left_on='PAIS_DESTINO', right_on='PAIS_LLAVE_EXPORTACIONES')\n",
    "\n",
    "# KG\n",
    "df_kg_long_paises_expo = df_kg_long_paises_expo.merge(df_geo_paises_expo, how='left', left_on='PAIS_DESTINO', right_on='PAIS_LLAVE_EXPORTACIONES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PAIS_DESTINO</th>\n",
       "      <th>PAIS_LLAVE_EXPORTACIONES</th>\n",
       "      <th>COUNTRY_OR_AREA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>ZF de Barranquilla</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>ZF de Bogotá</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>ZF de Candelaria Cartagena</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>ZF de Cartagena</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>ZF de Pacifico Cali</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>ZF de Palmaseca Cali</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>ZF de Rio negro Medellín</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>ZF Santander</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>ZFP de Tocancipá</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>ZFP Internacional de Pereira</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>ZFP Internacional del Valle de Aburrá ZOFIVA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>ZFP Intexzona</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>ZFP La Cayena</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>ZFP Parque Central</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>ZFP Parque Industrial Dexton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>ZFP Surcolombiana</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>ZFPE Bio D Facatativá</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>ZFPE Gyplac</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>ZFPE Puerto Industrial Agua Dulce Dirección de Aduanas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>ZF del Eje Cafetero</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>ZF Metropolitana</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>ZFPE Bionergy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>ZFPE Kcag</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>ZFP de Occidente</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>ZFP Tayrona</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>ZFPE Biocombustibles Sostenibles del Caribe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>ZFP Zofrandina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>ZFPE Argos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>ZF de Santa Marta</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>ZFP Internacional del Atlántico</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>ZFPE de Servicios Sociedad Portuaria Regional de Santa Marta</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>ZFPE Femsa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>ZF de Palermo Atlántico</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>ZFPE Puerto Mamonal Sociedad Portuaria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>ZFP Conjunto Industrial Parque Sur</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>ZFP del Cauca</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     PAIS_DESTINO  \\\n",
       "191  ZF de Barranquilla                                             \n",
       "192  ZF de Bogotá                                                   \n",
       "193  ZF de Candelaria Cartagena                                     \n",
       "194  ZF de Cartagena                                                \n",
       "195  ZF de Pacifico Cali                                            \n",
       "196  ZF de Palmaseca Cali                                           \n",
       "197  ZF de Rio negro Medellín                                       \n",
       "198  ZF Santander                                                   \n",
       "199  ZFP de Tocancipá                                               \n",
       "200  ZFP Internacional de Pereira                                   \n",
       "201  ZFP Internacional del Valle de Aburrá ZOFIVA                   \n",
       "202  ZFP Intexzona                                                  \n",
       "203  ZFP La Cayena                                                  \n",
       "204  ZFP Parque Central                                             \n",
       "205  ZFP Parque Industrial Dexton                                   \n",
       "206  ZFP Surcolombiana                                              \n",
       "207  ZFPE Bio D Facatativá                                          \n",
       "208  ZFPE Gyplac                                                    \n",
       "209  ZFPE Puerto Industrial Agua Dulce Dirección de Aduanas         \n",
       "221  ZF del Eje Cafetero                                            \n",
       "222  ZF Metropolitana                                               \n",
       "223  ZFPE Bionergy                                                  \n",
       "224  ZFPE Kcag                                                      \n",
       "229  ZFP de Occidente                                               \n",
       "230  ZFP Tayrona                                                    \n",
       "231  ZFPE Biocombustibles Sostenibles del Caribe                    \n",
       "234  ZFP Zofrandina                                                 \n",
       "235  ZFPE Argos                                                     \n",
       "238  ZF de Santa Marta                                              \n",
       "239  ZFP Internacional del Atlántico                                \n",
       "240  ZFPE de Servicios Sociedad Portuaria Regional de Santa Marta   \n",
       "241  ZFPE Femsa                                                     \n",
       "243  ZF de Palermo Atlántico                                        \n",
       "244  ZFPE Puerto Mamonal Sociedad Portuaria                         \n",
       "246  ZFP Conjunto Industrial Parque Sur                             \n",
       "247  ZFP del Cauca                                                  \n",
       "\n",
       "    PAIS_LLAVE_EXPORTACIONES COUNTRY_OR_AREA  \n",
       "191  NaN                      NaN             \n",
       "192  NaN                      NaN             \n",
       "193  NaN                      NaN             \n",
       "194  NaN                      NaN             \n",
       "195  NaN                      NaN             \n",
       "196  NaN                      NaN             \n",
       "197  NaN                      NaN             \n",
       "198  NaN                      NaN             \n",
       "199  NaN                      NaN             \n",
       "200  NaN                      NaN             \n",
       "201  NaN                      NaN             \n",
       "202  NaN                      NaN             \n",
       "203  NaN                      NaN             \n",
       "204  NaN                      NaN             \n",
       "205  NaN                      NaN             \n",
       "206  NaN                      NaN             \n",
       "207  NaN                      NaN             \n",
       "208  NaN                      NaN             \n",
       "209  NaN                      NaN             \n",
       "221  NaN                      NaN             \n",
       "222  NaN                      NaN             \n",
       "223  NaN                      NaN             \n",
       "224  NaN                      NaN             \n",
       "229  NaN                      NaN             \n",
       "230  NaN                      NaN             \n",
       "231  NaN                      NaN             \n",
       "234  NaN                      NaN             \n",
       "235  NaN                      NaN             \n",
       "238  NaN                      NaN             \n",
       "239  NaN                      NaN             \n",
       "240  NaN                      NaN             \n",
       "241  NaN                      NaN             \n",
       "243  NaN                      NaN             \n",
       "244  NaN                      NaN             \n",
       "246  NaN                      NaN             \n",
       "247  NaN                      NaN             "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No deben salir países de verdad nulos, solo agrupaciones internacionales o zonas francas\n",
    "# En caso de que salgan países nulos, se deben agregar al modelo relacional\n",
    "df_usd_long_paises_expo[df_usd_long_paises_expo['COUNTRY_OR_AREA'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PAIS_DESTINO</th>\n",
       "      <th>PAIS_LLAVE_EXPORTACIONES</th>\n",
       "      <th>COUNTRY_OR_AREA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>ZF de Barranquilla</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>ZF de Bogotá</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>ZF de Candelaria Cartagena</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>ZF de Cartagena</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>ZF de Pacifico Cali</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>ZF de Palmaseca Cali</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>ZF de Rio negro Medellín</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>ZF Santander</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>ZFP de Tocancipá</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>ZFP Internacional de Pereira</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>ZFP Internacional del Valle de Aburrá ZOFIVA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>ZFP Intexzona</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>ZFP La Cayena</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>ZFP Parque Central</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>ZFP Parque Industrial Dexton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>ZFP Surcolombiana</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>ZFPE Bio D Facatativá</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>ZFPE Gyplac</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>ZFPE Puerto Industrial Agua Dulce Dirección de Aduanas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>ZF del Eje Cafetero</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>ZF Metropolitana</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>ZFPE Bionergy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>ZFPE Kcag</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>ZFP de Occidente</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>ZFP Tayrona</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>ZFPE Biocombustibles Sostenibles del Caribe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>ZFP Zofrandina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>ZFPE Argos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>ZF de Santa Marta</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>ZFP Internacional del Atlántico</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>ZFPE de Servicios Sociedad Portuaria Regional de Santa Marta</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>ZFPE Femsa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>ZF de Palermo Atlántico</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>ZFPE Puerto Mamonal Sociedad Portuaria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>ZFP Conjunto Industrial Parque Sur</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>ZFP del Cauca</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     PAIS_DESTINO  \\\n",
       "191  ZF de Barranquilla                                             \n",
       "192  ZF de Bogotá                                                   \n",
       "193  ZF de Candelaria Cartagena                                     \n",
       "194  ZF de Cartagena                                                \n",
       "195  ZF de Pacifico Cali                                            \n",
       "196  ZF de Palmaseca Cali                                           \n",
       "197  ZF de Rio negro Medellín                                       \n",
       "198  ZF Santander                                                   \n",
       "199  ZFP de Tocancipá                                               \n",
       "200  ZFP Internacional de Pereira                                   \n",
       "201  ZFP Internacional del Valle de Aburrá ZOFIVA                   \n",
       "202  ZFP Intexzona                                                  \n",
       "203  ZFP La Cayena                                                  \n",
       "204  ZFP Parque Central                                             \n",
       "205  ZFP Parque Industrial Dexton                                   \n",
       "206  ZFP Surcolombiana                                              \n",
       "207  ZFPE Bio D Facatativá                                          \n",
       "208  ZFPE Gyplac                                                    \n",
       "209  ZFPE Puerto Industrial Agua Dulce Dirección de Aduanas         \n",
       "221  ZF del Eje Cafetero                                            \n",
       "222  ZF Metropolitana                                               \n",
       "223  ZFPE Bionergy                                                  \n",
       "224  ZFPE Kcag                                                      \n",
       "229  ZFP de Occidente                                               \n",
       "230  ZFP Tayrona                                                    \n",
       "231  ZFPE Biocombustibles Sostenibles del Caribe                    \n",
       "234  ZFP Zofrandina                                                 \n",
       "235  ZFPE Argos                                                     \n",
       "238  ZF de Santa Marta                                              \n",
       "239  ZFP Internacional del Atlántico                                \n",
       "240  ZFPE de Servicios Sociedad Portuaria Regional de Santa Marta   \n",
       "241  ZFPE Femsa                                                     \n",
       "243  ZF de Palermo Atlántico                                        \n",
       "244  ZFPE Puerto Mamonal Sociedad Portuaria                         \n",
       "246  ZFP Conjunto Industrial Parque Sur                             \n",
       "247  ZFP del Cauca                                                  \n",
       "\n",
       "    PAIS_LLAVE_EXPORTACIONES COUNTRY_OR_AREA  \n",
       "191  NaN                      NaN             \n",
       "192  NaN                      NaN             \n",
       "193  NaN                      NaN             \n",
       "194  NaN                      NaN             \n",
       "195  NaN                      NaN             \n",
       "196  NaN                      NaN             \n",
       "197  NaN                      NaN             \n",
       "198  NaN                      NaN             \n",
       "199  NaN                      NaN             \n",
       "200  NaN                      NaN             \n",
       "201  NaN                      NaN             \n",
       "202  NaN                      NaN             \n",
       "203  NaN                      NaN             \n",
       "204  NaN                      NaN             \n",
       "205  NaN                      NaN             \n",
       "206  NaN                      NaN             \n",
       "207  NaN                      NaN             \n",
       "208  NaN                      NaN             \n",
       "209  NaN                      NaN             \n",
       "221  NaN                      NaN             \n",
       "222  NaN                      NaN             \n",
       "223  NaN                      NaN             \n",
       "224  NaN                      NaN             \n",
       "229  NaN                      NaN             \n",
       "230  NaN                      NaN             \n",
       "231  NaN                      NaN             \n",
       "234  NaN                      NaN             \n",
       "235  NaN                      NaN             \n",
       "238  NaN                      NaN             \n",
       "239  NaN                      NaN             \n",
       "240  NaN                      NaN             \n",
       "241  NaN                      NaN             \n",
       "243  NaN                      NaN             \n",
       "244  NaN                      NaN             \n",
       "246  NaN                      NaN             \n",
       "247  NaN                      NaN             "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No deben salir países de verdad nulos, solo agrupaciones internacionales o zonas francas\n",
    "# En caso de que salgan países nulos, se deben agregar al modelo relacional\n",
    "df_kg_long_paises_expo[df_kg_long_paises_expo['COUNTRY_OR_AREA'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Crear totales de control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_totales(df, df_parametros, valor_col):\n",
    "    \"\"\"\n",
    "    Genera un DataFrame con los totales agrupados para los años especificados en df_parametros.\n",
    "    \n",
    "    Parámetros:\n",
    "    df (DataFrame): DataFrame original que contiene los datos a agrupar.\n",
    "    df_parametros (DataFrame): DataFrame que contiene los años 'T_1_YEAR' y 'T_YEAR'.\n",
    "    valor_col (str): Nombre de la columna que contiene los valores que se van a sumar.\n",
    "    \n",
    "    Retorna:\n",
    "    DataFrame con los totales sumados.\n",
    "    \"\"\"\n",
    "    # Sumar los valores para el año T_1_YEAR\n",
    "    suma_t_1 = df[df['YEAR'] == df_parametros['T_1_YEAR'].iloc[0]][valor_col].sum()\n",
    "    \n",
    "    # Sumar los valores para el año T_YEAR\n",
    "    suma_t = df[df['YEAR'] == df_parametros['T_YEAR'].iloc[0]][valor_col].sum()\n",
    "    \n",
    "    # Crear el DataFrame con los resultados\n",
    "    df_total_usd = pd.DataFrame({\n",
    "        'TABLA' : ['TOTAL'],\n",
    "        'CATEGORIA': ['TOTAL'],\n",
    "        'SUMA_USD_T_1': [suma_t_1],\n",
    "        'SUMA_USD_T': [suma_t]\n",
    "    })\n",
    "\n",
    "    # Crear sumas de control\n",
    "    suma_t_1_control =  df_total_usd['SUMA_USD_T_1']\n",
    "    suma_t_control =  df_total_usd['SUMA_USD_T']\n",
    "      \n",
    "    return suma_t_1_control, suma_t_control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Totales de control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOTALES USD Y KG\n",
    "# Estos totales se calculan con la misma lógica al interior de las funciones de la siguiente sección para realizar la verificación.\n",
    "\n",
    "# Cerrado\n",
    "# USD TOTAL\n",
    "suma_total_usd_t_1_control_cerrado, suma_total_usd_t_control_cerrado = generar_totales(df=df_usd_long, df_parametros=TEMP_PARAMETROS_CERRADO, valor_col='VALOR_USD')\n",
    "# USD NME\n",
    "suma_total_usd_t_1_nme_control_cerrado, suma_total_usd_t_nme_control_cerrado = generar_totales(df=df_usd_long[df_usd_long['TIPO']=='No Mineras'], df_parametros=TEMP_PARAMETROS_CERRADO, valor_col='VALOR_USD')\n",
    "# PESO TOTAL\n",
    "suma_total_kg_t_1_control_cerrado, suma_total_kg_t_control_cerrado = generar_totales(df=df_kg_long, df_parametros=TEMP_PARAMETROS_CERRADO, valor_col='PESO_KG')\n",
    "# PESO MINERAS\n",
    "suma_total_kg_t_1_mineras_control_cerrado, suma_total_kg_t_mineras_control_cerrado = generar_totales(df=df_kg_long[(df_kg_long['TIPO']=='Mineras') & (df_kg_long['MEDIO_TRANSPORTE'] != 'Otras vías')], df_parametros=TEMP_PARAMETROS_CERRADO, valor_col='PESO_KG')\n",
    "# PESO NME\n",
    "suma_total_kg_t_1_nme_control_cerrado, suma_total_kg_t_nme_control_cerrado = generar_totales(df=df_kg_long[(df_kg_long['TIPO']=='No Mineras') & (df_kg_long['MEDIO_TRANSPORTE'] != 'Otras vías')], df_parametros=TEMP_PARAMETROS_CERRADO, valor_col='PESO_KG')\n",
    "\n",
    "\n",
    "# Corrido\n",
    "# USD TOTAL\n",
    "suma_total_usd_t_1_control_corrido, suma_total_usd_t_control_corrido = generar_totales(df=df_usd_long, df_parametros=TEMP_PARAMETROS_CORRIDO, valor_col='VALOR_USD')\n",
    "# USD NME\n",
    "suma_total_usd_t_1_nme_control_corrido, suma_total_usd_t_nme_control_corrido = generar_totales(df=df_usd_long[df_usd_long['TIPO']=='No Mineras'], df_parametros=TEMP_PARAMETROS_CORRIDO, valor_col='VALOR_USD')\n",
    "# PESO TOTAL\n",
    "suma_total_kg_t_1_control_corrido, suma_total_kg_t_control_corrido = generar_totales(df=df_kg_long, df_parametros=TEMP_PARAMETROS_CORRIDO, valor_col='PESO_KG')\n",
    "# PESO MINERAS\n",
    "suma_total_kg_t_1_mineras_control_corrido, suma_total_kg_t_mineras_control_corrido = generar_totales(df=df_kg_long[(df_kg_long['TIPO']=='Mineras') & (df_kg_long['MEDIO_TRANSPORTE'] != 'Otras vías')], df_parametros=TEMP_PARAMETROS_CORRIDO, valor_col='PESO_KG')\n",
    "# PESO NME\n",
    "suma_total_kg_t_1_nme_control_corrido, suma_total_kg_t_nme_control_corrido = generar_totales(df=df_kg_long[(df_kg_long['TIPO']=='No Mineras') & (df_kg_long['MEDIO_TRANSPORTE'] != 'Otras vías')], df_parametros=TEMP_PARAMETROS_CORRIDO, valor_col='PESO_KG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Crear agrupaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_tabla_agrupada(df, agrupacion, unidad, tabla, categoria_col, valor_col, temp_parametros):\n",
    "    \"\"\"\n",
    "    Genera una tabla agregada con métricas financieras de un DataFrame de exportaciones, agrupando por diferentes categorías.\n",
    "    \n",
    "    Optimizada para reducir el tiempo de ejecución filtrando previamente y usando operaciones vectorizadas.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Filtrar los datos por los dos años antes de agrupar para evitar filtrado en cada agregación\n",
    "    df_t1 = df[df['YEAR'] == temp_parametros['T_1_YEAR'].iloc[0]]\n",
    "    df_t = df[df['YEAR'] == temp_parametros['T_YEAR'].iloc[0]]\n",
    "\n",
    "    # Determinar las columnas de agrupación\n",
    "    if categoria_col == unidad:\n",
    "        group_cols = [unidad]\n",
    "    else:\n",
    "        group_cols = [categoria_col] + ([unidad] if unidad in df.columns else [])\n",
    "    \n",
    "    # Agrupar para cada año por separado\n",
    "    suma_t1 = df_t1.groupby(group_cols)[valor_col].sum().reset_index(name='SUMA_USD_T_1')\n",
    "    suma_t = df_t.groupby(group_cols)[valor_col].sum().reset_index(name='SUMA_USD_T')\n",
    "\n",
    "    # Unir los resultados de los dos años\n",
    "    df_agrupado = pd.merge(suma_t1, suma_t, on=group_cols, how='outer').fillna(0)\n",
    "\n",
    "    # Agregar las columnas 'AGRUPACION' y 'TABLA'\n",
    "    df_agrupado['AGRUPACION'] = agrupacion\n",
    "    df_agrupado['TABLA'] = tabla\n",
    "\n",
    "    # Agregar la columna 'UNIDAD'\n",
    "    if unidad in df.columns:\n",
    "        df_agrupado['UNIDAD'] = df_agrupado[unidad]\n",
    "    else:\n",
    "        df_agrupado['UNIDAD'] = unidad\n",
    "\n",
    "    # Asignar la columna 'CATEGORIA'\n",
    "    if categoria_col == unidad:\n",
    "        df_agrupado['CATEGORIA'] = df_agrupado['UNIDAD']\n",
    "    else:\n",
    "        df_agrupado = df_agrupado.rename(columns={categoria_col: 'CATEGORIA'})\n",
    "\n",
    "    # Calcular las diferencias absoluta y porcentual utilizando operaciones vectorizadas\n",
    "    df_agrupado['DIFERENCIA_ABSOLUTA'] = df_agrupado['SUMA_USD_T'] - df_agrupado['SUMA_USD_T_1']\n",
    "    df_agrupado['DIFERENCIA_PORCENTUAL'] = np.where(\n",
    "        df_agrupado['SUMA_USD_T_1'] == 0,\n",
    "        np.where(df_agrupado['SUMA_USD_T'] > 0, 100, np.where(df_agrupado['SUMA_USD_T'] == 0, 0, -100)),\n",
    "        (df_agrupado['DIFERENCIA_ABSOLUTA'] / df_agrupado['SUMA_USD_T_1']) * 100\n",
    "    )\n",
    "\n",
    "    # Reordenar las columnas\n",
    "    df_agrupado = df_agrupado[['AGRUPACION', 'UNIDAD', 'TABLA', 'CATEGORIA', 'SUMA_USD_T_1', 'SUMA_USD_T', 'DIFERENCIA_ABSOLUTA', 'DIFERENCIA_PORCENTUAL']]\n",
    "\n",
    "    return df_agrupado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_tabla_totales(df, agrupacion, unidad, valor_col, temp_parametros):\n",
    "    \"\"\"\n",
    "    Genera una tabla que contiene los totales de valores financieros agrupados por una unidad específica,\n",
    "    o un total general si 'unidad' es una cadena estática. Calcula las diferencias absolutas y porcentuales\n",
    "    entre dos períodos de tiempo definidos.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df (pd.DataFrame): DataFrame con los datos a procesar.\n",
    "    agrupacion (str): Nombre de la agrupación para la columna 'AGRUPACION'.\n",
    "    unidad (str): Nombre de la columna a usar como 'UNIDAD', o un valor constante si es estático.\n",
    "    valor_col (str): Nombre de la columna con los valores numéricos a sumar.\n",
    "    temp_parametros (pd.DataFrame): DataFrame con los parámetros de tiempo, columnas 'T_1_YEAR' y 'T_YEAR'.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame: DataFrame con las columnas:\n",
    "        - 'AGRUPACION': Nivel de agrupación.\n",
    "        - 'UNIDAD': Nombre de la unidad o cadena estática.\n",
    "        - 'TABLA': 'TOTAL'.\n",
    "        - 'CATEGORIA': 'TOTAL'.\n",
    "        - 'SUMA_USD_T_1': Suma de los valores para T_1_YEAR.\n",
    "        - 'SUMA_USD_T': Suma de los valores para T_YEAR.\n",
    "        - 'DIFERENCIA_ABSOLUTA': Diferencia entre T_YEAR y T_1_YEAR.\n",
    "        - 'DIFERENCIA_PORCENTUAL': Cambio porcentual entre T_YEAR y T_1_YEAR.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Filtrar de antemano los datos por los años T_1_YEAR y T_YEAR para mejorar eficiencia\n",
    "    df_t_1 = df[df['YEAR'] == temp_parametros['T_1_YEAR'].iloc[0]]\n",
    "    df_t = df[df['YEAR'] == temp_parametros['T_YEAR'].iloc[0]]\n",
    "\n",
    "    # Si 'unidad' es una columna dinámica\n",
    "    if unidad in df.columns:\n",
    "        # Agrupar por 'unidad' y sumar los valores\n",
    "        suma_t_1 = df_t_1.groupby(unidad)[valor_col].sum().reset_index(name='SUMA_USD_T_1')\n",
    "        suma_t = df_t.groupby(unidad)[valor_col].sum().reset_index(name='SUMA_USD_T')\n",
    "        \n",
    "        # Combinar los resultados por unidad\n",
    "        df_totales = pd.merge(suma_t_1, suma_t, on=unidad, how='outer').fillna(0)\n",
    "        df_totales['UNIDAD'] = df_totales[unidad]\n",
    "    else:\n",
    "        # Si 'unidad' es un valor estático, calcular los totales sin agrupación\n",
    "        suma_t_1 = df_t_1[valor_col].sum()\n",
    "        suma_t = df_t[valor_col].sum()\n",
    "        \n",
    "        df_totales = pd.DataFrame({\n",
    "            'AGRUPACION': [agrupacion],\n",
    "            'UNIDAD': [unidad],\n",
    "            'TABLA': ['TOTAL'],\n",
    "            'CATEGORIA': ['TOTAL'],\n",
    "            'SUMA_USD_T_1': [suma_t_1],\n",
    "            'SUMA_USD_T': [suma_t]\n",
    "        })\n",
    "\n",
    "    # Agregar columnas 'AGRUPACION', 'TABLA', y 'CATEGORIA' si es una columna dinámica\n",
    "    if unidad in df.columns:\n",
    "        df_totales['AGRUPACION'] = agrupacion\n",
    "        df_totales['TABLA'] = 'TOTAL'\n",
    "        df_totales['CATEGORIA'] = 'TOTAL'\n",
    "\n",
    "    # Reordenar las columnas\n",
    "    df_totales = df_totales[['AGRUPACION', 'UNIDAD', 'TABLA', 'CATEGORIA', 'SUMA_USD_T_1', 'SUMA_USD_T']]\n",
    "\n",
    "    # Calcular la diferencia absoluta y la diferencia porcentual usando operaciones vectorizadas\n",
    "    df_totales['DIFERENCIA_ABSOLUTA'] = df_totales['SUMA_USD_T'] - df_totales['SUMA_USD_T_1']\n",
    "    df_totales['DIFERENCIA_PORCENTUAL'] = np.where(\n",
    "        (df_totales['SUMA_USD_T_1'] == 0) & (df_totales['SUMA_USD_T'] > 0), 100,\n",
    "        np.where(\n",
    "            (df_totales['SUMA_USD_T_1'] > 0) & (df_totales['SUMA_USD_T'] == 0), -100,\n",
    "            np.where(\n",
    "                (df_totales['SUMA_USD_T_1'] == 0) & (df_totales['SUMA_USD_T'] == 0), 0,\n",
    "                (df_totales['DIFERENCIA_ABSOLUTA'] / df_totales['SUMA_USD_T_1']) * 100\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return df_totales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_tablas_completas_usd(df, df_control, agrupacion, valor_col, temp_parametros):\n",
    "    \"\"\"\n",
    "    Genera un DataFrame completo con tablas agrupadas y totales para una agrupación específica. La función calcula\n",
    "    los totales financieros de exportaciones, agrupa por diferentes categorías y valida los datos a través de sumas\n",
    "    parciales y totales para verificar la integridad de la información.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame de entrada que contiene los datos de exportaciones con columnas de valores y años preagrupados para velocidad.\n",
    "    df_control (pd.DataFrame): DataFrame de entrada que contiene la base de exportaciones completa sin agrupar en formato long para crear totales de control.\n",
    "    agrupacion (str): Nombre de la agrupación que define las unidades, tablas y categorías (ej. 'CONTINENTES', 'TLCS').\n",
    "    valor_col (str): Nombre de la columna que contiene los valores a sumar (por ejemplo, 'VALOR_USD').\n",
    "    temp_parametros (pd.DataFrame): DataFrame que contiene los parámetros temporales, con las columnas 'T_1_YEAR' \n",
    "                                    y 'T_YEAR', que definen los años a comparar.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Retorna dos DataFrames:\n",
    "        - df_resultado_filtrado: DataFrame con las tablas agrupadas y los totales.\n",
    "        - df_validador_final: DataFrame que contiene los resultados de validación de las sumas parciales y totales.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Definir nombres de las tablas y categorías para agrupar los datos\n",
    "    tablas = ['CONTINENTE', 'DEPARTAMENTOS', 'PAIS', 'SECTORES', 'SUBSECTORES']\n",
    "    categorias = ['CONTINENTE', 'DEPARTAMENTO_ORIGEN', 'PAIS_DESTINO', 'SECTOR', 'SUBSECTOR']\n",
    "\n",
    "    # Crear totales de control para validar la integridad de los datos\n",
    "    # Suma total de exportaciones (USD) para todos los datos\n",
    "    suma_total_usd_t_1_control, suma_total_usd_t_control = generar_totales(df=df_control, df_parametros=temp_parametros, valor_col='VALOR_USD')\n",
    "    # Suma total de exportaciones (USD) para el tipo 'No Mineras'\n",
    "    suma_total_usd_t_1_nme_control, suma_total_usd_t_nme_control = generar_totales(df=df_control[df_control['TIPO']=='No Mineras'], df_parametros=temp_parametros, valor_col='VALOR_USD')\n",
    "    \n",
    "    # Definir la columna que se usará como unidad de agrupación según el valor de 'agrupacion'\n",
    "    if agrupacion == 'CONTINENTES':\n",
    "        unidad = 'CONTINENTE'\n",
    "    elif agrupacion == 'TLCS':\n",
    "        unidad = 'TLCS'\n",
    "    elif agrupacion == 'PAISES':\n",
    "        unidad = 'PAIS_DESTINO'\n",
    "    elif agrupacion == 'DEPARTAMENTOS':\n",
    "        unidad = 'DEPARTAMENTO_ORIGEN'\n",
    "    elif agrupacion == 'HUBS':\n",
    "        unidad = 'HUB'\n",
    "    elif agrupacion == 'COLOMBIA':\n",
    "        unidad = 'COLOMBIA'\n",
    "    else:\n",
    "        raise ValueError(\"Agrupación no reconocida. Por favor, define los parámetros correspondientes.\")\n",
    "\n",
    "    # Inicializar DataFrames vacíos para almacenar los resultados finales y las validaciones\n",
    "    df_resultado_final = pd.DataFrame()\n",
    "    df_validador_final = pd.DataFrame()\n",
    "\n",
    "    # Loop para generar tablas agrupadas por cada combinación de 'tabla' y 'categoria_col'\n",
    "    df_nme = df[df['TIPO']=='No Mineras']\n",
    "    for tabla, categoria_col in zip(tablas, categorias):\n",
    "        print(f\"Agrupación: {agrupacion}, Categoría: {categoria_col}\")\n",
    "        \n",
    "        # Generar la tabla agrupada para la categoría actual\n",
    "        df_agrupada = generar_tabla_agrupada(\n",
    "            df=df_nme,\n",
    "            agrupacion=agrupacion,\n",
    "            unidad=unidad,\n",
    "            tabla=tabla,\n",
    "            categoria_col=categoria_col,\n",
    "            valor_col=valor_col,\n",
    "            temp_parametros=temp_parametros\n",
    "        )\n",
    "        \n",
    "        # Concatenar los resultados al DataFrame final\n",
    "        df_resultado_final = pd.concat([df_resultado_final, df_agrupada], ignore_index=True)\n",
    "\n",
    "        # Validar los datos sumando las columnas 'SUMA_USD_T_1' y 'SUMA_USD_T' para la categoría actual\n",
    "        df_validador = df_agrupada[df_agrupada['TABLA'] == tabla].groupby(['TABLA', 'CATEGORIA'])[['SUMA_USD_T_1', 'SUMA_USD_T']].sum().reset_index()\n",
    "        \n",
    "        # Sumar los valores parciales\n",
    "        suma_parcial_t_1 = df_validador['SUMA_USD_T_1'].sum()\n",
    "        suma_parcial_t = df_validador['SUMA_USD_T'].sum()\n",
    "\n",
    "        # Definir el margen de tolerancia (en este caso, 1)\n",
    "        tolerancia = 1\n",
    "        # Comparación para la primera suma con tolerancia\n",
    "        resultado_t_1 = abs(round(suma_parcial_t_1) - round(suma_total_usd_t_1_nme_control.iloc[0])) <= tolerancia\n",
    "        # Comparación para la segunda suma con tolerancia\n",
    "        resultado_t = abs(round(suma_parcial_t) - round(suma_total_usd_t_nme_control.iloc[0])) <= tolerancia\n",
    "        \n",
    "        # Mostrar los resultados de la validación\n",
    "        print(resultado_t_1, resultado_t)\n",
    "        \n",
    "        # Guardar los resultados de la validación en un DataFrame\n",
    "        df_resultados_validacion = pd.DataFrame({\n",
    "            'AGRUPACION': [agrupacion],\n",
    "            'UNIDAD': [unidad],\n",
    "            'TABLA': [tabla],\n",
    "            'CATEGORIA': [categoria_col],\n",
    "            'SUMA_USD_T_1': [resultado_t_1],\n",
    "            'SUMA_USD_T': [resultado_t]\n",
    "        })\n",
    "        \n",
    "        # Concatenar las validaciones al DataFrame final de validación\n",
    "        df_validador_final = pd.concat([df_validador_final, df_resultados_validacion], ignore_index=True)\n",
    "\n",
    "    # Generar la tabla de totales y agregarla al DataFrame final\n",
    "    print(f\"Agregando totales - Agrupación: {agrupacion}, Unidad: {unidad}\")\n",
    "    totales = generar_tabla_totales(\n",
    "        df=df,\n",
    "        agrupacion=agrupacion,\n",
    "        unidad=unidad,\n",
    "        valor_col=valor_col,\n",
    "        temp_parametros=temp_parametros\n",
    "    )\n",
    "    df_resultado_final = pd.concat([df_resultado_final, totales], ignore_index=True)\n",
    "\n",
    "    # Validar los datos de los totales\n",
    "    suma_parcial_t_1 = totales['SUMA_USD_T_1'].sum()\n",
    "    suma_parcial_t = totales['SUMA_USD_T'].sum()\n",
    "    \n",
    "    # Definir el margen de tolerancia (en este caso, 1)\n",
    "    tolerancia = 1\n",
    "    # Comparación para la primera suma con tolerancia\n",
    "    resultado_t_1 = abs(round(suma_parcial_t_1) - round(suma_total_usd_t_1_control.iloc[0])) <= tolerancia\n",
    "    # Comparación para la segunda suma con tolerancia\n",
    "    resultado_t = abs(round(suma_parcial_t) - round(suma_total_usd_t_control.iloc[0])) <= tolerancia\n",
    "\n",
    "    \n",
    "    # Mostrar los resultados de la validación\n",
    "    print(resultado_t_1, resultado_t)\n",
    "    \n",
    "    # Guardar los resultados de la validación para los totales\n",
    "    df_resultados_validacion = pd.DataFrame({\n",
    "        'AGRUPACION': [agrupacion],\n",
    "        'UNIDAD': [unidad],\n",
    "        'TABLA': ['TOTAL'],\n",
    "        'CATEGORIA': ['TOTAL'],\n",
    "        'SUMA_USD_T_1': [resultado_t_1],\n",
    "        'SUMA_USD_T': [resultado_t]\n",
    "    })\n",
    "    df_validador_final = pd.concat([df_validador_final, df_resultados_validacion], ignore_index=True)\n",
    "   \n",
    "    # Generar la tabla de tipos y agregarla al DataFrame final\n",
    "    print(f\"Agregando tipos - Agrupación: {agrupacion}, Unidad: {unidad}\")\n",
    "    # Definir nombres de las tablas y categorías para agrupar los datos\n",
    "    tabla_tipo = 'TIPOS'\n",
    "    categoria_tipo = 'TIPO'\n",
    "    tipos = generar_tabla_agrupada(df=df, \n",
    "                           agrupacion=agrupacion, \n",
    "                           unidad=unidad, \n",
    "                           tabla=tabla_tipo, \n",
    "                           categoria_col=categoria_tipo, \n",
    "                           valor_col=valor_col, \n",
    "                           temp_parametros=temp_parametros) \n",
    "    df_resultado_final = pd.concat([df_resultado_final, tipos], ignore_index=True)\n",
    "    # Validar los datos de los totales\n",
    "    suma_parcial_t_1 = tipos['SUMA_USD_T_1'].sum()\n",
    "    suma_parcial_t = tipos['SUMA_USD_T'].sum()\n",
    "    \n",
    "    # Definir el margen de tolerancia (en este caso, 1)\n",
    "    tolerancia = 1\n",
    "    # Comparación para la primera suma con tolerancia\n",
    "    resultado_t_1 = abs(round(suma_parcial_t_1) - round(suma_total_usd_t_1_control.iloc[0])) <= tolerancia\n",
    "    # Comparación para la segunda suma con tolerancia\n",
    "    resultado_t = abs(round(suma_parcial_t) - round(suma_total_usd_t_control.iloc[0])) <= tolerancia\n",
    "\n",
    "    # Mostrar los resultados de la validación\n",
    "    print(resultado_t_1, resultado_t)\n",
    "    \n",
    "    # Guardar los resultados de la validación para los totales\n",
    "    df_resultados_validacion = pd.DataFrame({\n",
    "        'AGRUPACION': [agrupacion],\n",
    "        'UNIDAD': [unidad],\n",
    "        'TABLA': [tabla_tipo],\n",
    "        'CATEGORIA': [categoria_tipo],\n",
    "        'SUMA_USD_T_1': [resultado_t_1],\n",
    "        'SUMA_USD_T': [resultado_t]\n",
    "    })\n",
    "    df_validador_final = pd.concat([df_validador_final, df_resultados_validacion], ignore_index=True)\n",
    "\n",
    "    # Eliminar filas donde los valores en ambas columnas de sumas sean cero\n",
    "    condicion_1 = (df_resultado_final['SUMA_USD_T_1'] == 0) & (df_resultado_final['SUMA_USD_T'] == 0)\n",
    "    df_resultado_filtrado = df_resultado_final[~condicion_1].reset_index(drop=True)\n",
    "\n",
    "    # Retornar los DataFrames finales de agrupación y validación\n",
    "    return df_resultado_filtrado, df_validador_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_tablas_completas_kg(df, df_control, agrupacion, valor_col, temp_parametros):\n",
    "    \"\"\"\n",
    "    Genera un DataFrame completo con tablas agrupadas y totales para una agrupación específica. La función calcula\n",
    "    los totales financieros de exportaciones, agrupa por diferentes categorías y valida los datos a través de sumas\n",
    "    parciales y totales para verificar la integridad de la información.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame de entrada que contiene los datos de exportaciones con columnas de valores y años preagrupados para velocidad.\n",
    "    df_control (pd.DataFrame): DataFrame de entrada que contiene la base de exportaciones completa sin agrupar en formato long para crear totales de control.\n",
    "    agrupacion (str): Nombre de la agrupación que define las unidades, tablas y categorías (ej. 'CONTINENTES', 'TLCS').\n",
    "    valor_col (str): Nombre de la columna que contiene los valores a sumar (por ejemplo, 'VALOR_USD', 'PESO_KG').\n",
    "    temp_parametros (pd.DataFrame): DataFrame que contiene los parámetros temporales, con las columnas 'T_1_YEAR' \n",
    "                                    y 'T_YEAR', que definen los años a comparar.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Retorna dos DataFrames:\n",
    "        - df_resultado_filtrado: DataFrame con las tablas agrupadas y los totales.\n",
    "        - df_validador_final: DataFrame que contiene los resultados de validación de las sumas parciales y totales.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Definir nombres de las tablas y categorías para agrupar los datos\n",
    "    # Tablas de medios mineros\n",
    "    tablas_mineros = ['MEDIO MINERAS', 'PAIS MINERAS']\n",
    "    categorias_mineros = ['MEDIO_TRANSPORTE', 'PAIS_DESTINO']\n",
    "    # Tablas de medios no mineros\n",
    "    tablas_nme = ['MEDIO NO MINERAS', 'PAIS NO MINERAS']\n",
    "    categorias_nme = ['MEDIO_TRANSPORTE', 'PAIS_DESTINO']\n",
    "\n",
    "    # Crear totales de control para validar la integridad de los datos\n",
    "    # Suma total de exportaciones (KG) para todos los datos\n",
    "    suma_total_kg_t_1_control, suma_total_kg_t_control = generar_totales(df=df_control, df_parametros=temp_parametros, valor_col='PESO_KG')\n",
    "    # Suma total de exportaciones (KG) para el tipo 'No Mineras'\n",
    "    suma_total_kg_t_1_nme_control, suma_total_kg_t_nme_control = generar_totales(df=df_control[df_control['TIPO']=='No Mineras'], df_parametros=temp_parametros, valor_col='PESO_KG')\n",
    "    # Suma total de exportaciones (KG) para el tipo 'Mineras'\n",
    "    suma_total_kg_t_1_mineros_control, suma_total_kg_t_mineros_control = generar_totales(df=df_control[df_control['TIPO']=='Mineras'], df_parametros=temp_parametros, valor_col='PESO_KG')\n",
    "    \n",
    "    # Definir la columna que se usará como unidad de agrupación según el valor de 'agrupacion'\n",
    "    if agrupacion == 'CONTINENTES':\n",
    "        unidad = 'CONTINENTE'\n",
    "    elif agrupacion == 'TLCS':\n",
    "        unidad = 'TLCS'\n",
    "    elif agrupacion == 'PAISES':\n",
    "        unidad = 'PAIS_DESTINO'\n",
    "    elif agrupacion == 'DEPARTAMENTOS':\n",
    "        unidad = 'DEPARTAMENTO_ORIGEN'\n",
    "    elif agrupacion == 'HUBS':\n",
    "        unidad = 'HUB'\n",
    "    elif agrupacion == 'COLOMBIA':\n",
    "        unidad = 'COLOMBIA'\n",
    "    else:\n",
    "        raise ValueError(\"Agrupación no reconocida. Por favor, define los parámetros correspondientes.\")\n",
    "\n",
    "    # Inicializar DataFrames vacíos para almacenar los resultados finales y las validaciones\n",
    "    df_resultado_final = pd.DataFrame()\n",
    "    df_validador_final = pd.DataFrame()\n",
    "\n",
    "    # Medios no mineras\n",
    "    # Loop para generar tablas agrupadas por cada combinación de 'tabla' y 'categoria_col'\n",
    "    df_nme = df[df['TIPO']=='No Mineras']\n",
    "    for tabla, categoria_col in zip(tablas_nme, categorias_nme):\n",
    "        print(f\"Agrupación: {agrupacion}, Categoría: {categoria_col}\")\n",
    "        \n",
    "        # Generar la tabla agrupada para la categoría actual\n",
    "        df_agrupada = generar_tabla_agrupada(\n",
    "            df=df_nme,\n",
    "            agrupacion=agrupacion,\n",
    "            unidad=unidad,\n",
    "            tabla=tabla,\n",
    "            categoria_col=categoria_col,\n",
    "            valor_col=valor_col,\n",
    "            temp_parametros=temp_parametros\n",
    "        )\n",
    "        \n",
    "        # Concatenar los resultados al DataFrame final\n",
    "        df_resultado_final = pd.concat([df_resultado_final, df_agrupada], ignore_index=True)\n",
    "\n",
    "        # Validar los datos sumando las columnas 'SUMA_USD_T_1' y 'SUMA_USD_T' para la categoría actual\n",
    "        df_validador = df_agrupada[df_agrupada['TABLA'] == tabla].groupby(['TABLA', 'CATEGORIA'])[['SUMA_USD_T_1', 'SUMA_USD_T']].sum().reset_index()\n",
    "        \n",
    "        # Sumar los valores parciales\n",
    "        suma_parcial_t_1 = df_validador['SUMA_USD_T_1'].sum()\n",
    "        suma_parcial_t = df_validador['SUMA_USD_T'].sum()\n",
    "\n",
    "        # Definir el margen de tolerancia (en este caso, 1)\n",
    "        tolerancia = 1\n",
    "        # Comparación para la primera suma con tolerancia\n",
    "        resultado_t_1 = abs(round(suma_parcial_t_1) - round(suma_total_kg_t_1_nme_control.iloc[0])) <= tolerancia\n",
    "        # Comparación para la segunda suma con tolerancia\n",
    "        resultado_t = abs(round(suma_parcial_t) - round(suma_total_kg_t_nme_control.iloc[0])) <= tolerancia\n",
    "        \n",
    "        # Mostrar los resultados de la validación\n",
    "        print(resultado_t_1, resultado_t)\n",
    "        \n",
    "        # Guardar los resultados de la validación en un DataFrame\n",
    "        df_resultados_validacion = pd.DataFrame({\n",
    "            'AGRUPACION': [agrupacion],\n",
    "            'UNIDAD': [unidad],\n",
    "            'TABLA': [tabla],\n",
    "            'CATEGORIA': [categoria_col],\n",
    "            'SUMA_USD_T_1': [resultado_t_1],\n",
    "            'SUMA_USD_T': [resultado_t]\n",
    "        })\n",
    "        \n",
    "        # Concatenar las validaciones al DataFrame final de validación\n",
    "        df_validador_final = pd.concat([df_validador_final, df_resultados_validacion], ignore_index=True)\n",
    "\n",
    "    # Medios mineras\n",
    "    # Loop para generar tablas agrupadas por cada combinación de 'tabla' y 'categoria_col'\n",
    "    df_mineros = df[df['TIPO']=='Mineras']\n",
    "    for tabla, categoria_col in zip(tablas_mineros, categorias_mineros):\n",
    "        print(f\"Agrupación: {agrupacion}, Categoría: {categoria_col}\")\n",
    "        \n",
    "        # Generar la tabla agrupada para la categoría actual\n",
    "        df_agrupada = generar_tabla_agrupada(\n",
    "            df=df_mineros,\n",
    "            agrupacion=agrupacion,\n",
    "            unidad=unidad,\n",
    "            tabla=tabla,\n",
    "            categoria_col=categoria_col,\n",
    "            valor_col=valor_col,\n",
    "            temp_parametros=temp_parametros\n",
    "        )\n",
    "        \n",
    "        # Concatenar los resultados al DataFrame final\n",
    "        df_resultado_final = pd.concat([df_resultado_final, df_agrupada], ignore_index=True)\n",
    "\n",
    "        # Validar los datos sumando las columnas 'SUMA_USD_T_1' y 'SUMA_USD_T' para la categoría actual\n",
    "        df_validador = df_agrupada[df_agrupada['TABLA'] == tabla].groupby(['TABLA', 'CATEGORIA'])[['SUMA_USD_T_1', 'SUMA_USD_T']].sum().reset_index()\n",
    "        \n",
    "        # Sumar los valores parciales\n",
    "        suma_parcial_t_1 = df_validador['SUMA_USD_T_1'].sum()\n",
    "        suma_parcial_t = df_validador['SUMA_USD_T'].sum()\n",
    "\n",
    "        # Definir el margen de tolerancia (en este caso, 1)\n",
    "        tolerancia = 1\n",
    "        # Comparación para la primera suma con tolerancia\n",
    "        resultado_t_1 = abs(round(suma_parcial_t_1) - round(suma_total_kg_t_1_mineros_control.iloc[0])) <= tolerancia\n",
    "        # Comparación para la segunda suma con tolerancia\n",
    "        resultado_t = abs(round(suma_parcial_t) - round(suma_total_kg_t_mineros_control.iloc[0])) <= tolerancia\n",
    "        \n",
    "        # Mostrar los resultados de la validación\n",
    "        print(resultado_t_1, resultado_t)\n",
    "        \n",
    "        # Guardar los resultados de la validación en un DataFrame\n",
    "        df_resultados_validacion = pd.DataFrame({\n",
    "            'AGRUPACION': [agrupacion],\n",
    "            'UNIDAD': [unidad],\n",
    "            'TABLA': [tabla],\n",
    "            'CATEGORIA': [categoria_col],\n",
    "            'SUMA_USD_T_1': [resultado_t_1],\n",
    "            'SUMA_USD_T': [resultado_t]\n",
    "        })\n",
    "        \n",
    "        # Concatenar las validaciones al DataFrame final de validación\n",
    "        df_validador_final = pd.concat([df_validador_final, df_resultados_validacion], ignore_index=True)\n",
    "\n",
    "\n",
    "    # Generar la tabla de totales y agregarla al DataFrame final\n",
    "    print(f\"Agregando totales - Agrupación: {agrupacion}, Unidad: {unidad}\")\n",
    "    totales = generar_tabla_totales(\n",
    "        df=df,\n",
    "        agrupacion=agrupacion,\n",
    "        unidad=unidad,\n",
    "        valor_col=valor_col,\n",
    "        temp_parametros=temp_parametros\n",
    "    )\n",
    "    df_resultado_final = pd.concat([df_resultado_final, totales], ignore_index=True)\n",
    "\n",
    "    # Validar los datos de los totales\n",
    "    suma_parcial_t_1 = totales['SUMA_USD_T_1'].sum()\n",
    "    suma_parcial_t = totales['SUMA_USD_T'].sum()\n",
    "    \n",
    "    # Definir el margen de tolerancia (en este caso, 1)\n",
    "    tolerancia = 1\n",
    "    # Comparación para la primera suma con tolerancia\n",
    "    resultado_t_1 = abs(round(suma_parcial_t_1) - round(suma_total_kg_t_1_control.iloc[0])) <= tolerancia\n",
    "    # Comparación para la segunda suma con tolerancia\n",
    "    resultado_t = abs(round(suma_parcial_t) - round(suma_total_kg_t_control.iloc[0])) <= tolerancia\n",
    "\n",
    "    \n",
    "    # Mostrar los resultados de la validación\n",
    "    print(resultado_t_1, resultado_t)\n",
    "    \n",
    "    # Guardar los resultados de la validación para los totales\n",
    "    df_resultados_validacion = pd.DataFrame({\n",
    "        'AGRUPACION': [agrupacion],\n",
    "        'UNIDAD': [unidad],\n",
    "        'TABLA': ['TOTAL'],\n",
    "        'CATEGORIA': ['TOTAL'],\n",
    "        'SUMA_USD_T_1': [resultado_t_1],\n",
    "        'SUMA_USD_T': [resultado_t]\n",
    "    })\n",
    "    df_validador_final = pd.concat([df_validador_final, df_resultados_validacion], ignore_index=True)\n",
    "   \n",
    "    # Generar la tabla de tipos y agregarla al DataFrame final\n",
    "    print(f\"Agregando tipos - Agrupación: {agrupacion}, Unidad: {unidad}\")\n",
    "    # Definir nombres de las tablas y categorías para agrupar los datos\n",
    "    tabla_tipo = 'TIPOS'\n",
    "    categoria_tipo = 'TIPO'\n",
    "    tipos = generar_tabla_agrupada(df=df, \n",
    "                           agrupacion=agrupacion, \n",
    "                           unidad=unidad, \n",
    "                           tabla=tabla_tipo, \n",
    "                           categoria_col=categoria_tipo, \n",
    "                           valor_col=valor_col, \n",
    "                           temp_parametros=temp_parametros) \n",
    "    df_resultado_final = pd.concat([df_resultado_final, tipos], ignore_index=True)\n",
    "    # Validar los datos de los totales\n",
    "    suma_parcial_t_1 = tipos['SUMA_USD_T_1'].sum()\n",
    "    suma_parcial_t = tipos['SUMA_USD_T'].sum()\n",
    "    \n",
    "    # Definir el margen de tolerancia (en este caso, 1)\n",
    "    tolerancia = 1\n",
    "    # Comparación para la primera suma con tolerancia\n",
    "    resultado_t_1 = abs(round(suma_parcial_t_1) - round(suma_total_kg_t_1_control.iloc[0])) <= tolerancia\n",
    "    # Comparación para la segunda suma con tolerancia\n",
    "    resultado_t = abs(round(suma_parcial_t) - round(suma_total_kg_t_control.iloc[0])) <= tolerancia\n",
    "\n",
    "    # Mostrar los resultados de la validación\n",
    "    print(resultado_t_1, resultado_t)\n",
    "    \n",
    "    # Guardar los resultados de la validación para los totales\n",
    "    df_resultados_validacion = pd.DataFrame({\n",
    "        'AGRUPACION': [agrupacion],\n",
    "        'UNIDAD': [unidad],\n",
    "        'TABLA': [tabla_tipo],\n",
    "        'CATEGORIA': [categoria_tipo],\n",
    "        'SUMA_USD_T_1': [resultado_t_1],\n",
    "        'SUMA_USD_T': [resultado_t]\n",
    "    })\n",
    "    df_validador_final = pd.concat([df_validador_final, df_resultados_validacion], ignore_index=True)\n",
    "\n",
    "    # Eliminar filas donde los valores en ambas columnas de sumas sean cero\n",
    "    condicion_1 = (df_resultado_final['SUMA_USD_T_1'] == 0) & (df_resultado_final['SUMA_USD_T'] == 0)\n",
    "    df_resultado_filtrado = df_resultado_final[~condicion_1].reset_index(drop=True)\n",
    "\n",
    "    # Retornar los DataFrames finales de agrupación y validación\n",
    "    return df_resultado_filtrado, df_validador_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_agrupacion_nits(df, df_control, temp_parametros, agrupacion, unidad_col, tabla='EMPRESAS'):\n",
    "    \"\"\"\n",
    "    Genera una tabla agregada por la unidad y agrupación especificada, optimizando la eficiencia al filtrar\n",
    "    los años relevantes y usando operaciones vectorizadas. Además, genera un DataFrame de validación para comparar\n",
    "    los totales calculados con un DataFrame de control.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df (pd.DataFrame): DataFrame de entrada con los datos de exportaciones ya filtrados.\n",
    "    df_control (pd.DataFrame): DataFrame de control que contiene la base de exportaciones completa para verificar totales.\n",
    "    temp_parametros (pd.DataFrame): DataFrame con las columnas 'T_1_YEAR' y 'T_YEAR' que definen los años de comparación.\n",
    "    agrupacion (str): Nombre de la agrupación, como 'CONTINENTES', 'DEPARTAMENTOS', 'PAISES' o 'COLOMBIA'.\n",
    "    unidad_col (str): Nombre de la columna a utilizar como unidad, como 'CONTINENTE', 'DEPARTAMENTO_ORIGEN', 'PAIS_DESTINO'.\n",
    "    tabla (str): Nombre de la tabla (por defecto 'EMPRESAS').\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    tuple: Retorna dos DataFrames:\n",
    "        - df_resultado: pd.DataFrame: DataFrame con las columnas 'AGRUPACION', 'UNIDAD', 'TABLA', 'CATEGORIA', 'RAZON_SOCIAL',\n",
    "                                        'SECTOR_ESTRELLA', 'SUMA_USD_T_1', 'SUMA_USD_T'.\n",
    "        - df_resultados_validacion: DataFrame que contiene los resultados de validación de las sumas parciales y totales.\n",
    "    \"\"\"\n",
    "\n",
    "    # Crear totales de control\n",
    "    suma_total_usd_t_1_control, suma_total_usd_t_control = generar_totales(df=df_control, df_parametros=temp_parametros, valor_col='VALOR_USD')\n",
    "\n",
    "    # Obtener los años de comparación\n",
    "    t_1_year = temp_parametros['T_1_YEAR'].iloc[0]\n",
    "    t_year = temp_parametros['T_YEAR'].iloc[0]\n",
    "\n",
    "    # Filtrar el DataFrame solo por los años relevantes (T_1_YEAR y T_YEAR)\n",
    "    df_filtrado = df[df['YEAR'].isin([t_1_year, t_year])]\n",
    "\n",
    "    # Utilizar operaciones vectorizadas en lugar de apply\n",
    "    df_filtrado['SUMA_USD_T_1'] = np.where(df_filtrado['YEAR'] == t_1_year, df_filtrado['VALOR_USD'], 0)\n",
    "    df_filtrado['SUMA_USD_T'] = np.where(df_filtrado['YEAR'] == t_year, df_filtrado['VALOR_USD'], 0)\n",
    "\n",
    "    # Agrupación específica para 'COLOMBIA'\n",
    "    if unidad_col == 'COLOMBIA':\n",
    "        df_agrupado = df_filtrado.groupby(['NIT_EXPORTADOR', 'RAZON_SOCIAL', 'SECTOR_ESTRELLA']).agg(\n",
    "            SUMA_USD_T_1=('SUMA_USD_T_1', 'sum'),\n",
    "            SUMA_USD_T=('SUMA_USD_T', 'sum')\n",
    "        ).reset_index()\n",
    "        df_agrupado['UNIDAD'] = 'COLOMBIA'  # Unidad constante para COLOMBIA\n",
    "\n",
    "    else:\n",
    "        # Agrupación por la unidad especificada\n",
    "        df_agrupado = df_filtrado.groupby([unidad_col, 'NIT_EXPORTADOR', 'RAZON_SOCIAL', 'SECTOR_ESTRELLA']).agg(\n",
    "            SUMA_USD_T_1=('SUMA_USD_T_1', 'sum'),\n",
    "            SUMA_USD_T=('SUMA_USD_T', 'sum')\n",
    "        ).reset_index()\n",
    "        df_agrupado['UNIDAD'] = df_agrupado[unidad_col]  # Agregar la unidad correspondiente\n",
    "\n",
    "    # Agregar columnas AGRUPACION, TABLA y CATEGORIA\n",
    "    df_agrupado['AGRUPACION'] = agrupacion\n",
    "    df_agrupado['TABLA'] = tabla\n",
    "    df_agrupado['CATEGORIA'] = df_agrupado['NIT_EXPORTADOR']\n",
    "\n",
    "    # Reorganizar las columnas para el resultado final\n",
    "    df_resultado = df_agrupado[['AGRUPACION', 'UNIDAD', 'TABLA', 'CATEGORIA', 'RAZON_SOCIAL', 'SECTOR_ESTRELLA', 'SUMA_USD_T_1', 'SUMA_USD_T']]\n",
    "\n",
    "    # Verificar totales\n",
    "    suma_parcial_t_1 = df_resultado['SUMA_USD_T_1'].sum()\n",
    "    suma_parcial_t = df_resultado['SUMA_USD_T'].sum()\n",
    "\n",
    "    # Definir el margen de tolerancia (en este caso, 1)\n",
    "    tolerancia = 1\n",
    "\n",
    "    # Comparación para la primera suma con tolerancia\n",
    "    resultado_t_1 = abs(round(suma_parcial_t_1) - round(suma_total_usd_t_1_control.iloc[0])) <= tolerancia\n",
    "\n",
    "    # Comparación para la segunda suma con tolerancia\n",
    "    resultado_t = abs(round(suma_parcial_t) - round(suma_total_usd_t_control.iloc[0])) <= tolerancia\n",
    "\n",
    "    # Mostrar los resultados de la validación\n",
    "    print(resultado_t_1, resultado_t)\n",
    "\n",
    "    # Guardar los resultados de la validación para los totales\n",
    "    df_resultados_validacion = pd.DataFrame({\n",
    "        'AGRUPACION': [agrupacion],\n",
    "        'SUMA_USD_T_1': [resultado_t_1],\n",
    "        'SUMA_USD_T': [resultado_t]\n",
    "    })\n",
    "\n",
    "    return df_resultado, df_resultados_validacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contar_empresas(df_long, agrupacion, temp_parametros, df_geografia, umbral=10000):\n",
    "    \"\"\"\n",
    "    Función que cuenta el número de empresas (NITs únicos) que superan un umbral de exportaciones, agrupadas por diferentes categorías\n",
    "    como CONTINENTES, DEPARTAMENTOS, PAISES, TLCS, HUBS, etc., para dos períodos de tiempo específicos (T_1_YEAR y T_YEAR).\n",
    "\n",
    "    Parámetros:\n",
    "    -----------\n",
    "    df_long (pd.DataFrame): DataFrame con los datos de exportaciones. \n",
    "    agrupacion (str): Categoría de agrupación, puede ser 'HUBS', 'DEPARTAMENTOS', 'PAISES', 'TLCS', 'CONTINENTES', 'SUB_REGION' o 'COLOMBIA'.\n",
    "    temp_parametros (pd.DataFrame): DataFrame con los parámetros temporales que contienen las columnas 'T_1_YEAR' y 'T_YEAR'.\n",
    "    df_geografia (pd.DataFrame): DataFrame auxiliar con información geográfica adicional, necesario para algunas agrupaciones específicas.\n",
    "    umbral (float): Valor mínimo de exportaciones en USD que debe superar una empresa para ser contada (default: 10000).\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame: DataFrame con el número de empresas (NITs únicos) que superan el umbral, agrupadas por la categoría y los años.\n",
    "    \"\"\"\n",
    "\n",
    "    # Aplicar filtros iniciales:\n",
    "    # Filtrar por empresas \"No Mineras\" en las columnas 'TIPO' y 'TIPO_ESTRELLA'\n",
    "    filtro_tipo = df_long['TIPO'] == \"No Mineras\"\n",
    "    filtro_tipo_estrella = df_long['TIPO_ESTRELLA'] == \"No Mineras\"\n",
    "\n",
    "    # Filtrar por las categorías específicas en la columna 'CADENA_ESTRELLA'\n",
    "    filtro_cadena = df_long['CADENA_ESTRELLA'].isin([\n",
    "        \"Agroalimentos\", \n",
    "        \"Industrias 4.0\", \n",
    "        \"Metalmecánica y Otras Industrias\", \n",
    "        \"Químicos y Ciencias de la Vida\", \n",
    "        \"Sistema Moda\"\n",
    "    ])\n",
    "\n",
    "    # Aplicar los filtros al DataFrame\n",
    "    df_filtrado = df_long[filtro_tipo & filtro_tipo_estrella & filtro_cadena]\n",
    "    \n",
    "    # Definir un diccionario para mapear la agrupación seleccionada a la columna correspondiente\n",
    "    column_map = {\n",
    "        'HUBS': 'HUB',\n",
    "        'DEPARTAMENTOS': 'DPTO_MAS_EXPORTA_ESTRELLA',\n",
    "        'PAISES': 'PAIS_DESTINO',\n",
    "        'TLCS': 'TLCS',\n",
    "        'CONTINENTES': 'CONTINENTE',\n",
    "        'COLOMBIA': 'NIT_EXPORTADOR',  # Para 'COLOMBIA', el conteo se hace por NIT_EXPORTADOR\n",
    "        'SUB_REGION': ''  # SUB_REGION requiere un manejo especial más adelante\n",
    "    }\n",
    "\n",
    "    # Verificar si la agrupación seleccionada es válida\n",
    "    if agrupacion not in column_map:\n",
    "        raise ValueError(f\"Agrupación {agrupacion} no es válida. Debe ser una de {list(column_map.keys())}\")\n",
    "    \n",
    "    # Obtener la columna de agrupación adecuada\n",
    "    agrupacion_col = column_map[agrupacion]\n",
    "\n",
    "    # Filtrar registros donde NIT_EXPORTADOR no es -1\n",
    "    df_filtrado = df_filtrado[df_filtrado['NIT_EXPORTADOR'] != '-1']\n",
    "\n",
    "    # Caso especial para 'COLOMBIA': contar por NIT_EXPORTADOR y sumar VALOR_USD\n",
    "    if agrupacion == 'COLOMBIA':\n",
    "        conteo_empresas = pd.DataFrame()\n",
    "        \n",
    "        for year_col in ['T_1_YEAR', 'T_YEAR']:\n",
    "            year = temp_parametros[year_col].iloc[0]  # Obtener el año actual\n",
    "\n",
    "            # Filtrar por el año correspondiente\n",
    "            df_year = df_filtrado[df_filtrado['YEAR'] == year]\n",
    "\n",
    "            # Agrupar por NIT_EXPORTADOR y sumar VALOR_USD\n",
    "            df_sumado = df_year.groupby('NIT_EXPORTADOR')['VALOR_USD'].sum().reset_index()\n",
    "\n",
    "            # Filtrar empresas que superan el umbral de VALOR_USD\n",
    "            df_filtrado_umbral = df_sumado[df_sumado['VALOR_USD'] > umbral]\n",
    "\n",
    "            # Contar NIT_EXPORTADOR únicos\n",
    "            conteo_nit_unicos = df_filtrado_umbral['NIT_EXPORTADOR'].nunique()\n",
    "\n",
    "            # Guardar el resultado en el DataFrame final\n",
    "            conteo_empresas[f'conteo_{year}'] = [conteo_nit_unicos]\n",
    "\n",
    "        # Añadir la columna de agrupación con valor 'COLOMBIA'\n",
    "        conteo_empresas['AGRUPACION'] = 'COLOMBIA'\n",
    "\n",
    "        return conteo_empresas\n",
    "\n",
    "    # Manejo especial para las agrupaciones 'CONTINENTES', 'SUB_REGION', 'TLCS', y 'HUBS'\n",
    "    if agrupacion in ['CONTINENTES', 'SUB_REGION', 'TLCS', 'HUBS']:\n",
    "        if agrupacion == 'CONTINENTES':\n",
    "            # Unir con el DataFrame 'df_geografia' para obtener el código y nombre de la región\n",
    "            df_filtrado = df_filtrado.merge(\n",
    "                df_geografia[['PAIS_LLAVE_EXPORTACIONES', 'REGION_NAME']].drop_duplicates(),\n",
    "                left_on='PAIS_DESTINO', right_on='PAIS_LLAVE_EXPORTACIONES', how='left'\n",
    "            )\n",
    "            agrupacion_col = 'REGION_NAME'\n",
    "        \n",
    "        elif agrupacion == 'SUB_REGION':\n",
    "            # Unir con el DataFrame 'df_geografia' para obtener el código y nombre de la subregión\n",
    "            df_filtrado = df_filtrado.merge(\n",
    "                df_geografia[['PAIS_LLAVE_EXPORTACIONES', 'SUB_REGION_NAME']].drop_duplicates(),\n",
    "                left_on='PAIS_DESTINO', right_on='PAIS_LLAVE_EXPORTACIONES', how='left'\n",
    "            )\n",
    "            agrupacion_col = 'SUB_REGION_NAME'\n",
    "\n",
    "        elif agrupacion == 'TLCS':\n",
    "            # Unir con el DataFrame 'df_geografia' para obtener el código y nombre del TLC\n",
    "            df_filtrado = df_filtrado.merge(\n",
    "                df_geografia[['PAIS_LLAVE_EXPORTACIONES', 'NOMBRE_TLC']].drop_duplicates(),\n",
    "                left_on='PAIS_DESTINO', right_on='PAIS_LLAVE_EXPORTACIONES', how='left'\n",
    "            )\n",
    "            agrupacion_col = 'NOMBRE_TLC'\n",
    "\n",
    "        elif agrupacion == 'HUBS':\n",
    "            # Unir con el DataFrame 'CORR' para obtener el código y nombre del HUB\n",
    "            df_filtrado = df_filtrado.merge(\n",
    "                df_geografia[['PAIS_LLAVE_EXPORTACIONES', 'NOMBRE_HUB']].drop_duplicates(),\n",
    "                left_on='PAIS_DESTINO', right_on='PAIS_LLAVE_EXPORTACIONES', how='left'\n",
    "            )\n",
    "            agrupacion_col = 'NOMBRE_HUB'\n",
    "\n",
    "    # Filtrar por la columna de agrupación seleccionada (que no sea nula) (Departamentos y Países no requiere de un tratamiento especial)\n",
    "    df_filtrado_agrupacion = df_filtrado[df_filtrado[agrupacion_col].notna()]\n",
    "\n",
    "    # Crear un DataFrame vacío para almacenar los resultados\n",
    "    conteo_empresas = pd.DataFrame()\n",
    "\n",
    "    # Obtener todas las agrupaciones posibles en base a la columna de agrupación\n",
    "    agrupaciones_completas = df_filtrado_agrupacion[agrupacion_col].dropna().unique()\n",
    "\n",
    "    # Iterar por los años T_1_YEAR y T_YEAR\n",
    "    for year_col in ['T_1_YEAR', 'T_YEAR']:\n",
    "        year = temp_parametros[year_col].iloc[0]  # Obtener el año actual\n",
    "\n",
    "        # Filtrar por el año actual\n",
    "        df_year = df_filtrado_agrupacion[df_filtrado_agrupacion['YEAR'] == year]\n",
    "\n",
    "        # Agrupar por la columna de agrupación y NIT_EXPORTADOR, y sumar VALOR_USD\n",
    "        df_sumado = df_year.groupby([agrupacion_col, 'NIT_EXPORTADOR'])['VALOR_USD'].sum().reset_index()\n",
    "\n",
    "        # Filtrar las empresas que superen el umbral de VALOR_USD\n",
    "        df_filtrado_umbral = df_sumado[df_sumado['VALOR_USD'] > umbral]\n",
    "\n",
    "        # Agrupar por la columna de agrupación y contar NITs únicos\n",
    "        conteo_por_agrupacion = df_filtrado_umbral.groupby(agrupacion_col)['NIT_EXPORTADOR'].nunique().reset_index(name=f'conteo_{year}')\n",
    "\n",
    "        # Asegurarse de que todas las agrupaciones posibles estén presentes (incluso con conteo 0)\n",
    "        conteo_completo = pd.DataFrame(agrupaciones_completas, columns=[agrupacion_col]).merge(conteo_por_agrupacion, on=agrupacion_col, how='left').fillna(0)\n",
    "\n",
    "        # Combinar los resultados de conteo con el DataFrame final\n",
    "        if conteo_empresas.empty:\n",
    "            conteo_empresas = conteo_completo\n",
    "        else:\n",
    "            conteo_empresas = pd.merge(conteo_empresas, conteo_completo, on=agrupacion_col, how='outer').fillna(0)\n",
    "\n",
    "    # Convertir los conteos a enteros\n",
    "    conteo_empresas[f'conteo_{temp_parametros[\"T_1_YEAR\"].iloc[0]}'] = conteo_empresas[f'conteo_{temp_parametros[\"T_1_YEAR\"].iloc[0]}'].astype(int)\n",
    "    conteo_empresas[f'conteo_{temp_parametros[\"T_YEAR\"].iloc[0]}'] = conteo_empresas[f'conteo_{temp_parametros[\"T_YEAR\"].iloc[0]}'].astype(int)\n",
    "\n",
    "    # Añadir la columna de AGRUPACION\n",
    "    conteo_empresas['AGRUPACION'] = agrupacion\n",
    "\n",
    "    # Cambiar el nombre de la primera columna a 'UNIDAD' si la agrupación no es 'COLOMBIA'\n",
    "    if agrupacion != 'COLOMBIA':\n",
    "        conteo_empresas.columns.values[0] = 'UNIDAD'\n",
    "\n",
    "    return conteo_empresas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contar_empresas_total(df_long, temp_parametros_cerrado, temp_parametros_corrido, df_list, umbral=10000):\n",
    "    \"\"\"\n",
    "    Genera el conteo total de empresas que superan un umbral de exportaciones para diferentes agrupaciones, \n",
    "    tanto en periodos cerrados como corridos. Las agrupaciones incluyen Hubs, Departamentos, Países, TLCs, \n",
    "    Continentes, Colombia y Sub-Regiones.\n",
    "\n",
    "    Parámetros:\n",
    "    -----------\n",
    "    df_long (pd.DataFrame): DataFrame de entrada que contiene los datos de exportaciones.\n",
    "    temp_parametros_cerrado (pd.DataFrame): DataFrame con los parámetros temporales para el periodo cerrado.\n",
    "    temp_parametros_corrido (pd.DataFrame): DataFrame con los parámetros temporales para el periodo corrido.\n",
    "    df_list (list): Lista auxiliar con los dataframes de información geográfica (Hubs, TLCs, etc.).\n",
    "    umbral (float): Valor mínimo de exportaciones en USD que debe superar una empresa para ser contada. (Por defecto 10000 USD).\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    CONTEOCERRADO (pd.DataFrame): DataFrame que contiene los resultados del conteo de empresas para el periodo cerrado.\n",
    "    CONTEOCORRIDO (pd.DataFrame): DataFrame que contiene los resultados del conteo de empresas para el periodo corrido.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Lista de las agrupaciones que se van a procesar: Hubs, Departamentos, Países, TLCs, Continentes, Colombia y Sub-Regiones.\n",
    "    agrupaciones = ['HUBS', 'DEPARTAMENTOS', 'PAISES', 'TLCS', 'CONTINENTES', 'COLOMBIA']\n",
    "    \n",
    "    # Inicializar listas para almacenar los resultados de conteo para los periodos cerrado y corrido.\n",
    "    conteos_cerrado = []\n",
    "    conteos_corrido = []\n",
    "\n",
    "    # Iterar sobre cada agrupación para realizar el conteo de empresas tanto en el periodo cerrado como en el corrido.\n",
    "    for agrupacion in agrupaciones:\n",
    "\n",
    "        # Obtener correlativo dependiendo de la agrupación si es necesaria\n",
    "        if agrupacion in ['HUBS', 'TLCS', 'CONTINENTES']:\n",
    "            df_geografia = df_list[agrupacion]\n",
    "        # Crear un df vacío si no requiere\n",
    "        else:\n",
    "            df_geografia = pd.DataFrame()\n",
    "        \n",
    "        # -------------------------------\n",
    "        # Conteo para el periodo cerrado\n",
    "        # -------------------------------\n",
    "        # Llamar a la función contar_empresas para obtener el conteo del periodo cerrado según la agrupación actual.\n",
    "        conteo_cerrado = contar_empresas(df_long, agrupacion, temp_parametros_cerrado, df_geografia, umbral)\n",
    "        \n",
    "        # Renombrar las columnas según la agrupación. Asegura que la columna 'UNIDAD' sea coherente con la agrupación.\n",
    "        if agrupacion == 'HUBS':\n",
    "            conteo_cerrado = conteo_cerrado.rename(columns={'NOMBRE_HUB': 'UNIDAD'})\n",
    "        elif agrupacion == 'DEPARTAMENTOS':\n",
    "            conteo_cerrado = conteo_cerrado.rename(columns={'DPTO_MAS_EXPORTA_ESTRELLA': 'UNIDAD'})\n",
    "        elif agrupacion == 'PAISES':\n",
    "            conteo_cerrado = conteo_cerrado.rename(columns={'PAIS_DESTINO': 'UNIDAD'})\n",
    "        elif agrupacion == 'TLCS':\n",
    "            conteo_cerrado = conteo_cerrado.rename(columns={'NOMBRE_TLC': 'UNIDAD'})\n",
    "        elif agrupacion == 'CONTINENTES':\n",
    "            conteo_cerrado = conteo_cerrado.rename(columns={'REGION_NAME': 'UNIDAD'})\n",
    "        elif agrupacion == 'COLOMBIA':\n",
    "            # Para Colombia, siempre se fija la unidad como 'COLOMBIA'.\n",
    "            conteo_cerrado['UNIDAD'] = 'COLOMBIA'\n",
    "        \n",
    "        # Añadir el conteo del periodo cerrado a la lista de resultados.\n",
    "        conteos_cerrado.append(conteo_cerrado)\n",
    "\n",
    "        # -------------------------------\n",
    "        # Conteo para el periodo corrido\n",
    "        # -------------------------------\n",
    "        # Llamar a la función contar_empresas para obtener el conteo del periodo corrido según la agrupación actual.\n",
    "        conteo_corrido = contar_empresas(df_long, agrupacion, temp_parametros_corrido, df_geografia, umbral)\n",
    "        \n",
    "        # Renombrar las columnas según la agrupación. Igual que para el periodo cerrado, aseguramos que la columna 'UNIDAD' sea coherente.\n",
    "        if agrupacion == 'HUBS':\n",
    "            conteo_corrido = conteo_corrido.rename(columns={'NOMBRE_HUB': 'UNIDAD'})\n",
    "        elif agrupacion == 'DEPARTAMENTOS':\n",
    "            conteo_corrido = conteo_corrido.rename(columns={'DPTO_MAS_EXPORTA_ESTRELLA': 'UNIDAD'})\n",
    "        elif agrupacion == 'PAISES':\n",
    "            conteo_corrido = conteo_corrido.rename(columns={'PAIS_DESTINO': 'UNIDAD'})\n",
    "        elif agrupacion == 'TLCS':\n",
    "            conteo_corrido = conteo_corrido.rename(columns=({'NOMBRE_TLC': 'UNIDAD'}))\n",
    "        elif agrupacion == 'CONTINENTES':\n",
    "            conteo_corrido = conteo_corrido.rename(columns=({'REGION_NAME': 'UNIDAD'}))\n",
    "        elif agrupacion == 'COLOMBIA':\n",
    "            # Para Colombia, la unidad se fija como 'COLOMBIA' para el periodo corrido.\n",
    "            conteo_corrido['UNIDAD'] = 'COLOMBIA'\n",
    "        \n",
    "        # Añadir el conteo del periodo corrido a la lista de resultados.\n",
    "        conteos_corrido.append(conteo_corrido)\n",
    "\n",
    "    # Concatenar los resultados de todas las agrupaciones para el periodo cerrado en un único DataFrame.\n",
    "    CONTEOCERRADO = pd.concat(conteos_cerrado, axis=0)\n",
    "\n",
    "    # Concatenar los resultados de todas las agrupaciones para el periodo corrido en un único DataFrame.\n",
    "    CONTEOCORRIDO = pd.concat(conteos_corrido, axis=0)\n",
    "\n",
    "    # Cambiar nombres\n",
    "    CONTEOCERRADO.columns.values[1] = 'CONTEO_T_1'  # Cambiar el nombre de la columna 2\n",
    "    CONTEOCERRADO.columns.values[2] = 'CONTEO_T'  # Cambiar el nombre de la columna 3\n",
    "\n",
    "    # Cambiar nombres\n",
    "    CONTEOCORRIDO.columns.values[1] = 'CONTEO_T_1'  # Cambiar el nombre de la columna 2\n",
    "    CONTEOCORRIDO.columns.values[2] = 'CONTEO_T'  # Cambiar el nombre de la columna 3\n",
    "\n",
    "    # Retornar los DataFrames finales para los periodos cerrado y corrido.\n",
    "    return CONTEOCERRADO, CONTEOCORRIDO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agregar_columnas_crecimiento(df, col_t_1, col_t):\n",
    "    \"\"\"\n",
    "    Agrega las columnas de diferencia absoluta y crecimiento porcentual a un DataFrame, \n",
    "    calculando la diferencia entre las columnas proporcionadas.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame de entrada que contiene las columnas con valores a comparar.\n",
    "    col_t_1 (str): Nombre de la columna que representa los valores de un año anterior (T-1).\n",
    "    col_t (str): Nombre de la columna que representa los valores del año actual (T).\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: El DataFrame con las columnas adicionales de 'DIFERENCIA_ABSOLUTA' y 'DIFERENCIA_PORCENTUAL'.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calcular la diferencia absoluta entre col_t y col_t_1\n",
    "    df['DIFERENCIA_ABSOLUTA'] = df[col_t] - df[col_t_1]\n",
    "    \n",
    "    # Calcular la diferencia porcentual con una lógica de control para evitar divisiones por 0\n",
    "    df['DIFERENCIA_PORCENTUAL'] = df.apply(\n",
    "        lambda row: 100 if row[col_t_1] == 0 and row[col_t] > 0 else\n",
    "                    -100 if row[col_t_1] > 0 and row[col_t] == 0 else\n",
    "                    0 if row[col_t_1] == 0 and row[col_t] == 0 else\n",
    "                    ((row[col_t] - row[col_t_1]) / row[col_t_1]) * 100,\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_df_por_agrupacion(df_input, correlativa, agrupacion, columna_correlativa, columna_renombrada):\n",
    "    \"\"\"\n",
    "    Procesa un DataFrame de exportaciones agrupado por una unidad específica (ej. países), uniendo con una tabla correlativa, \n",
    "    sumando los valores y agregando columnas de diferencias.\n",
    "\n",
    "    Parámetros:\n",
    "    -----------\n",
    "    df_input (pd.DataFrame): DataFrame de entrada que contiene las exportaciones ya agrupadas por diferentes categorías.\n",
    "    correlativa (pd.DataFrame): Tabla correlativa que se utilizará para hacer el 'merge' con la columna correlativa.\n",
    "    agrupacion (str): Nombre de la agrupación que se va a agregar a la columna 'AGRUPACION'.\n",
    "    columna_correlativa (str): Nombre de la columna en la tabla correlativa para unir con el DataFrame de entrada.\n",
    "    columna_renombrada (str): Nombre de la columna en el DataFrame correlativo que se renombrará a 'UNIDAD'.\n",
    "\n",
    "    Retorna:\n",
    "    --------\n",
    "    pd.DataFrame: DataFrame procesado con las sumas de exportaciones, diferencias agregadas y agrupado por la unidad y categoría.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Filtrar los datos para que solo contengan la agrupación seleccionada ('PAISES' en este caso).\n",
    "    df_insumo = df_input[df_input['AGRUPACION'] == 'PAISES']\n",
    "    \n",
    "    # Realizar una unión (merge) con la tabla correlativa usando una relación 'left' entre la columna 'UNIDAD' del DataFrame de entrada \n",
    "    # y la columna especificada por 'columna_correlativa' en la tabla correlativa.\n",
    "    df_resultado = df_insumo.merge(correlativa, how='left', left_on=['UNIDAD'], right_on=[columna_correlativa])\n",
    "    \n",
    "    # Seleccionar únicamente las columnas que son relevantes para el análisis, incluyendo la columna correlativa que se renombrará.\n",
    "    df_resultado = df_resultado[['TABLA', 'CATEGORIA', 'SUMA_USD_T_1', 'SUMA_USD_T', columna_renombrada]]\n",
    "    \n",
    "    # Renombrar la columna correlativa seleccionada a 'UNIDAD' para estandarizar los nombres de las columnas.\n",
    "    df_resultado = df_resultado.rename(columns={columna_renombrada: 'UNIDAD'})\n",
    "    \n",
    "    # Añadir la columna 'AGRUPACION' al DataFrame con el valor pasado como argumento en la función.\n",
    "    df_resultado['AGRUPACION'] = agrupacion\n",
    "    \n",
    "    # Reorganizar las columnas del DataFrame en un orden específico: AGRUPACION, UNIDAD, TABLA, CATEGORIA, SUMA_USD_T_1 y SUMA_USD_T.\n",
    "    df_resultado = df_resultado[['AGRUPACION', 'UNIDAD', 'TABLA', 'CATEGORIA', 'SUMA_USD_T_1', 'SUMA_USD_T']]\n",
    "    \n",
    "    # Agrupar los datos por las columnas 'AGRUPACION', 'UNIDAD', 'TABLA' y 'CATEGORIA', y sumar los valores de 'SUMA_USD_T_1' y 'SUMA_USD_T'.\n",
    "    df_resultado = df_resultado.groupby(['AGRUPACION', 'UNIDAD', 'TABLA', 'CATEGORIA'], as_index=False).agg({\n",
    "        'SUMA_USD_T_1': 'sum',\n",
    "        'SUMA_USD_T': 'sum'\n",
    "    })\n",
    "    \n",
    "    # Agregar columnas de diferencias calculando el crecimiento entre las columnas 'SUMA_USD_T_1' y 'SUMA_USD_T'.\n",
    "    df_resultado = agregar_columnas_crecimiento(df=df_resultado, col_t_1='SUMA_USD_T_1', col_t='SUMA_USD_T')\n",
    "    \n",
    "    # Retornar el DataFrame procesado con las sumas y diferencias de exportaciones.\n",
    "    return df_resultado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función principal que crea la tabla consolidada para HUBS, TLCS y CONTINENTES\n",
    "def crear_df_st_categorias(df_st_categorias, corrhubs, corrtlcs, corrcont):\n",
    "    \"\"\"\n",
    "    Crea un DataFrame consolidado que incluye los datos procesados para HUBS, TLCs y CONTINENTES, \n",
    "    uniendo las correlativas correspondientes y eliminando las filas con sumas iguales a 0.\n",
    "\n",
    "    Parámetros:\n",
    "    -----------\n",
    "    df_st_categorias (pd.DataFrame): DataFrame de entrada con las categorías base.\n",
    "    corrhubs (pd.DataFrame): DataFrame con las correlativas de HUBS.\n",
    "    corrtlcs (pd.DataFrame): DataFrame con las correlativas de TLCs.\n",
    "    corrcont (pd.DataFrame): DataFrame con las correlativas de CONTINENTES.\n",
    "\n",
    "    Retorna:\n",
    "    --------\n",
    "    pd.DataFrame: DataFrame consolidado con las categorías base y las correlativas de HUBS, TLCs y CONTINENTES.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Procesar HUBS\n",
    "    df_st_hubs = procesar_df_por_agrupacion(\n",
    "        df_input=df_st_categorias,         # DataFrame de entrada con las categorías\n",
    "        correlativa=corrhubs,              # Correlativa específica para HUBS\n",
    "        agrupacion='HUBS',                 # Nombre de la agrupación que se va a asignar\n",
    "        columna_correlativa='PAIS_LLAVE_EXPORTACIONES',  # Columna correlativa para la unión\n",
    "        columna_renombrada='NOMBRE_HUB'    # Columna que se va a renombrar a 'UNIDAD'\n",
    "    )\n",
    "\n",
    "    # Procesar TLCs\n",
    "    df_st_tlcs = procesar_df_por_agrupacion(\n",
    "        df_input=df_st_categorias,         # DataFrame de entrada con las categorías\n",
    "        correlativa=corrtlcs,              # Correlativa específica para TLCs\n",
    "        agrupacion='TLCS',                 # Nombre de la agrupación que se va a asignar\n",
    "        columna_correlativa='PAIS_LLAVE_EXPORTACIONES',  # Columna correlativa para la unión\n",
    "        columna_renombrada='NOMBRE_TLC'    # Columna que se va a renombrar a 'UNIDAD'\n",
    "    )\n",
    "\n",
    "    # Procesar CONTINENTES\n",
    "    df_st_cont = procesar_df_por_agrupacion(\n",
    "        df_input=df_st_categorias,         # DataFrame de entrada con las categorías\n",
    "        correlativa=corrcont,              # Correlativa específica para CONTINENTES\n",
    "        agrupacion='CONTINENTES',          # Nombre de la agrupación que se va a asignar\n",
    "        columna_correlativa='PAIS_LLAVE_EXPORTACIONES',  # Columna correlativa para la unión\n",
    "        columna_renombrada='REGION_NAME'   # Columna que se va a renombrar a 'UNIDAD'\n",
    "    )\n",
    "\n",
    "    # Concatenar los resultados de las tres agrupaciones (categorías base, HUBS, TLCs, CONTINENTES)\n",
    "    df_st_completo = pd.concat([df_st_hubs, df_st_tlcs, df_st_cont])\n",
    "    \n",
    "    # Eliminar las filas donde tanto SUMA_USD_T_1 como SUMA_USD_T son iguales a 0\n",
    "    condicion_1 = (df_st_completo['SUMA_USD_T_1'] == 0) & (df_st_completo['SUMA_USD_T'] == 0)\n",
    "    df_st_completo = df_st_completo[~condicion_1].reset_index(drop=True)  # Resetear el índice después de eliminar filas\n",
    "    \n",
    "    return df_st_completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_df_por_agrupacion_peso(df_input, correlativa, agrupacion, columna_correlativa, columna_renombrada):\n",
    "    \"\"\"\n",
    "    Procesa un DataFrame de entrada, filtrando por la agrupación 'PAISES', uniendo con una tabla correlativa y \n",
    "    calculando las sumas y diferencias de peso para los períodos T_1 y T.\n",
    "\n",
    "    Parámetros:\n",
    "    -----------\n",
    "    df_input (pd.DataFrame): DataFrame de entrada que contiene los datos de exportación, incluyendo los pesos.\n",
    "    correlativa (pd.DataFrame): DataFrame correlativo que se unirá con df_input basado en una columna correlativa.\n",
    "    agrupacion (str): Nombre de la agrupación a agregar al DataFrame final, como 'HUBS', 'TLCs', o 'CONTINENTES'.\n",
    "    columna_correlativa (str): Nombre de la columna en el DataFrame correlativa para realizar la unión.\n",
    "    columna_renombrada (str): Nombre de la columna que se renombrará a 'UNIDAD' después de la unión.\n",
    "\n",
    "    Retorna:\n",
    "    --------\n",
    "    pd.DataFrame: DataFrame procesado, con las sumas de peso para T_1 y T, y con las columnas de crecimiento agregado.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Filtrar el DataFrame de entrada para mantener solo las filas con la agrupación 'PAISES'\n",
    "    df_insumo = df_input[df_input['AGRUPACION'] == 'PAISES']\n",
    "    \n",
    "    # Realizar la unión del DataFrame filtrado con la tabla correlativa, usando 'UNIDAD' y la columna correlativa como claves\n",
    "    df_resultado = df_insumo.merge(correlativa, how='left', left_on=['UNIDAD'], right_on=[columna_correlativa])\n",
    "    \n",
    "    # Seleccionar únicamente las columnas relevantes del DataFrame resultante tras la unión\n",
    "    df_resultado = df_resultado[['TABLA', 'CATEGORIA', 'SUMA_PESO_T_1', 'SUMA_PESO_T', columna_renombrada]]\n",
    "    \n",
    "    # Renombrar la columna correlativa a 'UNIDAD' para estandarizar el nombre en el DataFrame resultante\n",
    "    df_resultado = df_resultado.rename(columns={columna_renombrada: 'UNIDAD'})\n",
    "    \n",
    "    # Agregar una nueva columna 'AGRUPACION' con el valor especificado en los parámetros de la función\n",
    "    df_resultado['AGRUPACION'] = agrupacion\n",
    "    \n",
    "    # Reordenar las columnas del DataFrame para asegurar que estén en el orden correcto\n",
    "    df_resultado = df_resultado[['AGRUPACION', 'UNIDAD', 'TABLA', 'CATEGORIA', 'SUMA_PESO_T_1', 'SUMA_PESO_T']]\n",
    "    \n",
    "    # Agrupar los datos por las columnas 'AGRUPACION', 'UNIDAD', 'TABLA' y 'CATEGORIA', sumando los pesos de T_1 y T\n",
    "    df_resultado = df_resultado.groupby(['AGRUPACION', 'UNIDAD', 'TABLA', 'CATEGORIA'], as_index=False).agg({\n",
    "        'SUMA_PESO_T_1': 'sum',  # Sumar los pesos de T_1\n",
    "        'SUMA_PESO_T': 'sum'     # Sumar los pesos de T\n",
    "    })\n",
    "    \n",
    "    # Agregar columnas adicionales calculando la diferencia y crecimiento porcentual entre T_1 y T \n",
    "    df_resultado = agregar_columnas_crecimiento(df=df_resultado, col_t_1='SUMA_PESO_T_1', col_t='SUMA_PESO_T' )\n",
    "    \n",
    "    # Devolver el DataFrame procesado con las columnas de sumas y crecimiento\n",
    "    return df_resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función principal que crea la tabla consolidada para HUBS, TLCS y CONTINENTES, basada en el peso\n",
    "def crear_df_st_categorias_peso(df_st_categorias, corrhubs, corrtlcs, corrcont):\n",
    "    \"\"\"\n",
    "    Procesa el DataFrame `df_st_categorias` para consolidar los datos de peso en las categorías de HUBS, TLCS y CONTINENTES.\n",
    "    La función realiza las operaciones de agrupación y suma de pesos para las categorías seleccionadas y luego elimina\n",
    "    las filas donde ambos valores de peso son cero.\n",
    "\n",
    "    Parámetros:\n",
    "    -----------\n",
    "    df_st_categorias (pd.DataFrame): DataFrame con los datos de entrada que contienen las categorías y pesos.\n",
    "    corrhubs (pd.DataFrame): DataFrame de correlación que contiene la correspondencia de HUBS con los países.\n",
    "    corrtlcs (pd.DataFrame): DataFrame de correlación que contiene la correspondencia de TLCs con los países.\n",
    "    corrcont (pd.DataFrame): DataFrame de correlación que contiene la correspondencia de continentes con los países.\n",
    "\n",
    "    Retorna:\n",
    "    --------\n",
    "    pd.DataFrame: DataFrame consolidado con las categorías de HUBS, TLCS y CONTINENTES, con las sumas de peso por categoría.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Procesar HUBS: filtrar y procesar el DataFrame por la agrupación de HUBS\n",
    "    df_st_hubs = procesar_df_por_agrupacion_peso(\n",
    "        df_input=df_st_categorias,           # DataFrame de entrada\n",
    "        correlativa=corrhubs,                # DataFrame de correlación para HUBS\n",
    "        agrupacion='HUBS',                   # Nombre de la agrupación (HUBS)\n",
    "        columna_correlativa='PAIS_LLAVE_EXPORTACIONES',  # Columna correlativa para la unión\n",
    "        columna_renombrada='NOMBRE_HUB'      # Columna a renombrar como 'UNIDAD'\n",
    "    )\n",
    "\n",
    "    # Procesar TLCS: filtrar y procesar el DataFrame por la agrupación de TLCs\n",
    "    df_st_tlcs = procesar_df_por_agrupacion_peso(\n",
    "        df_input=df_st_categorias,           # DataFrame de entrada\n",
    "        correlativa=corrtlcs,                # DataFrame de correlación para TLCs\n",
    "        agrupacion='TLCS',                   # Nombre de la agrupación (TLCS)\n",
    "        columna_correlativa='PAIS_LLAVE_EXPORTACIONES',  # Columna correlativa para la unión\n",
    "        columna_renombrada='NOMBRE_TLC'      # Columna a renombrar como 'UNIDAD'\n",
    "    )\n",
    "\n",
    "    # Procesar CONTINENTES: filtrar y procesar el DataFrame por la agrupación de continentes\n",
    "    df_st_cont = procesar_df_por_agrupacion_peso(\n",
    "        df_input=df_st_categorias,           # DataFrame de entrada\n",
    "        correlativa=corrcont,                # DataFrame de correlación para continentes\n",
    "        agrupacion='CONTINENTES',            # Nombre de la agrupación (CONTINENTES)\n",
    "        columna_correlativa='PAIS_LLAVE_EXPORTACIONES',  # Columna correlativa para la unión\n",
    "        columna_renombrada='REGION_NAME'     # Columna a renombrar como 'UNIDAD'\n",
    "    )\n",
    "\n",
    "    # Concatenar los DataFrames procesados para HUBS, TLCs y CONTINENTES\n",
    "    df_st_completo = pd.concat([df_st_hubs, df_st_tlcs, df_st_cont])\n",
    "\n",
    "    # Eliminar las filas donde las sumas de peso en T_1 y T sean iguales a cero\n",
    "    condicion_1 = (df_st_completo['SUMA_PESO_T_1'] == 0) & (df_st_completo['SUMA_PESO_T'] == 0)\n",
    "    df_st_completo = df_st_completo[~condicion_1].reset_index(drop=True)  # Filtrar y restablecer los índices\n",
    "\n",
    "    # Devolver el DataFrame completo procesado\n",
    "    return df_st_completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_agrupacion(df_insumo, df_correlativo, llave_correlativa, nombre_columna, agrupacion):\n",
    "    \"\"\"\n",
    "    Procesa un DataFrame para realizar una agrupación específica basada en una tabla correlativa y un conjunto de columnas de interés.\n",
    "    \n",
    "    Parámetros:\n",
    "    -----------\n",
    "    df_insumo : pd.DataFrame\n",
    "        DataFrame que contiene los datos base que se van a agrupar.\n",
    "    df_correlativo : pd.DataFrame\n",
    "        DataFrame correlativo que contiene la información adicional necesaria para unir con 'df_insumo'.\n",
    "    llave_correlativa : str\n",
    "        Nombre de la columna en 'df_correlativo' que se utilizará como llave para la unión.\n",
    "    nombre_columna : str\n",
    "        Nombre de la columna que se utilizará como la nueva 'UNIDAD' en el DataFrame final.\n",
    "    agrupacion : str\n",
    "        Nombre de la agrupación que se agregará a la columna 'AGRUPACION' en el DataFrame final.\n",
    "    \n",
    "    Retorna:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame con los datos agrupados por las columnas 'AGRUPACION', 'UNIDAD', 'TABLA', 'CATEGORIA', 'RAZON_SOCIAL', 'SECTOR_ESTRELLA',\n",
    "        y las sumas de 'SUMA_USD_T_1' y 'SUMA_USD_T'.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Realiza un merge (unión) entre 'df_insumo' y 'df_correlativo' utilizando 'UNIDAD' en 'df_insumo' y 'llave_correlativa' en 'df_correlativo'\n",
    "    df_merged = df_insumo.merge(df_correlativo, how='left', left_on=['UNIDAD'], right_on=[llave_correlativa])\n",
    "\n",
    "    # Selecciona las columnas de interés del DataFrame resultante de la unión\n",
    "    df_merged = df_merged[['TABLA', 'CATEGORIA', 'RAZON_SOCIAL', 'SECTOR_ESTRELLA', 'SUMA_USD_T_1', 'SUMA_USD_T', nombre_columna]]\n",
    "\n",
    "    # Renombra la columna 'nombre_columna' a 'UNIDAD' para estandarizar el nombre\n",
    "    df_merged = df_merged.rename(columns={nombre_columna: 'UNIDAD'})\n",
    "\n",
    "    # Agrega la columna 'AGRUPACION' con el valor proporcionado en el parámetro 'agrupacion'\n",
    "    df_merged['AGRUPACION'] = agrupacion\n",
    "\n",
    "    # Reorganiza las columnas en el orden deseado\n",
    "    df_merged = df_merged[['AGRUPACION', 'UNIDAD', 'TABLA', 'CATEGORIA', 'RAZON_SOCIAL', 'SECTOR_ESTRELLA', 'SUMA_USD_T_1', 'SUMA_USD_T']]\n",
    "\n",
    "    # Agrupa los datos por las columnas clave y suma los valores de 'SUMA_USD_T_1' y 'SUMA_USD_T'\n",
    "    df_merged = df_merged.groupby(\n",
    "        ['AGRUPACION', 'UNIDAD', 'TABLA', 'CATEGORIA', 'RAZON_SOCIAL', 'SECTOR_ESTRELLA'], \n",
    "        as_index=False\n",
    "    ).agg({\n",
    "        'SUMA_USD_T_1': 'sum',  # Sumar los valores de 'SUMA_USD_T_1'\n",
    "        'SUMA_USD_T': 'sum'  # Sumar los valores de 'SUMA_USD_T'\n",
    "    })\n",
    "\n",
    "    # Retorna el DataFrame final con los datos procesados y agrupados\n",
    "    return df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_df_nit(df_input, corrhubs, corrtlcs, corrcont):\n",
    "    \"\"\"\n",
    "    Procesa un DataFrame de entrada para realizar agrupaciones por HUBS, TLCs y CONTINENTES, uniendo con tablas correlativas\n",
    "    y calculando las sumas de valores financieros. Luego elimina las filas con valores nulos y agrega columnas de crecimiento.\n",
    "\n",
    "    Parámetros:\n",
    "    -----------\n",
    "    df_input : pd.DataFrame\n",
    "        DataFrame de entrada que contiene los datos de exportaciones por NIT (identificación tributaria).\n",
    "    corrhubs : pd.DataFrame\n",
    "        DataFrame correlativo que contiene información sobre HUBs.\n",
    "    corrtlcs : pd.DataFrame\n",
    "        DataFrame correlativo que contiene información sobre TLCs (Tratados de Libre Comercio).\n",
    "    corrcont : pd.DataFrame\n",
    "        DataFrame correlativo que contiene información sobre continentes.\n",
    "    \n",
    "    Retorna:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame consolidado que incluye las agrupaciones por HUBs, TLCs y continentes, con columnas de sumas de USD y crecimiento.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Crear DataFrame para HUBS realizando la unión y procesamiento con la tabla correlativa de HUBs\n",
    "    df_st_hubs = procesar_agrupacion(\n",
    "        df_insumo=df_input,\n",
    "        df_correlativo=corrhubs,\n",
    "        llave_correlativa='PAIS_LLAVE_EXPORTACIONES',  # Llave para unir con la tabla correlativa\n",
    "        nombre_columna='NOMBRE_HUB',  # Columna que se renombrará como 'UNIDAD'\n",
    "        agrupacion='HUBS'  # Agrupación de HUBS\n",
    "    )\n",
    "\n",
    "    # Crear DataFrame para TLCs realizando la unión y procesamiento con la tabla correlativa de TLCs\n",
    "    df_st_tlcs = procesar_agrupacion(\n",
    "        df_insumo=df_input,\n",
    "        df_correlativo=corrtlcs,\n",
    "        llave_correlativa='PAIS_LLAVE_EXPORTACIONES',  # Llave para unir con la tabla correlativa\n",
    "        nombre_columna='NOMBRE_TLC',  # Columna que se renombrará como 'UNIDAD'\n",
    "        agrupacion='TLCS'  # Agrupación de TLCs\n",
    "    )\n",
    "\n",
    "    # Crear DataFrame para CONTINENTES realizando la unión y procesamiento con la tabla correlativa de continentes\n",
    "    df_st_cont = procesar_agrupacion(\n",
    "        df_insumo=df_input,\n",
    "        df_correlativo=corrcont,\n",
    "        llave_correlativa='PAIS_LLAVE_EXPORTACIONES',  # Llave para unir con la tabla correlativa\n",
    "        nombre_columna='REGION_NAME',  # Columna que se renombrará como 'UNIDAD'\n",
    "        agrupacion='CONTINENTES'  # Agrupación de continentes\n",
    "    )\n",
    "\n",
    "    # Concatenar los DataFrames generados para HUBS, TLCs y CONTINENTES en un único DataFrame\n",
    "    SD_ST_NIT = pd.concat([df_st_hubs, df_st_tlcs, df_st_cont], ignore_index=True)\n",
    "\n",
    "    # Eliminar filas donde tanto 'SUMA_USD_T_1' como 'SUMA_USD_T' sean cero\n",
    "    condicion_1 = (SD_ST_NIT['SUMA_USD_T_1'] == 0) & (SD_ST_NIT['SUMA_USD_T'] == 0)\n",
    "    SD_ST_NIT = SD_ST_NIT[~condicion_1].reset_index(drop=True)  # Se eliminan esas filas y se resetea el índice\n",
    "\n",
    "    # Agregar columnas de crecimiento calculadas entre los valores de 'SUMA_USD_T_1' y 'SUMA_USD_T' utilizando una función externa\n",
    "    SD_ST_NIT = agregar_columnas_crecimiento(df=SD_ST_NIT, col_t_1='SUMA_USD_T_1', col_t='SUMA_USD_T')\n",
    "\n",
    "    # Retornar el DataFrame final con las agrupaciones y cálculos de crecimiento\n",
    "    return SD_ST_NIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 ST_CATEGORIAS_CERRADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparación (Preagrupación para asegurar velocidad)\n",
    "df_insumo_minero_nme = df_usd_long.groupby(['CONTINENTE', 'DEPARTAMENTO_ORIGEN', 'PAIS_DESTINO', 'SECTOR', 'SUBSECTOR', 'TIPO', 'YEAR'], as_index=False).agg({'VALOR_USD': 'sum'})\n",
    "df_insumo_control_usd = df_usd_long.groupby(['TIPO', 'YEAR'], as_index=False).agg({'VALOR_USD': 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agrupación: COLOMBIA, Categoría: CONTINENTE\n",
      "True True\n",
      "Agrupación: COLOMBIA, Categoría: DEPARTAMENTO_ORIGEN\n",
      "True True\n",
      "Agrupación: COLOMBIA, Categoría: PAIS_DESTINO\n",
      "True True\n",
      "Agrupación: COLOMBIA, Categoría: SECTOR\n",
      "True True\n",
      "Agrupación: COLOMBIA, Categoría: SUBSECTOR\n",
      "True True\n",
      "Agregando totales - Agrupación: COLOMBIA, Unidad: COLOMBIA\n",
      "True True\n",
      "Agregando tipos - Agrupación: COLOMBIA, Unidad: COLOMBIA\n",
      "True True\n",
      "Agrupación: PAISES, Categoría: CONTINENTE\n",
      "True True\n",
      "Agrupación: PAISES, Categoría: DEPARTAMENTO_ORIGEN\n",
      "True True\n",
      "Agrupación: PAISES, Categoría: PAIS_DESTINO\n",
      "True True\n",
      "Agrupación: PAISES, Categoría: SECTOR\n",
      "True True\n",
      "Agrupación: PAISES, Categoría: SUBSECTOR\n",
      "True True\n",
      "Agregando totales - Agrupación: PAISES, Unidad: PAIS_DESTINO\n",
      "True True\n",
      "Agregando tipos - Agrupación: PAISES, Unidad: PAIS_DESTINO\n",
      "True True\n",
      "Agrupación: DEPARTAMENTOS, Categoría: CONTINENTE\n",
      "True True\n",
      "Agrupación: DEPARTAMENTOS, Categoría: DEPARTAMENTO_ORIGEN\n",
      "True True\n",
      "Agrupación: DEPARTAMENTOS, Categoría: PAIS_DESTINO\n",
      "True True\n",
      "Agrupación: DEPARTAMENTOS, Categoría: SECTOR\n",
      "True True\n",
      "Agrupación: DEPARTAMENTOS, Categoría: SUBSECTOR\n",
      "True True\n",
      "Agregando totales - Agrupación: DEPARTAMENTOS, Unidad: DEPARTAMENTO_ORIGEN\n",
      "True True\n",
      "Agregando tipos - Agrupación: DEPARTAMENTOS, Unidad: DEPARTAMENTO_ORIGEN\n",
      "True True\n"
     ]
    }
   ],
   "source": [
    "# Definir los parámetros\n",
    "AGRUPACIONES = ['COLOMBIA', 'PAISES', 'DEPARTAMENTOS']\n",
    "VALOR_COL = 'VALOR_USD'\n",
    "TEMP_PARAMETROS = TEMP_PARAMETROS_CERRADO \n",
    "\n",
    "# Inicializar DataFrames vacíos para almacenar los resultados finales\n",
    "DF_ST_CATEGORIAS_CERRADO = pd.DataFrame()\n",
    "DF_ST_CATEGORIAS_CERRADO_VALIDACION = pd.DataFrame()\n",
    "\n",
    "# Loop para ejecutar la función en cada agrupación y concatenar los resultados\n",
    "for AGRUPACION in AGRUPACIONES:\n",
    "    # Ejecutar la función para cada agrupación\n",
    "    df_resultado, df_validacion = generar_tablas_completas_usd(\n",
    "        df=df_insumo_minero_nme,\n",
    "        df_control = df_insumo_control_usd,\n",
    "        agrupacion=AGRUPACION,\n",
    "        valor_col=VALOR_COL,\n",
    "        temp_parametros=TEMP_PARAMETROS\n",
    "    )\n",
    "    \n",
    "    # Concatenar los resultados de cada agrupación\n",
    "    DF_ST_CATEGORIAS_CERRADO = pd.concat([DF_ST_CATEGORIAS_CERRADO, df_resultado], ignore_index=True)\n",
    "    DF_ST_CATEGORIAS_CERRADO_VALIDACION = pd.concat([DF_ST_CATEGORIAS_CERRADO_VALIDACION, df_validacion], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGRUPACION</th>\n",
       "      <th>UNIDAD</th>\n",
       "      <th>TABLA</th>\n",
       "      <th>CATEGORIA</th>\n",
       "      <th>SUMA_USD_T_1</th>\n",
       "      <th>SUMA_USD_T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [AGRUPACION, UNIDAD, TABLA, CATEGORIA, SUMA_USD_T_1, SUMA_USD_T]\n",
       "Index: []"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Elegir observaciones con falsos en el df de validación, si no hay resultado, el proceso no tiene errores.\n",
    "DF_ST_CATEGORIAS_CERRADO_VALIDACION[(DF_ST_CATEGORIAS_CERRADO_VALIDACION['SUMA_USD_T_1'] == False) | (DF_ST_CATEGORIAS_CERRADO_VALIDACION['SUMA_USD_T'] == False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear agrupaciones de hubs, tlcs, continentes\n",
    "df_hubs_tlcs_continentes = crear_df_st_categorias(df_st_categorias=DF_ST_CATEGORIAS_CERRADO, corrhubs=df_hubs, corrtlcs=df_tlcs, corrcont=df_continentes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear tabla ST_CATEGORIAS_CERRADO\n",
    "DF_ST_CATEGORIAS_CERRADO = pd.concat([DF_ST_CATEGORIAS_CERRADO, df_hubs_tlcs_continentes])\n",
    "# Eliminar filas donde los valores en ambas columnas de sumas sean cero\n",
    "condicion_1 = (DF_ST_CATEGORIAS_CERRADO['SUMA_USD_T_1'] == 0) & (DF_ST_CATEGORIAS_CERRADO['SUMA_USD_T'] == 0)\n",
    "DF_ST_CATEGORIAS_CERRADO = DF_ST_CATEGORIAS_CERRADO[~condicion_1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 ST_CATEGORIAS_CORRIDO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparación (Preagrupación para asegurar velocidad)\n",
    "df_insumo_minero_nme = df_usd_long.groupby(['CONTINENTE', 'DEPARTAMENTO_ORIGEN', 'PAIS_DESTINO', 'SECTOR', 'SUBSECTOR', 'TIPO', 'YEAR'], as_index=False).agg({'VALOR_USD': 'sum'})\n",
    "df_insumo_control_usd = df_usd_long.groupby(['TIPO', 'YEAR'], as_index=False).agg({'VALOR_USD': 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agrupación: COLOMBIA, Categoría: CONTINENTE\n",
      "True True\n",
      "Agrupación: COLOMBIA, Categoría: DEPARTAMENTO_ORIGEN\n",
      "True True\n",
      "Agrupación: COLOMBIA, Categoría: PAIS_DESTINO\n",
      "True True\n",
      "Agrupación: COLOMBIA, Categoría: SECTOR\n",
      "True True\n",
      "Agrupación: COLOMBIA, Categoría: SUBSECTOR\n",
      "True True\n",
      "Agregando totales - Agrupación: COLOMBIA, Unidad: COLOMBIA\n",
      "True True\n",
      "Agregando tipos - Agrupación: COLOMBIA, Unidad: COLOMBIA\n",
      "True True\n",
      "Agrupación: PAISES, Categoría: CONTINENTE\n",
      "True True\n",
      "Agrupación: PAISES, Categoría: DEPARTAMENTO_ORIGEN\n",
      "True True\n",
      "Agrupación: PAISES, Categoría: PAIS_DESTINO\n",
      "True True\n",
      "Agrupación: PAISES, Categoría: SECTOR\n",
      "True True\n",
      "Agrupación: PAISES, Categoría: SUBSECTOR\n",
      "True True\n",
      "Agregando totales - Agrupación: PAISES, Unidad: PAIS_DESTINO\n",
      "True True\n",
      "Agregando tipos - Agrupación: PAISES, Unidad: PAIS_DESTINO\n",
      "True True\n",
      "Agrupación: DEPARTAMENTOS, Categoría: CONTINENTE\n",
      "True True\n",
      "Agrupación: DEPARTAMENTOS, Categoría: DEPARTAMENTO_ORIGEN\n",
      "True True\n",
      "Agrupación: DEPARTAMENTOS, Categoría: PAIS_DESTINO\n",
      "True True\n",
      "Agrupación: DEPARTAMENTOS, Categoría: SECTOR\n",
      "True True\n",
      "Agrupación: DEPARTAMENTOS, Categoría: SUBSECTOR\n",
      "True True\n",
      "Agregando totales - Agrupación: DEPARTAMENTOS, Unidad: DEPARTAMENTO_ORIGEN\n",
      "True True\n",
      "Agregando tipos - Agrupación: DEPARTAMENTOS, Unidad: DEPARTAMENTO_ORIGEN\n",
      "True True\n"
     ]
    }
   ],
   "source": [
    "# Definir los parámetros\n",
    "AGRUPACIONES = ['COLOMBIA', 'PAISES', 'DEPARTAMENTOS']\n",
    "VALOR_COL = 'VALOR_USD'\n",
    "TEMP_PARAMETROS = TEMP_PARAMETROS_CORRIDO \n",
    "\n",
    "# Inicializar DataFrames vacíos para almacenar los resultados finales\n",
    "DF_ST_CATEGORIAS_CORRIDO = pd.DataFrame()\n",
    "DF_ST_CATEGORIAS_CORRIDO_VALIDACION = pd.DataFrame()\n",
    "\n",
    "# Loop para ejecutar la función en cada agrupación y concatenar los resultados\n",
    "for AGRUPACION in AGRUPACIONES:\n",
    "    # Ejecutar la función para cada agrupación\n",
    "    df_resultado, df_validacion = generar_tablas_completas_usd(\n",
    "        df=df_insumo_minero_nme,\n",
    "        df_control = df_insumo_control_usd,\n",
    "        agrupacion=AGRUPACION,\n",
    "        valor_col=VALOR_COL,\n",
    "        temp_parametros=TEMP_PARAMETROS\n",
    "    )\n",
    "    \n",
    "    # Concatenar los resultados de cada agrupación\n",
    "    DF_ST_CATEGORIAS_CORRIDO = pd.concat([DF_ST_CATEGORIAS_CORRIDO, df_resultado], ignore_index=True)\n",
    "    DF_ST_CATEGORIAS_CORRIDO_VALIDACION = pd.concat([DF_ST_CATEGORIAS_CORRIDO_VALIDACION, df_validacion], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGRUPACION</th>\n",
       "      <th>UNIDAD</th>\n",
       "      <th>TABLA</th>\n",
       "      <th>CATEGORIA</th>\n",
       "      <th>SUMA_USD_T_1</th>\n",
       "      <th>SUMA_USD_T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [AGRUPACION, UNIDAD, TABLA, CATEGORIA, SUMA_USD_T_1, SUMA_USD_T]\n",
       "Index: []"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Elegir observaciones con falsos en el df de validación, si no hay resultado, el proceso no tiene errores.\n",
    "DF_ST_CATEGORIAS_CORRIDO_VALIDACION[(DF_ST_CATEGORIAS_CORRIDO_VALIDACION['SUMA_USD_T_1'] == False) | (DF_ST_CATEGORIAS_CORRIDO_VALIDACION['SUMA_USD_T'] == False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear agrupaciones de hubs, tlcs, continentes\n",
    "df_hubs_tlcs_continentes = crear_df_st_categorias(df_st_categorias=DF_ST_CATEGORIAS_CORRIDO, corrhubs=df_hubs, corrtlcs=df_tlcs, corrcont=df_continentes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear tabla ST_CATEGORIAS_CORRIDO\n",
    "DF_ST_CATEGORIAS_CORRIDO = pd.concat([DF_ST_CATEGORIAS_CORRIDO, df_hubs_tlcs_continentes])\n",
    "# Eliminar filas donde los valores en ambas columnas de sumas sean cero\n",
    "condicion_1 = (DF_ST_CATEGORIAS_CORRIDO['SUMA_USD_T_1'] == 0) & (DF_ST_CATEGORIAS_CORRIDO['SUMA_USD_T'] == 0)\n",
    "DF_ST_CATEGORIAS_CORRIDO = DF_ST_CATEGORIAS_CORRIDO[~condicion_1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 ST_CATEGORIAS_PESO_CERRADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparación (Preagrupación para asegurar velocidad)\n",
    "df_insumo_minero_nme = df_kg_long.groupby(['PAIS_DESTINO', 'DEPARTAMENTO_ORIGEN', 'MEDIO_TRANSPORTE', 'TIPO', 'YEAR'], as_index=False).agg({'PESO_KG': 'sum'})\n",
    "df_insumo_control_kg = df_kg_long.groupby(['TIPO', 'YEAR'], as_index=False).agg({'PESO_KG': 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agrupación: COLOMBIA, Categoría: MEDIO_TRANSPORTE\n",
      "True True\n",
      "Agrupación: COLOMBIA, Categoría: PAIS_DESTINO\n",
      "True True\n",
      "Agrupación: COLOMBIA, Categoría: MEDIO_TRANSPORTE\n",
      "True True\n",
      "Agrupación: COLOMBIA, Categoría: PAIS_DESTINO\n",
      "True True\n",
      "Agregando totales - Agrupación: COLOMBIA, Unidad: COLOMBIA\n",
      "True True\n",
      "Agregando tipos - Agrupación: COLOMBIA, Unidad: COLOMBIA\n",
      "True True\n",
      "Agrupación: PAISES, Categoría: MEDIO_TRANSPORTE\n",
      "True True\n",
      "Agrupación: PAISES, Categoría: PAIS_DESTINO\n",
      "True True\n",
      "Agrupación: PAISES, Categoría: MEDIO_TRANSPORTE\n",
      "True True\n",
      "Agrupación: PAISES, Categoría: PAIS_DESTINO\n",
      "True True\n",
      "Agregando totales - Agrupación: PAISES, Unidad: PAIS_DESTINO\n",
      "True True\n",
      "Agregando tipos - Agrupación: PAISES, Unidad: PAIS_DESTINO\n",
      "True True\n",
      "Agrupación: DEPARTAMENTOS, Categoría: MEDIO_TRANSPORTE\n",
      "True True\n",
      "Agrupación: DEPARTAMENTOS, Categoría: PAIS_DESTINO\n",
      "True True\n",
      "Agrupación: DEPARTAMENTOS, Categoría: MEDIO_TRANSPORTE\n",
      "True True\n",
      "Agrupación: DEPARTAMENTOS, Categoría: PAIS_DESTINO\n",
      "True True\n",
      "Agregando totales - Agrupación: DEPARTAMENTOS, Unidad: DEPARTAMENTO_ORIGEN\n",
      "True True\n",
      "Agregando tipos - Agrupación: DEPARTAMENTOS, Unidad: DEPARTAMENTO_ORIGEN\n",
      "True True\n"
     ]
    }
   ],
   "source": [
    "# Definir los parámetros\n",
    "AGRUPACIONES = ['COLOMBIA', 'PAISES', 'DEPARTAMENTOS']\n",
    "VALOR_COL = 'PESO_KG'\n",
    "TEMP_PARAMETROS = TEMP_PARAMETROS_CERRADO \n",
    "\n",
    "# Inicializar DataFrames vacíos para almacenar los resultados finales\n",
    "DF_ST_CATEGORIAS_PESO_CERRADO = pd.DataFrame()\n",
    "DF_ST_CATEGORIAS_PESO_CERRADO_VALIDACION = pd.DataFrame()\n",
    "\n",
    "# Loop para ejecutar la función en cada agrupación y concatenar los resultados\n",
    "for AGRUPACION in AGRUPACIONES:\n",
    "    # Ejecutar la función para cada agrupación\n",
    "    df_resultado, df_validacion = generar_tablas_completas_kg(\n",
    "        df=df_insumo_minero_nme,\n",
    "        df_control = df_insumo_control_kg,\n",
    "        agrupacion=AGRUPACION,\n",
    "        valor_col=VALOR_COL,\n",
    "        temp_parametros=TEMP_PARAMETROS\n",
    "    )\n",
    "    \n",
    "    # Concatenar los resultados de cada agrupación\n",
    "    DF_ST_CATEGORIAS_PESO_CERRADO = pd.concat([DF_ST_CATEGORIAS_PESO_CERRADO, df_resultado], ignore_index=True)\n",
    "    DF_ST_CATEGORIAS_PESO_CERRADO_VALIDACION = pd.concat([DF_ST_CATEGORIAS_PESO_CERRADO_VALIDACION, df_validacion], ignore_index=True)\n",
    "\n",
    "# Cambiar nombres de usd a kg ya que se usa la misma función que las categorias de usd\n",
    "DF_ST_CATEGORIAS_PESO_CERRADO = DF_ST_CATEGORIAS_PESO_CERRADO.rename(columns={'SUMA_USD_T_1': 'SUMA_PESO_T_1', 'SUMA_USD_T': 'SUMA_PESO_T'})\n",
    "DF_ST_CATEGORIAS_PESO_CERRADO_VALIDACION = DF_ST_CATEGORIAS_PESO_CERRADO_VALIDACION.rename(columns={'SUMA_USD_T_1': 'SUMA_PESO_T_1', 'SUMA_USD_T': 'SUMA_PESO_T'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGRUPACION</th>\n",
       "      <th>UNIDAD</th>\n",
       "      <th>TABLA</th>\n",
       "      <th>CATEGORIA</th>\n",
       "      <th>SUMA_PESO_T_1</th>\n",
       "      <th>SUMA_PESO_T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [AGRUPACION, UNIDAD, TABLA, CATEGORIA, SUMA_PESO_T_1, SUMA_PESO_T]\n",
       "Index: []"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Elegir observaciones con falsos en el df de validación, si no hay resultado, el proceso no tiene errores.\n",
    "DF_ST_CATEGORIAS_PESO_CERRADO_VALIDACION[(DF_ST_CATEGORIAS_PESO_CERRADO_VALIDACION['SUMA_PESO_T_1'] == False) | (DF_ST_CATEGORIAS_PESO_CERRADO_VALIDACION['SUMA_PESO_T'] == False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear agrupaciones de hubs, tlcs, continentes\n",
    "df_hubs_tlcs_continentes = crear_df_st_categorias_peso(df_st_categorias=DF_ST_CATEGORIAS_PESO_CERRADO, corrhubs=df_hubs, corrtlcs=df_tlcs, corrcont=df_continentes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear tabla ST_CATEGORIAS_PESO_CERRADO\n",
    "DF_ST_CATEGORIAS_PESO_CERRADO = pd.concat([DF_ST_CATEGORIAS_PESO_CERRADO, df_hubs_tlcs_continentes])\n",
    "# Eliminar filas donde los valores en ambas columnas de sumas sean cero\n",
    "condicion_1 = (DF_ST_CATEGORIAS_PESO_CERRADO['SUMA_PESO_T_1'] == 0) & (DF_ST_CATEGORIAS_PESO_CERRADO['SUMA_PESO_T'] == 0)\n",
    "DF_ST_CATEGORIAS_PESO_CERRADO = DF_ST_CATEGORIAS_PESO_CERRADO[~condicion_1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 ST_CATEGORIAS_PESO_CORRIDO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparación (Preagrupación para asegurar velocidad)\n",
    "df_insumo_minero_nme = df_kg_long.groupby(['PAIS_DESTINO', 'DEPARTAMENTO_ORIGEN', 'MEDIO_TRANSPORTE', 'TIPO', 'YEAR'], as_index=False).agg({'PESO_KG': 'sum'})\n",
    "df_insumo_control_kg = df_kg_long.groupby(['TIPO', 'YEAR'], as_index=False).agg({'PESO_KG': 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agrupación: COLOMBIA, Categoría: MEDIO_TRANSPORTE\n",
      "True True\n",
      "Agrupación: COLOMBIA, Categoría: PAIS_DESTINO\n",
      "True True\n",
      "Agrupación: COLOMBIA, Categoría: MEDIO_TRANSPORTE\n",
      "True True\n",
      "Agrupación: COLOMBIA, Categoría: PAIS_DESTINO\n",
      "True True\n",
      "Agregando totales - Agrupación: COLOMBIA, Unidad: COLOMBIA\n",
      "True True\n",
      "Agregando tipos - Agrupación: COLOMBIA, Unidad: COLOMBIA\n",
      "True True\n",
      "Agrupación: PAISES, Categoría: MEDIO_TRANSPORTE\n",
      "True True\n",
      "Agrupación: PAISES, Categoría: PAIS_DESTINO\n",
      "True True\n",
      "Agrupación: PAISES, Categoría: MEDIO_TRANSPORTE\n",
      "True True\n",
      "Agrupación: PAISES, Categoría: PAIS_DESTINO\n",
      "True True\n",
      "Agregando totales - Agrupación: PAISES, Unidad: PAIS_DESTINO\n",
      "True True\n",
      "Agregando tipos - Agrupación: PAISES, Unidad: PAIS_DESTINO\n",
      "True True\n",
      "Agrupación: DEPARTAMENTOS, Categoría: MEDIO_TRANSPORTE\n",
      "True True\n",
      "Agrupación: DEPARTAMENTOS, Categoría: PAIS_DESTINO\n",
      "True True\n",
      "Agrupación: DEPARTAMENTOS, Categoría: MEDIO_TRANSPORTE\n",
      "True True\n",
      "Agrupación: DEPARTAMENTOS, Categoría: PAIS_DESTINO\n",
      "True True\n",
      "Agregando totales - Agrupación: DEPARTAMENTOS, Unidad: DEPARTAMENTO_ORIGEN\n",
      "True True\n",
      "Agregando tipos - Agrupación: DEPARTAMENTOS, Unidad: DEPARTAMENTO_ORIGEN\n",
      "True True\n"
     ]
    }
   ],
   "source": [
    "# Definir los parámetros\n",
    "AGRUPACIONES = ['COLOMBIA', 'PAISES', 'DEPARTAMENTOS']\n",
    "VALOR_COL = 'PESO_KG'\n",
    "TEMP_PARAMETROS = TEMP_PARAMETROS_CORRIDO \n",
    "\n",
    "# Inicializar DataFrames vacíos para almacenar los resultados finales\n",
    "DF_ST_CATEGORIAS_PESO_CORRIDO = pd.DataFrame()\n",
    "DF_ST_CATEGORIAS_PESO_CORRIDO_VALIDACION = pd.DataFrame()\n",
    "\n",
    "# Loop para ejecutar la función en cada agrupación y concatenar los resultados\n",
    "for AGRUPACION in AGRUPACIONES:\n",
    "    # Ejecutar la función para cada agrupación\n",
    "    df_resultado, df_validacion = generar_tablas_completas_kg(\n",
    "        df=df_insumo_minero_nme,\n",
    "        df_control = df_insumo_control_kg,\n",
    "        agrupacion=AGRUPACION,\n",
    "        valor_col=VALOR_COL,\n",
    "        temp_parametros=TEMP_PARAMETROS\n",
    "    )\n",
    "    \n",
    "    # Concatenar los resultados de cada agrupación\n",
    "    DF_ST_CATEGORIAS_PESO_CORRIDO = pd.concat([DF_ST_CATEGORIAS_PESO_CORRIDO, df_resultado], ignore_index=True)\n",
    "    DF_ST_CATEGORIAS_PESO_CORRIDO_VALIDACION = pd.concat([DF_ST_CATEGORIAS_PESO_CORRIDO_VALIDACION, df_validacion], ignore_index=True)\n",
    "\n",
    "# Cambiar nombres de usd a kg ya que se usa la misma función que las categorias de usd\n",
    "DF_ST_CATEGORIAS_PESO_CORRIDO = DF_ST_CATEGORIAS_PESO_CORRIDO.rename(columns={'SUMA_USD_T_1': 'SUMA_PESO_T_1', 'SUMA_USD_T': 'SUMA_PESO_T'})\n",
    "DF_ST_CATEGORIAS_PESO_CORRIDO_VALIDACION = DF_ST_CATEGORIAS_PESO_CORRIDO_VALIDACION.rename(columns={'SUMA_USD_T_1': 'SUMA_PESO_T_1', 'SUMA_USD_T': 'SUMA_PESO_T'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGRUPACION</th>\n",
       "      <th>UNIDAD</th>\n",
       "      <th>TABLA</th>\n",
       "      <th>CATEGORIA</th>\n",
       "      <th>SUMA_PESO_T_1</th>\n",
       "      <th>SUMA_PESO_T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [AGRUPACION, UNIDAD, TABLA, CATEGORIA, SUMA_PESO_T_1, SUMA_PESO_T]\n",
       "Index: []"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Elegir observaciones con falsos en el df de validación, si no hay resultado, el proceso no tiene errores.\n",
    "DF_ST_CATEGORIAS_PESO_CORRIDO_VALIDACION[(DF_ST_CATEGORIAS_PESO_CORRIDO_VALIDACION['SUMA_PESO_T_1'] == False) | (DF_ST_CATEGORIAS_PESO_CORRIDO_VALIDACION['SUMA_PESO_T'] == False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear agrupaciones de hubs, tlcs, continentes\n",
    "df_hubs_tlcs_continentes = crear_df_st_categorias_peso(df_st_categorias=DF_ST_CATEGORIAS_PESO_CORRIDO, corrhubs=df_hubs, corrtlcs=df_tlcs, corrcont=df_continentes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear tabla ST_CATEGORIAS_PESO_CORRIDO\n",
    "DF_ST_CATEGORIAS_PESO_CORRIDO = pd.concat([DF_ST_CATEGORIAS_PESO_CORRIDO, df_hubs_tlcs_continentes])\n",
    "# Eliminar filas donde los valores en ambas columnas de sumas sean cero\n",
    "condicion_1 = (DF_ST_CATEGORIAS_PESO_CORRIDO['SUMA_PESO_T_1'] == 0) & (DF_ST_CATEGORIAS_PESO_CORRIDO['SUMA_PESO_T'] == 0)\n",
    "DF_ST_CATEGORIAS_PESO_CORRIDO = DF_ST_CATEGORIAS_PESO_CORRIDO[~condicion_1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 ST_NIT_CERRADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparación (Preagrupación para asegurar velocidad)\n",
    "# df_insumo_nits = df_usd_long[(df_usd_long['TIPO'] == 'No Mineras') & (df_usd_long['TIPO_ESTRELLA'] == 'No Mineras') & (~df_usd_long['NIT_EXPORTADOR'].isin(['-1']))]\n",
    "df_insumo_nits = df_usd_long[(df_usd_long['TIPO'] == 'No Mineras')]\n",
    "df_insumo_nits = df_insumo_nits.groupby(['YEAR', 'NIT_EXPORTADOR', 'RAZON_SOCIAL', 'SECTOR_ESTRELLA', 'CONTINENTE', 'DEPARTAMENTO_ORIGEN', 'HUB', 'PAIS_DESTINO'], as_index=False).agg({'VALOR_USD': 'sum'})\n",
    "df_insumo_nits = df_insumo_nits[df_insumo_nits['VALOR_USD']>0]\n",
    "# Base de control\n",
    "df_control_nits = df_insumo_nits.groupby(['YEAR'], as_index=False).agg({'VALOR_USD': 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agrupación: DEPARTAMENTOS, Categoría: DEPARTAMENTO_ORIGEN\n",
      "True True\n",
      "Agrupación: PAISES, Categoría: PAIS_DESTINO\n",
      "True True\n",
      "Agrupación: COLOMBIA, Categoría: COLOMBIA\n",
      "True True\n"
     ]
    }
   ],
   "source": [
    "# Definir los casos de agrupación y sus respectivas columnas de unidad\n",
    "casos_agrupacion = [\n",
    "    {'agrupacion': 'DEPARTAMENTOS', 'unidad_col': 'DEPARTAMENTO_ORIGEN'},\n",
    "    {'agrupacion': 'PAISES', 'unidad_col': 'PAIS_DESTINO'},\n",
    "    {'agrupacion': 'COLOMBIA', 'unidad_col': 'COLOMBIA'}  # Unidad constante\n",
    "]\n",
    "TEMP_PARAMETROS = TEMP_PARAMETROS_CERRADO \n",
    "\n",
    "# Inicializar DataFrames vacíos para almacenar los resultados finales\n",
    "DF_ST_NIT_CERRADO = pd.DataFrame()\n",
    "DF_ST_NIT_CERRADO_VALIDACION = pd.DataFrame()\n",
    "\n",
    "# Para cada caso de agrupación, ejecutar la función y concatenar los resultados\n",
    "for caso in casos_agrupacion:\n",
    "    agrupacion = caso['agrupacion']\n",
    "    unidad_col = caso['unidad_col']\n",
    "    print(f\"Agrupación: {agrupacion}, Categoría: {unidad_col}\")\n",
    "    \n",
    "    # Llamar a la función con los parámetros correspondientes\n",
    "    df_resultado, df_validacion = generar_agrupacion_nits(\n",
    "        df=df_insumo_nits,                     # DataFrame de exportaciones filtrado\n",
    "        df_control=df_control_nits,            # DataFrame de control\n",
    "        temp_parametros=TEMP_PARAMETROS,       # DataFrame con T_1_YEAR y T_YEAR\n",
    "        agrupacion=agrupacion,                 # Agrupación actual (ej. 'CONTINENTES', 'DEPARTAMENTOS')\n",
    "        unidad_col=unidad_col,                 # Columna de la unidad (ej. 'CONTINENTE', 'DEPARTAMENTO_ORIGEN')\n",
    "        tabla='EMPRESAS'                       # Nombre de la tabla (por defecto 'EMPRESAS')\n",
    "    )\n",
    "    \n",
    "    # Concatenar los resultados para este caso con el DataFrame final\n",
    "    DF_ST_NIT_CERRADO = pd.concat([DF_ST_NIT_CERRADO, df_resultado], ignore_index=True)\n",
    "    DF_ST_NIT_CERRADO_VALIDACION = pd.concat([DF_ST_NIT_CERRADO_VALIDACION, df_validacion], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGRUPACION</th>\n",
       "      <th>SUMA_USD_T_1</th>\n",
       "      <th>SUMA_USD_T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [AGRUPACION, SUMA_USD_T_1, SUMA_USD_T]\n",
       "Index: []"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Elegir observaciones con falsos en el df de validación, si no hay resultado, el proceso no tiene errores.\n",
    "DF_ST_NIT_CERRADO_VALIDACION[(DF_ST_NIT_CERRADO_VALIDACION['SUMA_USD_T_1'] == False) | (DF_ST_NIT_CERRADO_VALIDACION['SUMA_USD_T'] == False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear df de insumo para TLCS y HUBS\n",
    "df_insumo_tlcs_hubs = DF_ST_NIT_CERRADO[DF_ST_NIT_CERRADO['AGRUPACION'] == 'PAISES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear agrupaciones de hubs, tlcs, continentes\n",
    "df_nit_tlcs_hubs_continentes = procesar_df_nit(df_input=df_insumo_tlcs_hubs, corrhubs=df_hubs, corrtlcs=df_tlcs, corrcont=df_continentes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear tabla ST_NIT_CERRADO\n",
    "DF_ST_NIT_CERRADO = pd.concat([DF_ST_NIT_CERRADO, df_nit_tlcs_hubs_continentes])\n",
    "# Eliminar filas donde los valores en ambas columnas de sumas sean cero\n",
    "condicion_1 = (DF_ST_NIT_CERRADO['SUMA_USD_T_1'] == 0) & (DF_ST_NIT_CERRADO['SUMA_USD_T'] == 0)\n",
    "DF_ST_NIT_CERRADO = DF_ST_NIT_CERRADO[~condicion_1].reset_index(drop=True)\n",
    "# Agregar crecimiento\n",
    "DF_ST_NIT_CERRADO = agregar_columnas_crecimiento(df=DF_ST_NIT_CERRADO, col_t_1='SUMA_USD_T_1', col_t='SUMA_USD_T')\n",
    "# Eliminar repetidos\n",
    "DF_ST_NIT_CERRADO = DF_ST_NIT_CERRADO.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 ST_NIT_CORRIDO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparación (Preagrupación para asegurar velocidad)\n",
    "# df_insumo_nits = df_usd_long[(df_usd_long['TIPO'] == 'No Mineras') & (df_usd_long['TIPO_ESTRELLA'] == 'No Mineras') & (~df_usd_long['NIT_EXPORTADOR'].isin(['-1']))]\n",
    "df_insumo_nits = df_usd_long[(df_usd_long['TIPO'] == 'No Mineras')]\n",
    "df_insumo_nits = df_insumo_nits.groupby(['YEAR', 'NIT_EXPORTADOR', 'RAZON_SOCIAL', 'SECTOR_ESTRELLA', 'CONTINENTE', 'DEPARTAMENTO_ORIGEN', 'HUB', 'PAIS_DESTINO'], as_index=False).agg({'VALOR_USD': 'sum'})\n",
    "df_insumo_nits = df_insumo_nits[df_insumo_nits['VALOR_USD']>0]\n",
    "# Base de control\n",
    "df_control_nits = df_insumo_nits.groupby(['YEAR'], as_index=False).agg({'VALOR_USD': 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agrupación: DEPARTAMENTOS, Categoría: DEPARTAMENTO_ORIGEN\n",
      "True True\n",
      "Agrupación: PAISES, Categoría: PAIS_DESTINO\n",
      "True True\n",
      "Agrupación: COLOMBIA, Categoría: COLOMBIA\n",
      "True True\n"
     ]
    }
   ],
   "source": [
    "# Definir los casos de agrupación y sus respectivas columnas de unidad\n",
    "casos_agrupacion = [\n",
    "    {'agrupacion': 'DEPARTAMENTOS', 'unidad_col': 'DEPARTAMENTO_ORIGEN'},\n",
    "    {'agrupacion': 'PAISES', 'unidad_col': 'PAIS_DESTINO'},\n",
    "    {'agrupacion': 'COLOMBIA', 'unidad_col': 'COLOMBIA'}  # Unidad constante\n",
    "]\n",
    "TEMP_PARAMETROS = TEMP_PARAMETROS_CORRIDO \n",
    "\n",
    "# Inicializar DataFrames vacíos para almacenar los resultados finales\n",
    "DF_ST_NIT_CORRIDO = pd.DataFrame()\n",
    "DF_ST_NIT_CORRIDO_VALIDACION = pd.DataFrame()\n",
    "\n",
    "# Para cada caso de agrupación, ejecutar la función y concatenar los resultados\n",
    "for caso in casos_agrupacion:\n",
    "    agrupacion = caso['agrupacion']\n",
    "    unidad_col = caso['unidad_col']\n",
    "    print(f\"Agrupación: {agrupacion}, Categoría: {unidad_col}\")\n",
    "    \n",
    "    # Llamar a la función con los parámetros correspondientes\n",
    "    df_resultado, df_validacion = generar_agrupacion_nits(\n",
    "        df=df_insumo_nits,                     # DataFrame de exportaciones filtrado\n",
    "        df_control=df_control_nits,            # DataFrame de control\n",
    "        temp_parametros=TEMP_PARAMETROS,       # DataFrame con T_1_YEAR y T_YEAR\n",
    "        agrupacion=agrupacion,                 # Agrupación actual (ej. 'CONTINENTES', 'DEPARTAMENTOS')\n",
    "        unidad_col=unidad_col,                 # Columna de la unidad (ej. 'CONTINENTE', 'DEPARTAMENTO_ORIGEN')\n",
    "        tabla='EMPRESAS'                       # Nombre de la tabla (por defecto 'EMPRESAS')\n",
    "    )\n",
    "    \n",
    "    # Concatenar los resultados para este caso con el DataFrame final\n",
    "    DF_ST_NIT_CORRIDO = pd.concat([DF_ST_NIT_CORRIDO, df_resultado], ignore_index=True)\n",
    "    DF_ST_NIT_CORRIDO_VALIDACION = pd.concat([DF_ST_NIT_CORRIDO_VALIDACION, df_validacion], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGRUPACION</th>\n",
       "      <th>SUMA_USD_T_1</th>\n",
       "      <th>SUMA_USD_T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [AGRUPACION, SUMA_USD_T_1, SUMA_USD_T]\n",
       "Index: []"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Elegir observaciones con falsos en el df de validación, si no hay resultado, el proceso no tiene errores.\n",
    "DF_ST_NIT_CORRIDO_VALIDACION[(DF_ST_NIT_CORRIDO_VALIDACION['SUMA_USD_T_1'] == False) | (DF_ST_NIT_CORRIDO_VALIDACION['SUMA_USD_T'] == False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear df de insumo para TLCS y HUBS\n",
    "df_insumo_tlcs_hubs = DF_ST_NIT_CORRIDO[DF_ST_NIT_CORRIDO['AGRUPACION'] == 'PAISES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear agrupaciones de hubs, tlcs, continentes\n",
    "df_nit_tlcs_hubs_continentes = procesar_df_nit(df_input=df_insumo_tlcs_hubs, corrhubs=df_hubs, corrtlcs=df_tlcs, corrcont=df_continentes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear tabla ST_NIT_CORRIDO\n",
    "DF_ST_NIT_CORRIDO = pd.concat([DF_ST_NIT_CORRIDO, df_nit_tlcs_hubs_continentes])\n",
    "# Eliminar filas donde los valores en ambas columnas de sumas sean cero\n",
    "condicion_1 = (DF_ST_NIT_CORRIDO['SUMA_USD_T_1'] == 0) & (DF_ST_NIT_CORRIDO['SUMA_USD_T'] == 0)\n",
    "DF_ST_NIT_CORRIDO = DF_ST_NIT_CORRIDO[~condicion_1].reset_index(drop=True)\n",
    "# Agregar crecimiento\n",
    "DF_ST_NIT_CORRIDO = agregar_columnas_crecimiento(df=DF_ST_NIT_CORRIDO, col_t_1='SUMA_USD_T_1', col_t='SUMA_USD_T')\n",
    "# Eliminar repetidos\n",
    "DF_ST_NIT_CORRIDO = DF_ST_NIT_CORRIDO.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 ST_CONTEO_CERRADO y ST_CONTEO_CORRIDO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar conteos:\n",
    "ST_CONTEO_CERRADO, ST_CONTEO_CORRIDO = contar_empresas_total(df_long=df_usd_long, \n",
    "                                                             temp_parametros_cerrado=TEMP_PARAMETROS_CERRADO, \n",
    "                                                             temp_parametros_corrido=TEMP_PARAMETROS_CORRIDO, \n",
    "                                                             df_list=df_geo_list, \n",
    "                                                             umbral=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conteo cerrado\n",
    "ST_CONTEO_CERRADO = ST_CONTEO_CERRADO.reset_index()\n",
    "ST_CONTEO_CERRADO = ST_CONTEO_CERRADO[['AGRUPACION', 'UNIDAD', 'CONTEO_T_1', 'CONTEO_T']]\n",
    "# Eliminar filas donde los valores en ambas columnas de sumas sean cero\n",
    "condicion_1 = (ST_CONTEO_CERRADO['CONTEO_T_1'] == 0) & (ST_CONTEO_CERRADO['CONTEO_T'] == 0)\n",
    "ST_CONTEO_CERRADO = ST_CONTEO_CERRADO[~condicion_1].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conteo corrido\n",
    "ST_CONTEO_CORRIDO = ST_CONTEO_CORRIDO.reset_index()\n",
    "ST_CONTEO_CORRIDO = ST_CONTEO_CORRIDO[['AGRUPACION', 'UNIDAD', 'CONTEO_T_1', 'CONTEO_T']]\n",
    "# Eliminar filas donde los valores en ambas columnas de sumas sean cero\n",
    "condicion_1 = (ST_CONTEO_CORRIDO['CONTEO_T_1'] == 0) & (ST_CONTEO_CORRIDO['CONTEO_T'] == 0)\n",
    "ST_CONTEO_CORRIDO = ST_CONTEO_CORRIDO[~condicion_1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Oportunidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solo se debe cambiar la ubicación del archivo\n",
    "path_insumos = 'C:/Users/nrivera/OneDrive - PROCOLOMBIA/Documentos/017B-Documentos-Colombia/Cargue/Insumos/EXPORTACIONES/'\n",
    "oportunidades_file = 'Oportunidades.xlsx'\n",
    "dict_file = 'Diccionario-Departamentos-Oportunidades.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar datos\n",
    "df_oportunidades = pd.read_excel(path_insumos + oportunidades_file, sheet_name=\"Base_proyectos\", dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Eje', 'Apuesta', 'Cadena', 'Sector', 'Subsector', 'Producto', 'HUB',\n",
       "       'Pais', 'Departamento', 'Continente'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_oportunidades.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiar nombres para snowflake\n",
    "df_oportunidades = df_oportunidades.rename(columns={\n",
    "    'Eje' : 'EJE', \n",
    "    'Apuesta' : 'APUESTA',\n",
    "    'Cadena' :'CADENA', \n",
    "    'Sector': 'SECTOR', \n",
    "    'Subsector': 'SUBSECTOR', \n",
    "    'Producto' : 'PRODUCTO', \n",
    "    'HUB': 'HUB',\n",
    "    'Pais' : 'PAIS',\n",
    "    'Departamento' : 'DEPARTAMENTO',\n",
    "    'Continente' : 'CONTINENTE'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar datos de nombres\n",
    "df_dict_nombres = pd.read_excel(path_insumos + dict_file, sheet_name=\"Hoja1\", dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar códigos de nombres departamentos\n",
    "df_oportunidades = pd.merge(df_oportunidades, df_dict_nombres, on=['DEPARTAMENTO'], how='left')\n",
    "# Cambiar nombres \n",
    "df_oportunidades = df_oportunidades.rename(columns={\n",
    "    'COD_DIVIPOLA' : 'COD_DIVIPOLA_DEPARTAMENTO'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=object)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirmar que todo cruza\n",
    "df_oportunidades[df_oportunidades['PAIS'].isnull()]['COD_DIVIPOLA_DEPARTAMENTO'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Balanza Comercial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solo se debe cambiar la ubicación del archivo\n",
    "path_insumos = 'C:/Users/nrivera/OneDrive - PROCOLOMBIA/Documentos/017B-Documentos-Colombia/Cargue/Insumos/EXPORTACIONES/'\n",
    "balanza_file = 'Balanza Comercial.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar datos\n",
    "df_importaciones = pd.read_excel(path_insumos + balanza_file, sheet_name=\"IMPORTACIONES\", dtype= {'PAIS': str,\n",
    "                                                                                                  'AÑO': str,\n",
    "                                                                                                  'TIPO': str,\n",
    "                                                                                                  'FOB_USD': float})\n",
    "df_exportaciones = pd.read_excel(path_insumos + balanza_file, sheet_name=\"EXPORTACIONES\", dtype= {'PAIS': str,\n",
    "                                                                                                  'AÑO': str,\n",
    "                                                                                                  'TIPO': str,\n",
    "                                                                                                  'FOB_USD': float})\n",
    "\n",
    "# Cambiar nombres correctamente\n",
    "df_importaciones = df_importaciones.rename(columns={'PAIS': 'PAIS', 'AÑO': 'YEAR', 'TIPO': 'TIPO', 'FOB_USD': 'IMPORTACIONES_FOB'})\n",
    "df_exportaciones = df_exportaciones.rename(columns={'PAIS': 'PAIS', 'AÑO': 'YEAR', 'TIPO': 'TIPO', 'FOB_USD': 'EXPORTACIONES_FOB'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear totales\n",
    "\n",
    "# Exportaciones\n",
    "df_total_exportaciones = df_exportaciones.groupby(['PAIS', 'YEAR'])[['EXPORTACIONES_FOB']].sum().reset_index()\n",
    "# Agrega tipo\n",
    "df_total_exportaciones['TIPO'] = 'Total'\n",
    "# Ordenar columnas\n",
    "df_total_exportaciones = df_total_exportaciones[['PAIS', 'YEAR', 'TIPO', 'EXPORTACIONES_FOB']]\n",
    "# Agregar al dataframe por país\n",
    "df_exportaciones = pd.concat([df_exportaciones, df_total_exportaciones])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear totales\n",
    "\n",
    "# Importaciones\n",
    "df_total_importaciones = df_importaciones.groupby(['PAIS', 'YEAR'])[['IMPORTACIONES_FOB']].sum().reset_index()\n",
    "# Agrega tipo\n",
    "df_total_importaciones['TIPO'] = 'Total'\n",
    "# Ordenar columnas\n",
    "df_total_importaciones = df_total_importaciones[['PAIS', 'YEAR', 'TIPO', 'IMPORTACIONES_FOB']]\n",
    "# Agregar al dataframe por país\n",
    "df_importaciones = pd.concat([df_importaciones, df_total_importaciones])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear balanza comercial Colombia\n",
    "total_impo = df_importaciones.groupby(['TIPO', 'YEAR'])[['IMPORTACIONES_FOB']].sum().reset_index()\n",
    "total_expo = df_exportaciones.groupby(['TIPO', 'YEAR'])[['EXPORTACIONES_FOB']].sum().reset_index()\n",
    "\n",
    "# Crear agregado de totales\n",
    "df_total_balanza = pd.merge(total_impo, total_expo, on=['TIPO', 'YEAR'], how='left')\n",
    "\n",
    "# País Colombia total\n",
    "df_total_balanza['PAIS'] = 'COLOMBIA'\n",
    "\n",
    "# Ordenar columnas\n",
    "df_total_balanza = df_total_balanza[['PAIS', 'YEAR', 'TIPO', 'IMPORTACIONES_FOB', 'EXPORTACIONES_FOB']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear base por país\n",
    "df_balanza_insumo = pd.merge(df_importaciones, df_exportaciones, on=['PAIS', 'TIPO', 'YEAR'], how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar suma total de balanza de Colombia\n",
    "df_balanza_insumo = pd.concat([df_balanza_insumo, df_total_balanza])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rellenar los campos 'IMPORTACIONES_FOB' y 'EXPORTACIONES_FOB' con 0 donde haya NaN\n",
    "df_balanza_insumo[['IMPORTACIONES_FOB', 'EXPORTACIONES_FOB']] = df_balanza_insumo[['IMPORTACIONES_FOB', 'EXPORTACIONES_FOB']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular balanza\n",
    "df_balanza_insumo['BALANZA'] = df_balanza_insumo['EXPORTACIONES_FOB'] - df_balanza_insumo['IMPORTACIONES_FOB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elegir columnas \n",
    "df_balanza_final = df_balanza_insumo[['PAIS', 'YEAR', 'TIPO', 'BALANZA']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Tablas TLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se trae la tabla de tlcs con la llave de expotaciones\n",
    "query_tlcs = \"\"\"\n",
    "SELECT *\n",
    "FROM DOCUMENTOS_COLOMBIA.GEOGRAFIA.TLCS_TABLA AS A\n",
    "ORDER BY A.PAIS_LLAVE_EXPORTACIONES ASC;\n",
    "\"\"\"\n",
    "# Ejecutar\n",
    "df_paises_tlcs = snow_func.snowflake_sql(conn, query_tlcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1 Colombia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traer datos cerrados de exportaciones\n",
    "df_insumo_cerrado_colombia = DF_ST_CATEGORIAS_CERRADO.loc[(DF_ST_CATEGORIAS_CERRADO['AGRUPACION'] == 'PAISES') &\n",
    "                             (DF_ST_CATEGORIAS_CERRADO['TABLA'] == 'TIPOS') &\n",
    "                             (DF_ST_CATEGORIAS_CERRADO['CATEGORIA'] == 'No Mineras'),\n",
    "                            ['UNIDAD', 'SUMA_USD_T_1', 'SUMA_USD_T']]\n",
    "\n",
    "# Traer datos corridos de exportaciones\n",
    "df_insumo_corrido_colombia = DF_ST_CATEGORIAS_CORRIDO.loc[(DF_ST_CATEGORIAS_CORRIDO['AGRUPACION'] == 'PAISES') &\n",
    "                             (DF_ST_CATEGORIAS_CORRIDO['TABLA'] == 'TIPOS') &\n",
    "                             (DF_ST_CATEGORIAS_CORRIDO['CATEGORIA'] == 'No Mineras'),\n",
    "                            ['UNIDAD', 'SUMA_USD_T_1', 'SUMA_USD_T']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procedimiento para cerrado\n",
    "\n",
    "# Unir valores exportados a los países definidos por TLCs en la tabla relacional\n",
    "df_tlcs_colombia_cerrado = df_paises_tlcs.merge(df_insumo_cerrado_colombia, how='left', left_on='PAIS_LLAVE_EXPORTACIONES', right_on='UNIDAD')\n",
    "\n",
    "# Crear las sumas por TLC\n",
    "df_tlcs_colombia_cerrado = df_tlcs_colombia_cerrado.groupby('NOMBRE_TLC', as_index=False)[['SUMA_USD_T_1', 'SUMA_USD_T']].sum()\n",
    "\n",
    "# Crear columnas extras\n",
    "df_tlcs_colombia_cerrado['AGRUPACION'] = 'COLOMBIA'\n",
    "df_tlcs_colombia_cerrado['UNIDAD'] = 'COLOMBIA'\n",
    "df_tlcs_colombia_cerrado['TABLA'] = 'TLCS'\n",
    "\n",
    "# Agregar columna de diferencia absoluta y porcentual\n",
    "# Absoluta\n",
    "df_tlcs_colombia_cerrado['DIFERENCIA_ABSOLUTA'] = df_tlcs_colombia_cerrado['SUMA_USD_T'] - df_tlcs_colombia_cerrado['SUMA_USD_T_1']\n",
    "# Porcentual\n",
    "df_tlcs_colombia_cerrado['DIFERENCIA_PORCENTUAL'] = np.where(\n",
    "    df_tlcs_colombia_cerrado['SUMA_USD_T_1'] == 0,\n",
    "    np.where(df_tlcs_colombia_cerrado['SUMA_USD_T'] > 0, 100, np.where(df_tlcs_colombia_cerrado['SUMA_USD_T'] == 0, 0, -100)),\n",
    "    (df_tlcs_colombia_cerrado['DIFERENCIA_ABSOLUTA'] / df_tlcs_colombia_cerrado['SUMA_USD_T_1']) * 100\n",
    ")\n",
    "\n",
    "# Cambiar nombre de TLC a categoria para mantener consistencia\n",
    "df_tlcs_colombia_cerrado = df_tlcs_colombia_cerrado.rename(columns={'NOMBRE_TLC': 'CATEGORIA'})\n",
    "\n",
    "# Reorndear columnas\n",
    "df_tlcs_colombia_cerrado = df_tlcs_colombia_cerrado[['AGRUPACION', 'UNIDAD', 'TABLA', 'CATEGORIA', 'SUMA_USD_T_1','SUMA_USD_T', 'DIFERENCIA_ABSOLUTA', 'DIFERENCIA_PORCENTUAL']]\n",
    "\n",
    "# Eliminar filas donde los valores en ambas columnas de sumas sean cero\n",
    "condicion_1 = (df_tlcs_colombia_cerrado['SUMA_USD_T_1'] == 0) & (df_tlcs_colombia_cerrado['SUMA_USD_T'] == 0)\n",
    "df_tlcs_colombia_cerrado = df_tlcs_colombia_cerrado[~condicion_1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar datos a tabla ST_CATEGORIAS_CERRADO\n",
    "DF_ST_CATEGORIAS_CERRADO = pd.concat([DF_ST_CATEGORIAS_CERRADO, df_tlcs_colombia_cerrado])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procedimiento para corrido\n",
    "\n",
    "# Unir valores exportados a los países definidos por TLCs en la tabla relacional\n",
    "df_tlcs_colombia_corrido = df_paises_tlcs.merge(df_insumo_corrido_colombia, how='left', left_on='PAIS_LLAVE_EXPORTACIONES', right_on='UNIDAD')\n",
    "\n",
    "# Crear las sumas por TLC\n",
    "df_tlcs_colombia_corrido = df_tlcs_colombia_corrido.groupby('NOMBRE_TLC', as_index=False)[['SUMA_USD_T_1', 'SUMA_USD_T']].sum()\n",
    "\n",
    "# Crear columnas extras\n",
    "df_tlcs_colombia_corrido['AGRUPACION'] = 'COLOMBIA'\n",
    "df_tlcs_colombia_corrido['UNIDAD'] = 'COLOMBIA'\n",
    "df_tlcs_colombia_corrido['TABLA'] = 'TLCS'\n",
    "\n",
    "# Agregar columna de diferencia absoluta y porcentual\n",
    "# Absoluta\n",
    "df_tlcs_colombia_corrido['DIFERENCIA_ABSOLUTA'] = df_tlcs_colombia_corrido['SUMA_USD_T'] - df_tlcs_colombia_corrido['SUMA_USD_T_1']\n",
    "# Porcentual\n",
    "df_tlcs_colombia_corrido['DIFERENCIA_PORCENTUAL'] = np.where(\n",
    "    df_tlcs_colombia_corrido['SUMA_USD_T_1'] == 0,\n",
    "    np.where(df_tlcs_colombia_corrido['SUMA_USD_T'] > 0, 100, np.where(df_tlcs_colombia_corrido['SUMA_USD_T'] == 0, 0, -100)),\n",
    "    (df_tlcs_colombia_corrido['DIFERENCIA_ABSOLUTA'] / df_tlcs_colombia_corrido['SUMA_USD_T_1']) * 100\n",
    ")\n",
    "\n",
    "# Cambiar nombre de TLC a categoria para mantener consistencia\n",
    "df_tlcs_colombia_corrido = df_tlcs_colombia_corrido.rename(columns={'NOMBRE_TLC': 'CATEGORIA'})\n",
    "\n",
    "# Reorndear columnas\n",
    "df_tlcs_colombia_corrido = df_tlcs_colombia_corrido[['AGRUPACION', 'UNIDAD', 'TABLA', 'CATEGORIA', 'SUMA_USD_T_1','SUMA_USD_T', 'DIFERENCIA_ABSOLUTA', 'DIFERENCIA_PORCENTUAL']]\n",
    "\n",
    "# Eliminar filas donde los valores en ambas columnas de sumas sean cero\n",
    "condicion_1 = (df_tlcs_colombia_corrido['SUMA_USD_T_1'] == 0) & (df_tlcs_colombia_corrido['SUMA_USD_T'] == 0)\n",
    "df_tlcs_colombia_corrido = df_tlcs_colombia_corrido[~condicion_1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar datos a tabla ST_CATEGORIAS_CORRIDO\n",
    "DF_ST_CATEGORIAS_CORRIDO = pd.concat([DF_ST_CATEGORIAS_CORRIDO, df_tlcs_colombia_corrido])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2 Departamentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traer datos cerrados de exportaciones\n",
    "df_insumo_cerrado_departamento = DF_ST_CATEGORIAS_CERRADO.loc[(DF_ST_CATEGORIAS_CERRADO['AGRUPACION'] == 'DEPARTAMENTOS') &\n",
    "                             (DF_ST_CATEGORIAS_CERRADO['TABLA'] == 'PAIS'),\n",
    "                            ['UNIDAD', 'CATEGORIA', 'SUMA_USD_T_1', 'SUMA_USD_T']]\n",
    "\n",
    "# Traer datos corridos de exportaciones\n",
    "df_insumo_corrido_departamento = DF_ST_CATEGORIAS_CORRIDO.loc[(DF_ST_CATEGORIAS_CORRIDO['AGRUPACION'] == 'DEPARTAMENTOS') &\n",
    "                             (DF_ST_CATEGORIAS_CORRIDO['TABLA'] == 'PAIS'),\n",
    "                            ['UNIDAD', 'CATEGORIA', 'SUMA_USD_T_1', 'SUMA_USD_T']]\n",
    "\n",
    "# Crear df con todas la combinaciones posibles de departamentos\n",
    "\n",
    "# Cerrado\n",
    "df_departamentos_cerrado = DF_ST_CATEGORIAS_CERRADO.loc[(DF_ST_CATEGORIAS_CERRADO['AGRUPACION'] == 'DEPARTAMENTOS') &\n",
    "                             (DF_ST_CATEGORIAS_CERRADO['TABLA'] == 'PAIS'),\n",
    "                            ['AGRUPACION', 'UNIDAD']].drop_duplicates()\n",
    "\n",
    "# Corrido\n",
    "df_departamentos_corrido = DF_ST_CATEGORIAS_CORRIDO.loc[(DF_ST_CATEGORIAS_CORRIDO['AGRUPACION'] == 'DEPARTAMENTOS') &\n",
    "                             (DF_ST_CATEGORIAS_CORRIDO['TABLA'] == 'PAIS'),\n",
    "                            ['AGRUPACION', 'UNIDAD']].drop_duplicates()\n",
    "\n",
    "# Opciones totales\n",
    "df_departamentos = pd.concat([df_departamentos_cerrado, df_departamentos_corrido]).drop_duplicates()\n",
    "\n",
    "# Agregar combinaciones de tlcs\n",
    "df_departamentos = df_departamentos.merge(df_paises_tlcs, how='cross')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procedimiento para cerrado\n",
    "\n",
    "# Unir valores exportados a los departamentos definidos\n",
    "df_tlcs_departamentos_cerrado = df_departamentos.merge(df_insumo_cerrado_departamento, how='left', left_on=['UNIDAD', 'PAIS_LLAVE_EXPORTACIONES'], right_on=['UNIDAD', 'CATEGORIA'])\n",
    "\n",
    "# Crear las sumas por TLC\n",
    "df_tlcs_departamentos_cerrado = df_tlcs_departamentos_cerrado.groupby(['AGRUPACION', 'UNIDAD', 'NOMBRE_TLC'], as_index=False)[['SUMA_USD_T_1', 'SUMA_USD_T']].sum()\n",
    "\n",
    "# Crear columnas extras\n",
    "df_tlcs_departamentos_cerrado['TABLA'] = 'TLCS'\n",
    "\n",
    "# Agregar columna de diferencia absoluta y porcentual\n",
    "# Absoluta\n",
    "df_tlcs_departamentos_cerrado['DIFERENCIA_ABSOLUTA'] = df_tlcs_departamentos_cerrado['SUMA_USD_T'] - df_tlcs_departamentos_cerrado['SUMA_USD_T_1']\n",
    "# Porcentual\n",
    "df_tlcs_departamentos_cerrado['DIFERENCIA_PORCENTUAL'] = np.where(\n",
    "    df_tlcs_departamentos_cerrado['SUMA_USD_T_1'] == 0,\n",
    "    np.where(df_tlcs_departamentos_cerrado['SUMA_USD_T'] > 0, 100, np.where(df_tlcs_departamentos_cerrado['SUMA_USD_T'] == 0, 0, -100)),\n",
    "    (df_tlcs_departamentos_cerrado['DIFERENCIA_ABSOLUTA'] / df_tlcs_departamentos_cerrado['SUMA_USD_T_1']) * 100\n",
    ")\n",
    "\n",
    "# Cambiar nombre de TLC a categoria para mantener consistencia\n",
    "df_tlcs_departamentos_cerrado = df_tlcs_departamentos_cerrado.rename(columns={'NOMBRE_TLC': 'CATEGORIA'})\n",
    "\n",
    "# Reorndear columnas\n",
    "df_tlcs_departamentos_cerrado = df_tlcs_departamentos_cerrado[['AGRUPACION', 'UNIDAD', 'TABLA', 'CATEGORIA', 'SUMA_USD_T_1','SUMA_USD_T', 'DIFERENCIA_ABSOLUTA', 'DIFERENCIA_PORCENTUAL']]\n",
    "\n",
    "# Eliminar filas donde los valores en ambas columnas de sumas sean cero\n",
    "condicion_1 = (df_tlcs_departamentos_cerrado['SUMA_USD_T_1'] == 0) & (df_tlcs_departamentos_cerrado['SUMA_USD_T'] == 0)\n",
    "df_tlcs_departamentos_cerrado = df_tlcs_departamentos_cerrado[~condicion_1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar datos a tabla ST_CATEGORIAS_CERRADO\n",
    "DF_ST_CATEGORIAS_CERRADO = pd.concat([DF_ST_CATEGORIAS_CERRADO, df_tlcs_departamentos_cerrado])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procedimiento para corrido\n",
    "\n",
    "# Unir valores exportados a los departamentos definidos\n",
    "df_tlcs_departamentos_corrido = df_departamentos.merge(df_insumo_corrido_departamento, how='left', left_on=['UNIDAD', 'PAIS_LLAVE_EXPORTACIONES'], right_on=['UNIDAD', 'CATEGORIA'])\n",
    "\n",
    "# Crear las sumas por TLC\n",
    "df_tlcs_departamentos_corrido = df_tlcs_departamentos_corrido.groupby(['AGRUPACION', 'UNIDAD', 'NOMBRE_TLC'], as_index=False)[['SUMA_USD_T_1', 'SUMA_USD_T']].sum()\n",
    "\n",
    "# Crear columnas extras\n",
    "df_tlcs_departamentos_corrido['TABLA'] = 'TLCS'\n",
    "\n",
    "# Agregar columna de diferencia absoluta y porcentual\n",
    "# Absoluta\n",
    "df_tlcs_departamentos_corrido['DIFERENCIA_ABSOLUTA'] = df_tlcs_departamentos_corrido['SUMA_USD_T'] - df_tlcs_departamentos_corrido['SUMA_USD_T_1']\n",
    "# Porcentual\n",
    "df_tlcs_departamentos_corrido['DIFERENCIA_PORCENTUAL'] = np.where(\n",
    "    df_tlcs_departamentos_corrido['SUMA_USD_T_1'] == 0,\n",
    "    np.where(df_tlcs_departamentos_corrido['SUMA_USD_T'] > 0, 100, np.where(df_tlcs_departamentos_corrido['SUMA_USD_T'] == 0, 0, -100)),\n",
    "    (df_tlcs_departamentos_corrido['DIFERENCIA_ABSOLUTA'] / df_tlcs_departamentos_corrido['SUMA_USD_T_1']) * 100\n",
    ")\n",
    "\n",
    "# Cambiar nombre de TLC a categoria para mantener consistencia\n",
    "df_tlcs_departamentos_corrido = df_tlcs_departamentos_corrido.rename(columns={'NOMBRE_TLC': 'CATEGORIA'})\n",
    "\n",
    "# Reorndear columnas\n",
    "df_tlcs_departamentos_corrido = df_tlcs_departamentos_corrido[['AGRUPACION', 'UNIDAD', 'TABLA', 'CATEGORIA', 'SUMA_USD_T_1','SUMA_USD_T', 'DIFERENCIA_ABSOLUTA', 'DIFERENCIA_PORCENTUAL']]\n",
    "\n",
    "# Eliminar filas donde los valores en ambas columnas de sumas sean cero\n",
    "condicion_1 = (df_tlcs_departamentos_corrido['SUMA_USD_T_1'] == 0) & (df_tlcs_departamentos_corrido['SUMA_USD_T'] == 0)\n",
    "df_tlcs_departamentos_corrido = df_tlcs_departamentos_corrido[~condicion_1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar datos a tabla ST_CATEGORIAS_CORRIDO\n",
    "DF_ST_CATEGORIAS_CORRIDO = pd.concat([DF_ST_CATEGORIAS_CORRIDO, df_tlcs_departamentos_corrido])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Crear base de datos de validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir los nombres de las columnas y agrupaciones\n",
    "columna_base_exportaciones = ['Continente', 'Pais Destino', 'HUB', 'Departamento Origen']\n",
    "agrupacion_base_exportaciones = ['CONTINENTES', 'PAISES', 'HUBS', 'DEPARTAMENTOS']\n",
    "\n",
    "# Columnas a sumar\n",
    "columnas_cerrado = {'USD': ['2022 USD', '2023 USD'], 'KG': ['2022 KG Neto', '2023 KG Neto']}\n",
    "columnas_corrido = {'USD': ['2023 USD (Ene-Oct)', '2024 USD (Ene-Oct)'], 'KG': ['2023 KG Neto (Ene-Oct)', '2024 KG Neto (Ene-Oct)']}\n",
    "\n",
    "# Crear diccionario para la validación\n",
    "# Diccionario con las columnas para cada tipo de período y medida\n",
    "columnas_dict = {\n",
    "    'CERRADO': {\n",
    "        'USD': ['2022 USD', '2023 USD'],\n",
    "        'KG': ['2022 KG Neto', '2023 KG Neto']\n",
    "    },\n",
    "    'CORRIDO': {\n",
    "        'USD': ['2023 USD (Ene-Oct)', '2024 USD (Ene-Oct)'],\n",
    "        'KG': ['2023 KG Neto (Ene-Oct)', '2024 KG Neto (Ene-Oct)']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Especificar las medidas y tipos de periodo a considerar\n",
    "medidas = ['USD', 'KG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_validacion(df, columnas, medida, tipo_periodo):\n",
    "    \"\"\"\n",
    "    Genera un DataFrame de validación para los totales de exportaciones agrupados por una columna base.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame fuente con los datos de exportaciones.\n",
    "        columnas (list): Lista de dos columnas numéricas a sumar (por ejemplo, USD o KG).\n",
    "        medida (str): Unidad de medida, como 'USD' o 'KG'.\n",
    "        tipo_periodo (str): Tipo de periodo, como 'CERRADO' o 'CORRIDO'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame con las exportaciones agrupadas y columnas renombradas:\n",
    "            - AGRUPACION: Tipo de agrupación (CONTINENTES, PAISES, etc.).\n",
    "            - UNIDAD: Nombre de la unidad de agrupación.\n",
    "            - MEDIDA: Unidad de medida (USD o KG).\n",
    "            - TIPO_PERIODO: Tipo de periodo (CERRADO o CORRIDO).\n",
    "            - SUMA_T_1: Suma del primer año/periodo.\n",
    "            - SUMA_T: Suma del segundo año/periodo.\n",
    "    \"\"\"\n",
    "    # Inicializar un DataFrame vacío para almacenar los resultados\n",
    "    df_validacion = pd.DataFrame()\n",
    "\n",
    "    # Iterar sobre las columnas base de exportaciones y sus agrupaciones\n",
    "    for columna, agrupacion in zip(columna_base_exportaciones, agrupacion_base_exportaciones):\n",
    "        # Agrupar el DataFrame fuente por la columna base y sumar las columnas especificadas\n",
    "        df_agrupado = df.groupby([columna])[columnas].sum().reset_index()\n",
    "\n",
    "        # Renombrar columnas de las sumas\n",
    "        df_agrupado.rename(columns={columnas[0]: 'SUMA_T_1', columnas[1]: 'SUMA_T'}, inplace=True)\n",
    "        \n",
    "        # Renombrar la columna base a 'UNIDAD' para estandarización\n",
    "        df_agrupado.rename(columns={columna: 'UNIDAD'}, inplace=True)\n",
    "        \n",
    "        # Agregar las columnas adicionales al DataFrame agrupado\n",
    "        df_agrupado['AGRUPACION'] = agrupacion\n",
    "        df_agrupado['MEDIDA'] = medida\n",
    "        df_agrupado['TIPO_PERIODO'] = tipo_periodo\n",
    "\n",
    "        # Reorganizar las columnas\n",
    "        df_agrupado = df_agrupado[['AGRUPACION', 'UNIDAD', 'MEDIDA', 'TIPO_PERIODO', 'SUMA_T_1', 'SUMA_T']]\n",
    "\n",
    "        # Concatenar los resultados al DataFrame de validación\n",
    "        df_validacion = pd.concat([df_validacion, df_agrupado], ignore_index=True)\n",
    "\n",
    "    return df_validacion\n",
    "\n",
    "\n",
    "def generar_validacion_colombia(df, columnas, medida, tipo_periodo):\n",
    "    \"\"\"\n",
    "    Genera un DataFrame de validación para Colombia, calculando los totales de las columnas numéricas.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame fuente con los datos de exportaciones.\n",
    "        columnas (list): Lista de dos columnas numéricas a sumar (por ejemplo, USD o KG).\n",
    "        medida (str): Unidad de medida, como 'USD' o 'KG'.\n",
    "        tipo_periodo (str): Tipo de periodo, como 'CERRADO' o 'CORRIDO'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame con los totales de exportaciones para Colombia, incluyendo:\n",
    "            - AGRUPACION: \"COLOMBIA\".\n",
    "            - UNIDAD: \"COLOMBIA\".\n",
    "            - MEDIDA: Unidad de medida (USD o KG).\n",
    "            - TIPO_PERIODO: Tipo de periodo (CERRADO o CORRIDO).\n",
    "            - SUMA_T_1: Suma del primer año/periodo.\n",
    "            - SUMA_T: Suma del segundo año/periodo.\n",
    "    \"\"\"\n",
    "    # Calcular los totales directamente\n",
    "    totales = df[columnas].sum()\n",
    "\n",
    "    # Crear un DataFrame con los totales y columnas adicionales\n",
    "    totales_df = pd.DataFrame([{\n",
    "        'AGRUPACION': 'COLOMBIA',\n",
    "        'UNIDAD': 'COLOMBIA',\n",
    "        'MEDIDA': medida,\n",
    "        'TIPO_PERIODO': tipo_periodo,\n",
    "        'SUMA_T_1': totales[columnas[0]],\n",
    "        'SUMA_T': totales[columnas[1]]\n",
    "    }])\n",
    "\n",
    "    return totales_df\n",
    "\n",
    "\n",
    "def generar_validaciones(df, columnas_dict, medidas, tipos_periodo, incluir_colombia=False):\n",
    "    \"\"\"\n",
    "    Genera un DataFrame consolidado de validación a partir de diferentes combinaciones\n",
    "    de columnas, medidas y períodos.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame de entrada con los datos base.\n",
    "        columnas_dict (dict): Diccionario con claves para tipos de período y medidas.\n",
    "        medidas (list): Lista de medidas, como ['USD', 'KG'].\n",
    "        tipos_periodo (list): Lista de tipos de período (pueden incluir componentes adicionales).\n",
    "                              Ejemplo: ['CERRADO-TOTAL-EXPORTADO', 'CORRIDO-TOTAL-EXPORTADO'].\n",
    "        incluir_colombia (bool): Si se incluye la validación para el total de Colombia.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame consolidado con todas las validaciones generadas.\n",
    "    \"\"\"\n",
    "    df_validacion_final = pd.DataFrame()\n",
    "\n",
    "    for tipo_periodo in tipos_periodo:\n",
    "        # Extraer la clave del período para buscar en columnas_dict\n",
    "        periodo_clave = tipo_periodo.split('-')[0]  # Ejemplo: 'CERRADO' de 'CERRADO-TOTAL-EXPORTADO'\n",
    "\n",
    "        for medida in medidas:\n",
    "            try:\n",
    "                # Obtener las columnas según el período y medida\n",
    "                columnas = columnas_dict[periodo_clave][medida]\n",
    "\n",
    "                # Validación por agrupaciones generales\n",
    "                df_validacion_general = generar_validacion(df, columnas, medida, tipo_periodo)\n",
    "                df_validacion_final = pd.concat([df_validacion_final, df_validacion_general], ignore_index=True)\n",
    "\n",
    "                # Validación total para Colombia (si aplica)\n",
    "                if incluir_colombia:\n",
    "                    df_validacion_colombia = generar_validacion_colombia(df, columnas, medida, tipo_periodo)\n",
    "                    df_validacion_final = pd.concat([df_validacion_final, df_validacion_colombia], ignore_index=True)\n",
    "            except KeyError:\n",
    "                raise KeyError(f\"El período '{periodo_clave}' o la medida '{medida}' no existe en columnas_dict.\")\n",
    "\n",
    "    return df_validacion_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear totales de control para 'CONTINENTES', 'PAISES', 'HUBS', 'DEPARTAMENTOS', 'COLOMBIA'\n",
    "\n",
    "#####################################################\n",
    "# TOTAL EXPORTADO USD Y KG: AÑO CERRADO Y AÑO CORRIDO\n",
    "#####################################################\n",
    "\n",
    "# Validación de total exportado para USD y KG: CERRADO Y CORRIDO\n",
    "tipos_periodo_total = ['CERRADO-TOTAL-EXPORTADO', 'CORRIDO-TOTAL-EXPORTADO']\n",
    "\n",
    "# Generar validaciones\n",
    "df_validacion_total_exportado = generar_validaciones(\n",
    "    df=df_insumo_validacion,\n",
    "    columnas_dict=columnas_dict,\n",
    "    medidas=medidas,\n",
    "    tipos_periodo=tipos_periodo_total,\n",
    "    incluir_colombia=True  # Incluye totales para Colombia\n",
    ")\n",
    "\n",
    "###############################################################\n",
    "# TOTAL EXPORTADO NO MINERO USD Y KG: AÑO CERRADO Y AÑO CORRIDO\n",
    "###############################################################\n",
    "\n",
    "df_nme = df_insumo_validacion[df_insumo_validacion['Tipo']=='No Mineras']\n",
    "\n",
    "# Validación de NME exportado para USD y KG: CERRADO Y CORRIDO\n",
    "tipos_periodo_nme = ['CERRADO-NME-EXPORTADO', 'CORRIDO-NME-EXPORTADO']\n",
    "\n",
    "# Generar validaciones\n",
    "df_validacion_nme_exportado = generar_validaciones(\n",
    "    df=df_nme,\n",
    "    columnas_dict=columnas_dict,\n",
    "    medidas=medidas,\n",
    "    tipos_periodo=tipos_periodo_nme,\n",
    "    incluir_colombia=True  # Incluye totales para Colombia\n",
    ")\n",
    "\n",
    "############################################################\n",
    "# TOTAL EXPORTADO MINERO USD Y KG: AÑO CERRADO Y AÑO CORRIDO\n",
    "############################################################\n",
    "\n",
    "df_minero = df_insumo_validacion[df_insumo_validacion['Tipo']=='Mineras']\n",
    "\n",
    "# Validación de mineros exportado para USD y KG: CERRADO Y CORRIDO\n",
    "tipos_periodo_mineros = ['CERRADO-MINERO-EXPORTADO', 'CORRIDO-MINERO-EXPORTADO']\n",
    "\n",
    "# Generar validaciones\n",
    "df_validacion_minero_exportado = generar_validaciones(\n",
    "    df=df_minero,\n",
    "    columnas_dict=columnas_dict,\n",
    "    medidas=medidas,\n",
    "    tipos_periodo=tipos_periodo_mineros,\n",
    "    incluir_colombia=True  # Incluye totales para Colombia\n",
    ")\n",
    "\n",
    "#################################\n",
    "# CREAR DF CON EL RESULTADO FINAL\n",
    "#################################\n",
    "\n",
    "DF_EXPORTACIONES_CONTROL = pd.concat([df_validacion_total_exportado, df_validacion_nme_exportado, df_validacion_minero_exportado])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlativa con la definición de TLCs\n",
    "query_tlcs = \"\"\"\n",
    "SELECT DISTINCT A.PAIS_LLAVE_EXPORTACIONES,\n",
    "\tA.NOMBRE_TLC\n",
    "FROM DOCUMENTOS_COLOMBIA.GEOGRAFIA.ST_PAISES AS A\n",
    "WHERE A.PAIS_LLAVE_EXPORTACIONES IS NOT NULL\n",
    "ORDER BY 1 ASC;\n",
    "\"\"\"\n",
    "# Ejecutar\n",
    "df_tlcs = snow_func.snowflake_sql(conn, query_tlcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unir con la correlativa de TLCs\n",
    "df_insumo_tlcs = DF_EXPORTACIONES_CONTROL.merge(df_tlcs, how='left', left_on=['UNIDAD'], right_on=['PAIS_LLAVE_EXPORTACIONES'])\n",
    "\n",
    "# Generar las sumas agregadas por TLCs\n",
    "df_insumo_tlcs = df_insumo_tlcs.groupby(['MEDIDA', 'TIPO_PERIODO', 'NOMBRE_TLC'])[['SUMA_T_1', 'SUMA_T']].sum().reset_index()\n",
    "\n",
    "# Renombrar la columna correlativa seleccionada a 'UNIDAD' para estandarizar los nombres de las columnas.\n",
    "df_insumo_tlcs = df_insumo_tlcs.rename(columns={'NOMBRE_TLC': 'UNIDAD'})\n",
    "\n",
    "# Añadir la columna 'AGRUPACION' \n",
    "df_insumo_tlcs['AGRUPACION'] = 'TLCS'\n",
    "\n",
    "# Reorganizar las columnas\n",
    "DF_EXPORTACIONES_CONTROL_TLCS = df_insumo_tlcs[['AGRUPACION', 'UNIDAD', 'MEDIDA', 'TIPO_PERIODO', 'SUMA_T_1', 'SUMA_T']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenar ambos resultado\n",
    "DF_EXPORTACIONES_CONTROL = pd.concat([DF_EXPORTACIONES_CONTROL, DF_EXPORTACIONES_CONTROL_TLCS])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Subir a Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Statement executed successfully.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             status\n",
       "0  Statement executed successfully."
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usar base de datos:\n",
    "sql_database_usar = \"\"\"\n",
    "USE DOCUMENTOS_COLOMBIA;\n",
    "\"\"\"\n",
    "# Ejecutar\n",
    "snow_func.snowflake_sql(conn, sql_database_usar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Statement executed successfully.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             status\n",
       "0  Statement executed successfully."
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usar esquema exportaciones:\n",
    "sql_schema_exportaciones = \"\"\"\n",
    "USE SCHEMA EXPORTACIONES;\n",
    "\"\"\"\n",
    "# Ejecutar\n",
    "snow_func.snowflake_sql(conn, sql_schema_exportaciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WAREHOUSE</th>\n",
       "      <th>DATABASE</th>\n",
       "      <th>SCHEMA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WH_PROCOLOMBIA_ANALITICA</td>\n",
       "      <td>DOCUMENTOS_COLOMBIA</td>\n",
       "      <td>EXPORTACIONES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  WAREHOUSE             DATABASE         SCHEMA\n",
       "0  WH_PROCOLOMBIA_ANALITICA  DOCUMENTOS_COLOMBIA  EXPORTACIONES"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Asegurar que estamos en la ubicación que se desea para subir las bases de datos\n",
    "ubicacion = \"SELECT CURRENT_WAREHOUSE() AS WAREHOUSE, CURRENT_DATABASE() AS DATABASE, CURRENT_SCHEMA() AS SCHEMA;\"\n",
    "# Ejecutar\n",
    "snow_func.snowflake_sql(conn, ubicacion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de pd a subir\n",
    "bases_de_datos = [\n",
    "    DF_ST_CATEGORIAS_CERRADO, \n",
    "    DF_ST_CATEGORIAS_CORRIDO, \n",
    "    DF_ST_CATEGORIAS_PESO_CERRADO, \n",
    "    DF_ST_CATEGORIAS_PESO_CORRIDO, \n",
    "    DF_ST_NIT_CERRADO, \n",
    "    DF_ST_NIT_CORRIDO, \n",
    "    ST_CONTEO_CERRADO, \n",
    "    ST_CONTEO_CORRIDO, \n",
    "    df_oportunidades,\n",
    "    df_balanza_final,\n",
    "    DF_EXPORTACIONES_CONTROL\n",
    "]\n",
    "\n",
    "nombres_tablas = [\n",
    "    'ST_CATEGORIAS_CERRADO', \n",
    "    'ST_CATEGORIAS_CORRIDO', \n",
    "    'ST_CATEGORIAS_PESO_CERRADO', \n",
    "    'ST_CATEGORIAS_PESO_CORRIDO', \n",
    "    'ST_NIT_CERRADO', \n",
    "    'ST_NIT_CORRIDO', \n",
    "    'ST_CONTEO_CERRADO', \n",
    "    'ST_CONTEO_CORRIDO', \n",
    "    'OPORTUNIDADES',\n",
    "    'BALANZA',\n",
    "    'DF_EXPORTACIONES_CONTROL'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd de verificación\n",
    "df_resultados_verificacion = pd.DataFrame()\n",
    "# Subir y verificar bases a Snowflake\n",
    "for base, tabla in zip(bases_de_datos, nombres_tablas):\n",
    "    # Cargar el DataFrame en Snowflake y capturar el mensaje de carga\n",
    "    mensaje_carga = snow_func.snowflake_cargar_df(conn, base, f'{tabla}')\n",
    "    \n",
    "    # Verificar y almacenar el resultado en el DataFrame\n",
    "    resultado = snow_func.snowflake_sql(conn, f\"SELECT COUNT(*) FROM {tabla};\")\n",
    "    total_registros = resultado  # Extraer el total de registros\n",
    "\n",
    "    # Crear un DataFrame temporal para la nueva fila\n",
    "    nueva_fila = pd.DataFrame({\n",
    "        'Tabla': [tabla],\n",
    "        'Total_Registros': [total_registros],\n",
    "        'Mensaje_Carga': [mensaje_carga]\n",
    "    })\n",
    "\n",
    "    # Concatenar la nueva fila al DataFrame de resultados\n",
    "    df_resultados_verificacion = pd.concat([df_resultados_verificacion, nueva_fila], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tabla</th>\n",
       "      <th>Total_Registros</th>\n",
       "      <th>Mensaje_Carga</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ST_CATEGORIAS_CERRADO</td>\n",
       "      <td>COUNT(*)\n",
       "0  28190</td>\n",
       "      <td>DataFrame cargado exitosamente en la tabla: 28190 filas en 1 chunks.\\nTiempo de carga: 4.66 segundos.\\nProceso terminado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ST_CATEGORIAS_CORRIDO</td>\n",
       "      <td>COUNT(*)\n",
       "0  27725</td>\n",
       "      <td>DataFrame cargado exitosamente en la tabla: 27725 filas en 1 chunks.\\nTiempo de carga: 2.56 segundos.\\nProceso terminado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ST_CATEGORIAS_PESO_CERRADO</td>\n",
       "      <td>COUNT(*)\n",
       "0  5550</td>\n",
       "      <td>DataFrame cargado exitosamente en la tabla: 5550 filas en 1 chunks.\\nTiempo de carga: 2.88 segundos.\\nProceso terminado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ST_CATEGORIAS_PESO_CORRIDO</td>\n",
       "      <td>COUNT(*)\n",
       "0  5423</td>\n",
       "      <td>DataFrame cargado exitosamente en la tabla: 5423 filas en 1 chunks.\\nTiempo de carga: 2.32 segundos.\\nProceso terminado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ST_NIT_CERRADO</td>\n",
       "      <td>COUNT(*)\n",
       "0  121919</td>\n",
       "      <td>DataFrame cargado exitosamente en la tabla: 121919 filas en 1 chunks.\\nTiempo de carga: 3.52 segundos.\\nProceso terminado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ST_NIT_CORRIDO</td>\n",
       "      <td>COUNT(*)\n",
       "0  116671</td>\n",
       "      <td>DataFrame cargado exitosamente en la tabla: 116671 filas en 1 chunks.\\nTiempo de carga: 3.68 segundos.\\nProceso terminado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ST_CONTEO_CERRADO</td>\n",
       "      <td>COUNT(*)\n",
       "0  250</td>\n",
       "      <td>DataFrame cargado exitosamente en la tabla: 250 filas en 1 chunks.\\nTiempo de carga: 1.79 segundos.\\nProceso terminado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ST_CONTEO_CORRIDO</td>\n",
       "      <td>COUNT(*)\n",
       "0  250</td>\n",
       "      <td>DataFrame cargado exitosamente en la tabla: 250 filas en 1 chunks.\\nTiempo de carga: 1.97 segundos.\\nProceso terminado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>OPORTUNIDADES</td>\n",
       "      <td>COUNT(*)\n",
       "0  15957</td>\n",
       "      <td>DataFrame cargado exitosamente en la tabla: 15957 filas en 1 chunks.\\nTiempo de carga: 2.11 segundos.\\nProceso terminado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BALANZA</td>\n",
       "      <td>COUNT(*)\n",
       "0  2594</td>\n",
       "      <td>DataFrame cargado exitosamente en la tabla: 2594 filas en 1 chunks.\\nTiempo de carga: 2.19 segundos.\\nProceso terminado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DF_EXPORTACIONES_CONTROL</td>\n",
       "      <td>COUNT(*)\n",
       "0  3328</td>\n",
       "      <td>DataFrame cargado exitosamente en la tabla: 3328 filas en 1 chunks.\\nTiempo de carga: 2.24 segundos.\\nProceso terminado</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Tabla          Total_Registros  \\\n",
       "0   ST_CATEGORIAS_CERRADO          COUNT(*)\n",
       "0  28190      \n",
       "1   ST_CATEGORIAS_CORRIDO          COUNT(*)\n",
       "0  27725      \n",
       "2   ST_CATEGORIAS_PESO_CERRADO     COUNT(*)\n",
       "0  5550       \n",
       "3   ST_CATEGORIAS_PESO_CORRIDO     COUNT(*)\n",
       "0  5423       \n",
       "4   ST_NIT_CERRADO                 COUNT(*)\n",
       "0  121919     \n",
       "5   ST_NIT_CORRIDO                 COUNT(*)\n",
       "0  116671     \n",
       "6   ST_CONTEO_CERRADO              COUNT(*)\n",
       "0  250        \n",
       "7   ST_CONTEO_CORRIDO              COUNT(*)\n",
       "0  250        \n",
       "8   OPORTUNIDADES                  COUNT(*)\n",
       "0  15957      \n",
       "9   BALANZA                        COUNT(*)\n",
       "0  2594       \n",
       "10  DF_EXPORTACIONES_CONTROL       COUNT(*)\n",
       "0  3328       \n",
       "\n",
       "                                                                                                                Mensaje_Carga  \n",
       "0   DataFrame cargado exitosamente en la tabla: 28190 filas en 1 chunks.\\nTiempo de carga: 4.66 segundos.\\nProceso terminado   \n",
       "1   DataFrame cargado exitosamente en la tabla: 27725 filas en 1 chunks.\\nTiempo de carga: 2.56 segundos.\\nProceso terminado   \n",
       "2   DataFrame cargado exitosamente en la tabla: 5550 filas en 1 chunks.\\nTiempo de carga: 2.88 segundos.\\nProceso terminado    \n",
       "3   DataFrame cargado exitosamente en la tabla: 5423 filas en 1 chunks.\\nTiempo de carga: 2.32 segundos.\\nProceso terminado    \n",
       "4   DataFrame cargado exitosamente en la tabla: 121919 filas en 1 chunks.\\nTiempo de carga: 3.52 segundos.\\nProceso terminado  \n",
       "5   DataFrame cargado exitosamente en la tabla: 116671 filas en 1 chunks.\\nTiempo de carga: 3.68 segundos.\\nProceso terminado  \n",
       "6   DataFrame cargado exitosamente en la tabla: 250 filas en 1 chunks.\\nTiempo de carga: 1.79 segundos.\\nProceso terminado     \n",
       "7   DataFrame cargado exitosamente en la tabla: 250 filas en 1 chunks.\\nTiempo de carga: 1.97 segundos.\\nProceso terminado     \n",
       "8   DataFrame cargado exitosamente en la tabla: 15957 filas en 1 chunks.\\nTiempo de carga: 2.11 segundos.\\nProceso terminado   \n",
       "9   DataFrame cargado exitosamente en la tabla: 2594 filas en 1 chunks.\\nTiempo de carga: 2.19 segundos.\\nProceso terminado    \n",
       "10  DataFrame cargado exitosamente en la tabla: 3328 filas en 1 chunks.\\nTiempo de carga: 2.24 segundos.\\nProceso terminado    "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ver resultados\n",
    "df_resultados_verificacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cerrar sesión, conexión y cursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()\n",
    "session.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
